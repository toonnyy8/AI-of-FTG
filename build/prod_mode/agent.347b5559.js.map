{"version":3,"sources":["../src/js/MirageNet/dddqn10/model.js","../src/js/MirageNet/dddqn10/index.js","js/agent.js"],"names":["tfex","tf","DDDQN","sequenceLen","stateVectorLen","layerNum","actionsNum","memorySize","updateTargetStep","initLearningRate","minLearningRate","discount","maxCoderSize","count","model","buildModel","scope","variableScope","targetModel","setWeights","getWeights","memory","optimizer","train","adam","weights","inputSize","outputSize","push","getVariable","initializers","truncatedNormal","stddev","mean","zeros","coderNum","Math","ceil","i","reduce","prev","curr","console","log","variables","x","tidy","jumperLayers","AELayer","conv1d","add","funcs","mish","pop","transpose","value","reshape","A","sub","Q","outputs","length","split","forEach","w","idx","assign","batchPrevS","batchAs","batchRs","batchNextS","batchDiscount","evalNet","predict","Qs","map","actionNum","actionType","mul","oneHot","sum","predictions","targetPredictions","maxQ","argMax","targets","replayNum","loadIdxes","usePrioritizedReplay","train_","replayIdxes","replayIdxes_","slice","arrayPrevS","arrayAs","Array","fill","arrayRs","arrayNextS","arrayDiscount","floor","random","data","prevS","j","As","Rs","nextS","tensor3d","arrayA","tensor1d","arrayR","grads","computeGradients","tQandQ","targetQs","loss","stack","losses","meanSquaredError","print","applyGradients","addN","abs","arraySync","absTD","p","learningRate","max","weight","round","prioritys","tensor","mem","div","multinomial","prioritizedReplayIdx","undefined","preState","actions","rewards","nextState","unshift","index","bsz","begin","min","dddqn","initWeights","sl","load","enableProdMode","dddqnModel","name","preArchives","state","expired","ready","then","channel","self","addEventListener","e","instruction","postMessage","Object","keys","args","archives","outputActions","values","archive","outputAction","softmax","CP","shape","chooseByArgMax","concat","action","chooseByMultinomial","playerName","chooseActionRandomValue","find","store","acc","aiCtrl","Ws","tList","weightsBuffer","save","loadWeights","updatePrioritys"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+hBC,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,MAAA,EAAA,QAAA,WAAA,EA/hBD,IAAA,EAAA,EAAA,QAAA,qBACA,EAAA,QAAA,oCA8hBC,SAAA,IAAA,GAAA,mBAAA,QAAA,OAAA,KAAA,IAAA,EAAA,IAAA,QAAA,OAAA,EAAA,WAAA,OAAA,GAAA,EAAA,SAAA,EAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,IAAA,GAAA,GAAA,EAAA,IAAA,GAAA,OAAA,EAAA,IAAA,GAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,CAAA,IAAA,EAAA,OAAA,gBAAA,OAAA,yBAAA,IAAA,IAAA,KAAA,EAAA,GAAA,OAAA,UAAA,eAAA,KAAA,EAAA,GAAA,CAAA,IAAA,EAAA,EAAA,OAAA,yBAAA,EAAA,GAAA,KAAA,IAAA,EAAA,KAAA,EAAA,KAAA,OAAA,eAAA,EAAA,EAAA,GAAA,EAAA,GAAA,EAAA,IAAA,OAAA,EAAA,QAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EAAA,SAAA,EAAA,EAAA,GAAA,OAAA,EAAA,IAAA,EAAA,EAAA,IAAA,IAAA,SAAA,IAAA,MAAA,IAAA,UAAA,wDAAA,SAAA,EAAA,EAAA,GAAA,GAAA,OAAA,YAAA,OAAA,IAAA,uBAAA,OAAA,UAAA,SAAA,KAAA,GAAA,CAAA,IAAA,EAAA,GAAA,GAAA,EAAA,GAAA,EAAA,OAAA,EAAA,IAAA,IAAA,IAAA,EAAA,EAAA,EAAA,OAAA,cAAA,GAAA,EAAA,EAAA,QAAA,QAAA,EAAA,KAAA,EAAA,QAAA,GAAA,EAAA,SAAA,GAAA,GAAA,IAAA,MAAA,GAAA,GAAA,EAAA,EAAA,EAAA,QAAA,IAAA,GAAA,MAAA,EAAA,QAAA,EAAA,SAAA,QAAA,GAAA,EAAA,MAAA,GAAA,OAAA,GAAA,SAAA,EAAA,GAAA,GAAA,MAAA,QAAA,GAAA,OAAA,EAAA,SAAA,EAAA,EAAA,GAAA,KAAA,aAAA,GAAA,MAAA,IAAA,UAAA,qCAAA,SAAA,EAAA,EAAA,GAAA,IAAA,IAAA,EAAA,EAAA,EAAA,EAAA,OAAA,IAAA,CAAA,IAAA,EAAA,EAAA,GAAA,EAAA,WAAA,EAAA,aAAA,EAAA,EAAA,cAAA,EAAA,UAAA,IAAA,EAAA,UAAA,GAAA,OAAA,eAAA,EAAA,EAAA,IAAA,IAAA,SAAA,EAAA,EAAA,EAAA,GAAA,OAAA,GAAA,EAAA,EAAA,UAAA,GAAA,GAAA,EAAA,EAAA,GAAA,EA7hBD,IAAMA,GAAO,EAAaC,EAAAA,cAAAA,GAEbC,EA2hBZ,WA/gBM,SAAA,EAAA,GAVCC,IAAAA,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,EAUf,EATCC,EAAAA,EAAAA,eAAAA,OAAiB,IAAA,EAAA,GASlB,EARCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,EAQZ,EAPCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAOjC,EANCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,IAMd,EALCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,IAKpB,EAJCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,KAIpB,EAHCC,EAAAA,EAAAA,gBAAAA,OAAkB,IAAA,EAAA,KAGnB,EAFCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,IAEZ,EADCC,EAAAA,EAAAA,aAAAA,OAAe,IAAA,EAAA,EAChB,EAAA,EAAA,KAAA,GAGUJ,KAAAA,iBAAmBA,EAEnBG,KAAAA,SAAWA,EAEXE,KAAAA,MAAQ,EAERP,KAAAA,WAAaA,EAIbQ,KAAAA,MAAQ,KAAKC,WAAW,CACzBZ,YAAaA,EACbC,eAAgBA,EAChBC,SAAUA,EACVC,WAAYA,EACZM,aAAcA,GACfZ,EAAKgB,MAAMC,cAAc,SAGvBC,KAAAA,YAAc,KAAKH,WAAW,CAC/BZ,YAAaA,EACbC,eAAgBA,EAChBC,SAAUA,EACVC,WAAYA,EACZM,aAAcA,GACfZ,EAAKgB,MAAMC,cAAc,WAEvBC,KAAAA,YAAYC,WAAW,KAAKL,MAAMM,cAIlCb,KAAAA,WAAaA,EACbc,KAAAA,OAAS,GAITX,KAAAA,gBAAkBA,EAClBD,KAAAA,iBAAmBA,EACnBa,KAAAA,UAAYrB,EAAGsB,MAAMC,KAAK,KAAKf,kBAse/C,OAAA,EAAA,EAAA,CAAA,CAAA,IAAA,aA3d0B,MAAA,SAAA,GALnBN,IAAAA,EAAAA,EAAAA,YACAC,EAAAA,EAAAA,eACAC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,GAGQ,EAFnBC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,CAAC,EAAG,EAAG,GAED,EADnBM,EAAAA,EAAAA,aAAAA,OAAe,IAAA,EAAA,EACI,EAApBI,EAAQhB,UAAAA,OAAAA,QAAAA,IAAAA,UAAAA,GAAAA,UAAAA,GAAAA,EAAKgB,MAqML,OAAA,IArMY,WAQQ,SAAA,EAAA,GALnBb,IAAAA,EAAAA,EAAAA,YACAC,EAAAA,EAAAA,eACAC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,GAGQ,EAFnBC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,CAAC,EAAG,EAAG,GAED,EADnBM,EAAAA,EAAAA,aAAAA,OAAe,IAAA,EAAA,EACI,EAApBI,EAAQhB,UAAAA,OAAAA,QAAAA,IAAAA,UAAAA,GAAAA,UAAAA,GAAAA,EAAKgB,MAAO,EAAA,KAAA,GACdb,KAAAA,YAAcA,EACdC,KAAAA,eAAiBA,EACjBC,KAAAA,SAAWA,EACXC,KAAAA,WAAaA,EACbU,KAAAA,MAAQA,EACRS,KAAAA,QAAU,GAEXC,IAAAA,EAAYtB,EACZuB,EAAavB,EAAiBQ,EAC7Ba,KAAAA,QAAQG,KAAKZ,EAAMa,YAAuB,UAAA,CAAC,EAAGH,EAAWC,GAAa,UAAW1B,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MACtIR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAuB,UAAA,CAAC,EAAG,EAAGF,GAAa,UAAW1B,EAAG6B,aAAaI,MAAM,MAE/FT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAqB,QAAA,CAAC,EAAGF,EAAYA,GAAa,UAAW1B,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MACrIR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAqB,QAAA,CAAC,EAAG,EAAGF,GAAa,UAAW1B,EAAG6B,aAAaI,MAAM,MAG7F,IADDC,IAAAA,EAAqC,EAA1BC,KAAKC,KAAKhC,EAAW,GAC3BiC,EAAI,EAAGA,GAAKH,EAAUG,IAC3BZ,EAAYC,EACZA,EAAcvB,EAAiB,GAAMkC,EAAIH,GAAY/B,EAAiBQ,GAAgBuB,EAAWG,GAAKH,EACtGR,EAAaS,KAAKC,KAAKV,GAClBF,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBS,OAAAA,OAAAA,GAAK,CAACF,KAAKC,KAAKlC,EAAegC,GAAa,EAAGT,EAAWC,GAAa,UAAW1B,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAC7KR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBS,OAAAA,OAAAA,GAAK,CAAC,EAAG,EAAGX,GAAa,UAAW1B,EAAG6B,aAAaI,MAAM,MAChGT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBS,OAAAA,OAAAA,GAAK,CAAC,EAAGX,EAAYA,GAAa,UAAW1B,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MACxIR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBS,OAAAA,OAAAA,GAAK,CAAC,EAAG,EAAGX,GAAa,UAAW1B,EAAG6B,aAAaI,MAAM,MAGzGR,EAAYC,EACPF,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBM,OAAAA,OAAAA,EAAW,GAAK,CAACC,KAAKC,KAAKlC,EAAegC,GAAa,EAAGT,EAAWC,GAAa,UAAW1B,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MACxLR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBM,OAAAA,OAAAA,EAAW,GAAK,CAAC,EAAG,EAAGR,GAAa,UAAW1B,EAAG6B,aAAaI,MAAM,MAE3G,IAAA,IAAII,EAAI,EAAGA,GAAKH,EAAUG,IAC3BX,EAAcvB,EAAiB,IAAO+B,EAAWG,GAAKH,GAAY/B,EAAiBQ,EAAe0B,EAAIH,EACtGR,EAAaS,KAAKC,KAAKV,GAClBF,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBM,OAAAA,OAAAA,EAAWG,EAAI,GAAK,CAAC,EAAG,EAAGX,GAAa,UAAW1B,EAAG6B,aAAaI,MAAM,MAI/GT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAwB,WAAA,CAAC,EAAG1B,EAAa,GAAI,UAAWF,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAChIR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAwB,WAAA,CAAC,EAAG,EAAG,GAAI,UAAW5B,EAAG6B,aAAaI,MAAM,MAEvFT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAwB,WAAA,CAAC,EAAGzB,EAAiBQ,EAAc,GAAI,UAAWX,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAClJR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAwB,WAAA,CAAC,EAAG,EAAG,GAAI,UAAW5B,EAAG6B,aAAaI,MAAM,MAIvFT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAoB,OAAA,CAAC,EAAG1B,EAAa,GAAI,UAAWF,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAC5HR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAoB,OAAA,CAAC,EAAG,EAAG,GAAI,UAAW5B,EAAG6B,aAAaI,MAAM,MAEnFT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAoB,OAAA,CAAC,EAAGzB,EAAiBQ,EAAcN,EAAWiC,OAAO,SAACC,EAAMC,GAASD,OAAAA,EAAOC,GAAM,IAAK,UAAWxC,EAAG6B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAC9LR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAoB,OAAA,CAAC,EAAG,EAAGvB,EAAWiC,OAAO,SAACC,EAAMC,GAASD,OAAAA,EAAOC,GAAM,IAAK,UAAWxC,EAAG6B,aAAaI,MAAM,MAG5IQ,QAAQC,IAAI,KAAK3B,MAAM4B,WA7DZ,OAAA,EAAA,EAAA,CAAA,CAAA,IAAA,UAgEPC,MAAAA,SAAAA,GAAG,IAAA,EAAA,KACA5C,OAAAA,EAAG6C,KAAK,WACPC,IAAAA,EAAe,GACfC,EAAU/C,EAAGgD,OACbJ,EACA,EAAK7B,MAAMa,YAFD,WAGV,EACA,QAEJmB,EAAU/C,EAAGiD,IAAIF,EAAS,EAAKhC,MAAMa,YAA3B,YACVmB,EAAUhD,EAAKmD,MAAMC,KAAKJ,GAC1BD,EAAanB,KACT5B,EAAKmD,MAAMC,KACPnD,EAAGgD,OACCD,EACA,EAAKhC,MAAMa,YAFf,SAGI,EACA,QACFqB,IAAI,EAAKlC,MAAMa,YALjB,YAUH,IADDM,IAAAA,EAAqC,EAA1BC,KAAKC,KAAKhC,EAAW,GAC3BiC,EAAI,EAAGA,GAAKH,EAAUG,IAC3BU,EAAU/C,EAAGgD,OACTD,EACA,EAAKhC,MAAMa,YAAmBS,OAAAA,OAAAA,IAC9B,EACA,QAEJU,EAAU/C,EAAGiD,IAAIF,EAAS,EAAKhC,MAAMa,YAAmBS,OAAAA,OAAAA,KACxDU,EAAUhD,EAAKmD,MAAMC,KAAKJ,GAC1BD,EAAanB,KACT5B,EAAKmD,MAAMC,KACPnD,EAAGgD,OACCD,EACA,EAAKhC,MAAMa,YAAmBS,OAAAA,OAAAA,IAC9B,EACA,QACFY,IAAI,EAAKlC,MAAMa,YAAmBS,OAAAA,OAAAA,OAKhDU,EAAU/C,EAAGgD,OACTD,EACA,EAAKhC,MAAMa,YAAmBM,OAAAA,OAAAA,EAAW,IACzC,EACA,QAEJa,EAAU/C,EAAGiD,IAAIF,EAAS,EAAKhC,MAAMa,YAAmBM,OAAAA,OAAAA,EAAW,KACnEa,EAAUhD,EAAKmD,MAAMC,KAAKJ,GAC1BA,EAAU/C,EAAGiD,IAAIF,EAASD,EAAaM,OAElC,IAAA,IAAIf,EAAI,EAAGA,EAAIH,EAAUG,IAC1BU,EAAU/C,EAAGgD,OACTD,EACA/C,EAAGqD,UACC,EAAKtC,MAAMa,YAAmBM,OAAAA,OAAAA,EAAWG,IACzC,CAAC,EAAG,EAAG,IAEX,EACA,QAEJU,EAAU/C,EAAGiD,IAAIF,EAAS,EAAKhC,MAAMa,YAAmBM,OAAAA,OAAAA,EAAWG,EAAI,KACvEU,EAAUhD,EAAKmD,MAAMC,KAAKJ,GAC1BA,EAAU/C,EAAGiD,IAAIF,EAASD,EAAaM,OAGvCE,IAAAA,EAAQP,EAERO,EAAQtD,EAAGqD,UAAUC,EAAO,CAAC,EAAG,EAAG,IACnCA,EAAQtD,EAAGgD,OACPM,EACA,EAAKvC,MAAMa,YAFP,YAGJ,EAAG,GAEP0B,EAAQtD,EAAGiD,IAAIK,EAAO,EAAKvC,MAAMa,YAAzB,aAER0B,EAAQtD,EAAGqD,UAAUC,EAAO,CAAC,EAAG,EAAG,IACnCA,EAAQtD,EAAGgD,OACPM,EACA,EAAKvC,MAAMa,YAFP,YAGJ,EAAG,GAEP0B,EAAQtD,EAAGiD,IAAIK,EAAO,EAAKvC,MAAMa,YAAzB,aACR0B,EAAQtD,EAAGuD,QAAQD,EAAO,EAAE,EAAG,IAG/BE,IAAAA,EAAIT,EAGJS,EAAIxD,EAAGqD,UAAUG,EAAG,CAAC,EAAG,EAAG,IAC3BA,EAAIxD,EAAGgD,OACHQ,EACA,EAAKzC,MAAMa,YAFX,QAGA,EAAG,GAEP4B,EAAIxD,EAAGiD,IAAIO,EAAG,EAAKzC,MAAMa,YAArB,SACJ4B,EAAIxD,EAAGqD,UAAUG,EAAG,CAAC,EAAG,EAAG,IAC3BA,EAAIxD,EAAGgD,OACHQ,EACA,EAAKzC,MAAMa,YAFX,QAGA,EAAG,GAEP4B,EAAIxD,EAAGiD,IAAIO,EAAG,EAAKzC,MAAMa,YAArB,SACJ4B,EAAIxD,EAAGuD,QAAQC,EAAG,EAAE,EAAG,EAAKnD,WAAWiC,OAAO,SAACC,EAAMC,GAASD,OAAAA,EAAOC,GAAM,KAE3EgB,EAAIxD,EAAGyD,IAAID,EAAGxD,EAAGgC,KAAKwB,EAAG,GAAG,IAG5BE,IAAAA,EAAI1D,EAAGiD,IAAIK,EAAOE,GASfG,OANuB,GAA1B,EAAKtD,WAAWuD,OACNF,EAEA1D,EAAG6D,MAAMH,EAAG,EAAKrD,WAAY,OArLpC,CAAA,IAAA,aA4LF,MAAA,WACF,OAAA,KAAKmB,UA7LD,CAAA,IAAA,aAgMJA,MAAAA,SAAAA,GACFA,KAAAA,QAAQsC,QAAQ,SAACC,EAAGC,GAAQD,OAAAA,EAAEE,OAAOzC,EAAQwC,UAjMvC,EAAA,GAqMZ,CAAM,CACT9D,YAAAA,EACAC,eAAAA,EACAC,SAAAA,EACAC,WAAAA,EACAM,aAAAA,GACDI,KAgRV,CAAA,IAAA,SA7QUmD,MAAAA,SAAAA,EAAYC,EAASC,EAASC,EAAYC,GAAe,IAAA,EAAA,KACrDtE,OAAAA,EAAG6C,KAAK,WACP0B,IAAAA,EAAU,EAAK1D,MAAM2D,QAAQN,GACH,GAA1B,EAAK7D,WAAWuD,SAChBW,EAAU,CAACA,IAETE,IAAAA,EAAK,EAAKpE,WAAWqE,IAAI,SAACC,EAAWC,GAChC5E,OAAAA,EAAG6E,IACN7E,EAAG8E,OACCX,EAAQS,GACRD,GAEJJ,EAAQK,IACVG,IAAI,KAGNC,EAAc,EAAKnE,MAAM2D,QAAQH,GACP,GAA1B,EAAKhE,WAAWuD,SAChBoB,EAAc,CAACA,IAEfC,IAAAA,EAAoB,EAAKhE,YAAYuD,QAAQH,GAkB1C,OAjBuB,GAA1B,EAAKhE,WAAWuD,SAChBqB,EAAoB,CAACA,IAgBlB,CAdU,EAAK5E,WAAWqE,IAAI,SAACC,EAAWC,GACvCM,IAAAA,EAAOlF,EAAG6E,IACZ7E,EAAG8E,OACC9E,EAAGmF,OACCH,EAAYJ,GACZ,GAEJD,GAEJM,EAAkBL,IACpBG,IAAI,GAECK,OADShB,EAAQQ,GAAY3B,IAAIiC,EAAKL,IAAIP,MAGnCG,OAuO7B,CAAA,IAAA,QAnO4E,MAAA,WAAA,IAAA,EAAA,KAAnEY,EAAY,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,IAAKC,EAAY,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,CAAC,MAAOC,EAAuB,UAAA,OAAA,QAAA,IAAA,UAAA,IAAA,UAAA,GAC9DvF,EAAG6C,KAAK,WACA2C,IAAAA,EAAS,SAACC,GACVzF,EAAG6C,KAAK,WASC,IARD6C,IAAAA,EAAeD,EAAYE,QAE3BC,EAAa,GACbC,EAAU,IAAIC,MAAM,EAAKzF,WAAWuD,QAAQmC,KAAK,IACjDC,EAAU,IAAIF,MAAM,EAAKzF,WAAWuD,QAAQmC,KAAK,IACjDE,EAAa,GACbC,EAAgB,GAEX7D,EAAI,EAAGA,EAAIgD,EAAWhD,IAAK,EACT,MAAnBqD,EAAarD,IAAcqD,EAAarD,IAAM,EAAKjB,OAAOwC,UAC1D8B,EAAarD,GAAKF,KAAKgE,MAAMhE,KAAKiE,SAAW,EAAKhF,OAAOwC,SAEzDyC,IAAAA,EAAO,EAAKjF,OAAOsE,EAAarD,IAEpCuD,EAAWjE,KAAK0E,EAAKC,OAChB,IAAA,IAAIC,EAAI,EAAGA,EAAI,EAAKlG,WAAWuD,OAAQ2C,IACxCV,EAAQU,GAAGlE,GAAKgE,EAAKG,GAAGD,GACxBP,EAAQO,GAAGlE,GAAKgE,EAAKI,GAAGF,GAE5BN,EAAWtE,KAAK0E,EAAKK,OACrBR,EAAcvE,KAAK0E,EAAK3F,UAGxBwD,IAAAA,EAAalE,EAAG2G,SAASf,GACzBzB,EAAU0B,EAAQnB,IAAI,SAACkC,GAChB5G,OAAAA,EAAG6G,SAASD,EAAQ,WAE3BxC,EAAU4B,EAAQtB,IAAI,SAACoC,GAChB9G,OAAAA,EAAG6G,SAASC,EAAQ,aAE3BzC,EAAarE,EAAG2G,SAASV,GACzB3B,EAAgBtE,EAAG6G,SAASX,GAE5Ba,EAAQ,EAAK1F,UAAU2F,iBACvB,WACyB,IADnB,EAAA,EACmB,EAAKC,OACtB/C,EACAC,EACAC,EACAC,EACAC,GANF,GACG4C,EADH,EAAA,GACazC,EADb,EAAA,GAQE0C,EAAOnH,EAAGgC,KACVhC,EAAGoH,MACC,EAAK/G,WAAWqE,IAAI,SAACC,EAAWC,GAErB5E,OAAAA,EAAGqH,OAAOC,iBAAiBJ,EAAStC,GAAaH,EAAGG,QAKhEuC,OADPA,EAAKI,QACEJ,GACR,EAAKtG,MAAMM,YAAW,IAAO4F,MAYpC,EAAK1F,UAAUmG,eAAeT,GAGL,IADzB,EAAA,EACyB,EAAKE,OACtB/C,EACAC,EACAC,EACAC,EACAC,GANR,GACS4C,EADT,EAAA,GACmBzC,EADnB,EAAA,GAQIzE,EAAGyH,KACC,EAAKpH,WAAWqE,IAAI,SAACC,EAAWC,GACrB5E,OAAAA,EAAG0H,IAAI1H,EAAGyD,IAAIyD,EAAStC,GAAaH,EAAGG,QAEpD+C,YACG7D,QAAQ,SAAC8D,EAAO5D,GACb,EAAK5C,OAAOsE,EAAa1B,IAAM6D,EAAID,IAI/C,EAAKhH,QAEL,EAAKS,UAAUyG,aAAe3F,KAAK4F,IAAI,EAAKvH,iBAAoB,KAAA,IAAA,EAAKI,MAAS,IAAM,EAAKH,iBAErF,EAAKF,iBAAmB,EACxB,EAAKU,YAAYC,WACb,EAAKD,YAAYE,aAAauD,IAAI,SAACsD,EAAQhE,GAChChE,OAAAA,EAAGiD,IACNjD,EAAG6E,IAAI,EAAKhE,MAAMM,aAAa6C,GAAM,EAAKzD,kBAC1CP,EAAG6E,IAAImD,EAAQ,EAAI,EAAKzH,sBAKhC,EAAKK,MAAQuB,KAAK8F,MAAM,EAAK1H,mBAAqB,GAClD,EAAKU,YAAYC,WAAW,EAAKL,MAAMM,iBAK7B,GAAtB,EAAKC,OAAOwC,QASR4B,EARAD,EAC8BvF,EAAG6C,KAAK,WAC9BqF,IAAAA,EAAYlI,EAAGmI,OAAO,EAAK/G,OAAOsD,IAAI,SAAA0D,GAAOA,OAAAA,EAAIP,KAG9C7H,OAFPkI,EAAYlI,EAAGqI,IAAIH,EAAWlI,EAAG+E,IAAImD,EAAW,GAAG,IAE5ClI,EAAGsI,YAAYJ,EAAW7C,EAAW,MAAM,GAAMsC,cAG7BjD,IAAI,SAAC6D,EAAsBvE,GAC/CsB,OAAkB,MAAlBA,EAAUtB,IAAkCwE,MAAlBlD,EAAUtB,GAAoBuE,EAAuBjD,EAAUtB,KAG7FsB,OA0G1B,CAAA,IAAA,QApGSmD,MAAAA,SAAAA,EAAUC,EAASC,EAASC,EAAWlI,GACrC,KAAKU,OAAOwC,QAAU,KAAKtD,YACtBc,KAAAA,OAAOgC,MAEXhC,KAAAA,OAAOyH,QAAQ,CAChBvC,MAAOmC,EACPjC,GAAIkC,EACJjC,GAAIkC,EACJjC,MAAOkC,EACPlI,SAAUA,EACVmH,EAAG,QA0Fd,CAAA,IAAA,OAtFQiB,MAAAA,SAAAA,GAIM,OAHM,MAATA,GAAiBA,GAAS,KAAK1H,OAAOwC,UACtCkF,EAAQ3G,KAAKgE,MAAMhE,KAAKiE,SAAW,KAAKhF,OAAOwC,SAE5C,KAAKxC,OAAO0H,KAkF1B,CAAA,IAAA,kBA/E6B,MAAA,WAAA,IAAA,EAAA,KAAVC,EAAM,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,GAEd,GAAsB,GAAtB,KAAK3H,OAAOwC,OACP,IAAIoF,IAAAA,EAAAA,SAAAA,GACLhJ,EAAG6C,KAAK,WAOC,IAND+C,IAAAA,EAAa,GACbC,EAAU,IAAIC,MAAM,EAAKzF,WAAWuD,QAAQmC,KAAK,IACjDC,EAAU,IAAIF,MAAM,EAAKzF,WAAWuD,QAAQmC,KAAK,IACjDE,EAAa,GACbC,EAAgB,GAEX7D,EAAI2G,EAAO3G,EAAIF,KAAK8G,IAAI,EAAK7H,OAAOwC,OAAQoF,EAAQD,GAAM1G,IAAK,CAChEgE,IAAAA,EAAO,EAAKjF,OAAOiB,GACvBuD,EAAWjE,KAAK0E,EAAKC,OAChB,IAAA,IAAIC,EAAI,EAAGA,EAAI,EAAKlG,WAAWuD,OAAQ2C,IACxCV,EAAQU,GAAGlE,EAAI2G,GAAS3C,EAAKG,GAAGD,GAChCP,EAAQO,GAAGlE,EAAI2G,GAAS3C,EAAKI,GAAGF,GAEpCN,EAAWtE,KAAK0E,EAAKK,OACrBR,EAAcvE,KAAK0E,EAAK3F,UAGxBwD,IAAAA,EAAalE,EAAG2G,SAASf,GACzBzB,EAAU0B,EAAQnB,IAAI,SAACkC,GAChB5G,OAAAA,EAAG6G,SAASD,EAAQ,WAE3BxC,EAAU4B,EAAQtB,IAAI,SAACoC,GAChB9G,OAAAA,EAAG6G,SAASC,EAAQ,aAE3BzC,EAAarE,EAAG2G,SAASV,GACzB3B,EAAgBtE,EAAG6G,SAASX,GA1BtB,EAAA,EA4BW,EAAKe,OACtB/C,EACAC,EACAC,EACAC,EACAC,GAjCM,GA4BL4C,EA5BK,EAAA,GA4BKzC,EA5BL,EAAA,GAmCVzE,EAAGyH,KACC,EAAKpH,WAAWqE,IAAI,SAACC,EAAWC,GACrB5E,OAAAA,EAAG0H,IAAI1H,EAAGyD,IAAIyD,EAAStC,GAAaH,EAAGG,QAEpD+C,YACG7D,QAAQ,SAAC8D,EAAO5D,GACb,EAAK5C,OAAO4H,EAAQhF,GAAK6D,EAAID,OA1CpCoB,EAAQ,EAAGA,EAAQ,KAAK5H,OAAOwC,OAAQoF,GAASD,EAAhDC,EAAAA,OA4EpB,EAAA,GAxBM,SAASE,EAWb,GAVChJ,IAAAA,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,EAUf,EATCC,EAAAA,EAAAA,eAAAA,OAAiB,IAAA,EAAA,GASlB,EARCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,EAQZ,EAPCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAOjC,EANCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,IAMd,EALCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,IAKpB,EAJCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,KAIpB,EAHCC,EAAAA,EAAAA,gBAAAA,OAAkB,IAAA,EAAA,KAGnB,EAFCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,IAEZ,EADCC,EAAAA,EAAAA,aAEO,OAAA,IAAIV,EAAM,CACbC,YAAAA,EACAC,eAAAA,EACAC,SAAAA,EACAC,WAAAA,EACAC,WAAAA,EACAC,iBAAAA,EACAC,iBAAAA,EACAC,gBAAAA,EACAC,SAAAA,EACAC,kBAZW,IAAA,EAAA,EAChB,IAaF,QAAA,MAAA;;AC/hBD,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,IAAA,EAAA,QAAA,WAAA,OAAA,KAAA,GAAA,QAAA,SAAA,GAAA,YAAA,GAAA,eAAA,GAAA,OAAA,eAAA,QAAA,EAAA,CAAA,YAAA,EAAA,IAAA,WAAA,OAAA,EAAA;;;ACyCA,IAAA,EAAA,QAAA,UAAA,OAzCA,EAAA,EAAA,QAAA,qBACA,EAAA,QAAA,kCACA,EAAA,QAAA,qCAEA,EAAA,EAAA,QAAA,OAqCA,SAAA,IAAA,GAAA,mBAAA,QAAA,OAAA,KAAA,IAAA,EAAA,IAAA,QAAA,OAAA,EAAA,WAAA,OAAA,GAAA,EAAA,SAAA,EAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,IAAA,GAAA,GAAA,EAAA,IAAA,GAAA,OAAA,EAAA,IAAA,GAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,CAAA,IAAA,EAAA,OAAA,gBAAA,OAAA,yBAAA,IAAA,IAAA,KAAA,EAAA,GAAA,OAAA,UAAA,eAAA,KAAA,EAAA,GAAA,CAAA,IAAA,EAAA,EAAA,OAAA,yBAAA,EAAA,GAAA,KAAA,IAAA,EAAA,KAAA,EAAA,KAAA,OAAA,eAAA,EAAA,EAAA,GAAA,EAAA,GAAA,EAAA,IAAA,OAAA,EAAA,QAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EAtCA,IAAMZ,GAAO,EAAaC,EAAAA,cAAAA,GAEtBmJ,EAAcpJ,EAAKqJ,GAAGC,KAA1B,EAAA,2rmtrBAAA,WAEArJ,EAAGsJ,iBAEH,IAAIjJ,EAAa,CAAC,KAEdkJ,GAAa,EAAM,EAAA,OAAA,CACnBrJ,YAAa,EACbC,eAAgB,GAChBC,SAAU,GACVC,WAAYA,EACZC,WAAY,KACZG,gBAAiB,KACjBD,iBAAkB,KAClBD,iBAAkB,IAClBG,SAAU,GACVC,aAAc,IAElB4I,EAAW1I,MAAMM,aAAa2C,QAAQ,SAACC,GACnCA,EAAEE,OAAOkF,EAAYpF,EAAEyF,SAE3BD,EAAWtI,YAAYC,WACnBqI,EAAW1I,MAAMM,cAGrB,IAAIsI,EAAc,CACH,QAAA,CACPC,MAAO,KACPC,SAAS,GAEF,QAAA,CACPD,MAAO,KACPC,SAAS,IAIjB3J,EAAG4J,QAAQC,KAAK,WACRC,IAAAA,EAAUC,KACdD,EAAQE,iBAAiB,UAAW,SAACC,GACjCjK,EAAG6C,KAAK,WACIoH,OAAAA,EAAE5D,KAAK6D,aACN,IAAA,OAEGJ,EAAQK,YAAY,CAAED,YAAa,SACnC,MAEH,IAAA,OAEOE,GAA4C,GAA5CA,OAAOC,KAAKJ,EAAE5D,KAAKiE,KAAKC,UAAU3G,OAAa,CAC3C4G,IAAAA,EAAgBjB,EACf1I,MACA2D,QACGxE,EAAGmI,OACCiC,OAAOK,OAAOR,EAAE5D,KAAKiE,KAAKC,UACrB7F,IAAI,SAAAgG,GACMA,OAAAA,EAAQhB,UAIV,GAArBrJ,EAAWuD,SACX4G,EAAgB,CAACA,IAErBA,EAAgBA,EAAc9F,IAAI,SAAAiG,GAWvBA,OAVPA,EAAe3K,EAAG4K,QAAQD,EAAc,GACpCV,EAAE5D,KAAKiE,KAAKO,KACZF,EAAe3K,EAAGqI,IACdrI,EAAGiD,IACC0H,EACA,EAAIA,EAAaG,MAAM,IAE3B,IAGDH,IAGPjC,IAAAA,EAAU,GACVqC,EAAiB/K,EAAGgL,OACpBR,EAAc9F,IAAI,SAACuG,GACRjL,OAAAA,EAAGmF,OAAO8F,EAAQ,GAAG1H,QAAQ,EAAE,EAAG,MACzC,GACNoE,YAEEuD,EAAsBlL,EAAGgL,OACzBR,EAAc9F,IAAI,SAACuG,GACRjL,OAAAA,EAAGsI,YAAY2C,EAAQ,EAAG,MAAM,KACvC,GACNtD,YAEFyC,OAAOC,KAAKJ,EAAE5D,KAAKiE,KAAKC,UACnBzG,QAAQ,SAACqH,EAAYnH,GACd7B,KAAKiE,SAAW6D,EAAE5D,KAAKiE,KAAKC,SAASY,GAAYC,wBACjD1C,EAAQyC,GAAcD,EAAoBlH,GAE1C0E,EAAQyC,GAAcJ,EAAe/G,KAIjDoG,OAAOC,KAAKZ,GAAa3F,QAAQ,SAACqH,QAC8C3C,IAAxE4B,OAAOC,KAAKJ,EAAE5D,KAAKiE,KAAKC,UAAUc,KAAK,SAAA7B,GAAQA,OAAAA,IAAS2B,KACjB,GAAnC1B,EAAY0B,GAAYxB,SACxBJ,EAAW+B,MACP7B,EAAY0B,GAAYzB,MACxBO,EAAE5D,KAAKiE,KAAKC,SAASY,GAAYzC,QACjCuB,EAAE5D,KAAKiE,KAAKC,SAASY,GAAYxC,QACjCsB,EAAE5D,KAAKiE,KAAKC,SAASY,GAAYzB,MACjCO,EAAE5D,KAAKiE,KAAKC,SAASY,GAAYzK,UAGzC+I,EAAY0B,GAAYxB,SAAU,GAElCF,EAAY0B,GAAYxB,SAAU,IAI1CS,OAAOC,KAAKJ,EAAE5D,KAAKiE,KAAKC,UAAUzG,QAAQ,SAACqH,EAAYnH,GACnDyF,EAAY0B,GAAYzB,MAAQO,EAAE5D,KAAKiE,KAAKC,SAASY,GAAYzB,QAErEI,EAAQK,YAAY,CAChBD,YAAa,OACbI,KAAM,CACFC,SAAUH,OAAOC,KAAKJ,EAAE5D,KAAKiE,KAAKC,UAAUjI,OAAO,SAACiJ,EAAKJ,GAK9CI,OAJPA,EAAIJ,GAAc,CACdzC,QAASA,EAAQyC,GACjBK,OAAQvB,EAAE5D,KAAKiE,KAAKC,SAASY,GAAYK,QAEtCD,GACR,YAIXzB,EAAQK,YAAY,CAChBD,YAAa,OACbI,KAAM,CACFI,QAAS,MAKrB,MAEH,IAAA,QAEGnB,EAAWjI,MAAM2I,EAAE5D,KAAKiE,KAAKvB,IAAKkB,EAAE5D,KAAKiE,KAAK7E,YAAawE,EAAE5D,KAAKiE,KAAK/E,sBACvEuE,EAAQK,YAAY,CAAED,YAAa,UACnC,MAEH,IAAA,OAEGlK,EAAG6C,KAAK,WACA4I,IACAC,EADKnC,EAAW1I,MAAMM,aACXmB,OAAO,SAACiJ,EAAKxH,GAEjBwH,OADPA,EAAIxH,EAAEyF,MAAQzF,EACPwH,GACR,IACHzB,EAAQK,YAAY,CAChBD,YAAa,OACbI,KAAM,CACFqB,cAAe5L,EAAKqJ,GAAGwC,KAAKF,QAKxC,MAEH,IAAA,OAEOG,IAAAA,EAAc9L,EAAKqJ,GAAGC,KAAKY,EAAE5D,KAAKiE,KAAKqB,eAC3CpC,EAAW1I,MAAMM,aAAa2C,QAAQ,SAACC,GACnCA,EAAEE,OAAO4H,EAAY9H,EAAEyF,SAE3BD,EAAWtI,YAAYC,WACnBqI,EAAW1I,MAAMM,cAErB2I,EAAQK,YAAY,CAAED,YAAa,SACnC,MAEH,IAAA,kBAEGX,EAAWuC,kBACXhC,EAAQK,YAAY,CAAED,YAAa","file":"agent.347b5559.js","sourceRoot":"..\\..\\prod_mode","sourcesContent":["import * as tf from \"@tensorflow/tfjs\"\r\nimport { registerTfex } from \"../../../lib/tfjs-extensions/src\"\r\nconst tfex = registerTfex(tf)\r\n\r\nexport class DDDQN {\r\n    constructor({\r\n        sequenceLen = 4,\r\n        stateVectorLen = 59,\r\n        layerNum = 8,\r\n        actionsNum = [2, 2, 2, 2, 2, 2, 2],\r\n        memorySize = 1000,\r\n        updateTargetStep = 0.05,\r\n        initLearningRate = 1e-3,\r\n        minLearningRate = 1e-5,\r\n        discount = 0.63,\r\n        maxCoderSize = 4\r\n    }) {\r\n\r\n        {\r\n            this.updateTargetStep = updateTargetStep\r\n\r\n            this.discount = discount\r\n\r\n            this.count = 0\r\n\r\n            this.actionsNum = actionsNum\r\n        }\r\n\r\n        {\r\n            this.model = this.buildModel({\r\n                sequenceLen: sequenceLen,\r\n                stateVectorLen: stateVectorLen,\r\n                layerNum: layerNum,\r\n                actionsNum: actionsNum,\r\n                maxCoderSize: maxCoderSize\r\n            }, tfex.scope.variableScope(\"eval\"))\r\n            // this.model.summary()\r\n\r\n            this.targetModel = this.buildModel({\r\n                sequenceLen: sequenceLen,\r\n                stateVectorLen: stateVectorLen,\r\n                layerNum: layerNum,\r\n                actionsNum: actionsNum,\r\n                maxCoderSize: maxCoderSize\r\n            }, tfex.scope.variableScope(\"target\"))\r\n\r\n            this.targetModel.setWeights(this.model.getWeights())\r\n        }\r\n\r\n        {\r\n            this.memorySize = memorySize\r\n            this.memory = []\r\n        }\r\n\r\n        {\r\n            this.minLearningRate = minLearningRate\r\n            this.initLearningRate = initLearningRate\r\n            this.optimizer = tf.train.adam(this.initLearningRate)\r\n        }\r\n\r\n    }\r\n\r\n    buildModel({\r\n        sequenceLen,\r\n        stateVectorLen,\r\n        layerNum = 32,\r\n        actionsNum = [3, 3, 4],\r\n        maxCoderSize = 4\r\n    }, scope = tfex.scope) {\r\n        class m {\r\n            constructor({\r\n                sequenceLen,\r\n                stateVectorLen,\r\n                layerNum = 32,\r\n                actionsNum = [3, 3, 4],\r\n                maxCoderSize = 4\r\n            }, scope = tfex.scope) {\r\n                this.sequenceLen = sequenceLen\r\n                this.stateVectorLen = stateVectorLen\r\n                this.layerNum = layerNum\r\n                this.actionsNum = actionsNum\r\n                this.scope = scope\r\n                this.weights = []\r\n\r\n                let inputSize = stateVectorLen\r\n                let outputSize = stateVectorLen * maxCoderSize\r\n                this.weights.push(scope.getVariable(`input_w`, [1, inputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                this.weights.push(scope.getVariable(`input_b`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n\r\n                this.weights.push(scope.getVariable(`sc_w0`, [1, outputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                this.weights.push(scope.getVariable(`sc_b0`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n\r\n                let coderNum = Math.ceil(layerNum / 4) * 2\r\n                for (let i = 1; i <= coderNum; i++) {\r\n                    inputSize = outputSize\r\n                    outputSize = (stateVectorLen / 2) * (i / coderNum) + stateVectorLen * maxCoderSize * (coderNum - i) / coderNum\r\n                    outputSize = Math.ceil(outputSize)\r\n                    this.weights.push(scope.getVariable(`ae_w${i}`, [Math.ceil(sequenceLen / (coderNum)) + 1, inputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`ae_b${i}`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n                    this.weights.push(scope.getVariable(`sc_w${i}`, [1, outputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`sc_b${i}`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n                }\r\n\r\n                inputSize = outputSize\r\n                this.weights.push(scope.getVariable(`ae_w${coderNum + 1}`, [Math.ceil(sequenceLen / (coderNum)) + 1, inputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                this.weights.push(scope.getVariable(`ae_b${coderNum + 1}`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n\r\n                for (let i = 1; i <= coderNum; i++) {\r\n                    outputSize = (stateVectorLen / 2) * ((coderNum - i) / coderNum) + stateVectorLen * maxCoderSize * i / coderNum\r\n                    outputSize = Math.ceil(outputSize)\r\n                    this.weights.push(scope.getVariable(`ae_b${coderNum + i + 1}`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n                }\r\n\r\n                {\r\n                    this.weights.push(scope.getVariable(`value_w1`, [1, sequenceLen, 1], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`value_b1`, [1, 1, 1], \"float32\", tf.initializers.zeros({})))\r\n\r\n                    this.weights.push(scope.getVariable(`value_w2`, [1, stateVectorLen * maxCoderSize, 1], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`value_b2`, [1, 1, 1], \"float32\", tf.initializers.zeros({})))\r\n                }\r\n\r\n                {\r\n                    this.weights.push(scope.getVariable(`A_w1`, [1, sequenceLen, 1], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`A_b1`, [1, 1, 1], \"float32\", tf.initializers.zeros({})))\r\n\r\n                    this.weights.push(scope.getVariable(`A_w2`, [1, stateVectorLen * maxCoderSize, actionsNum.reduce((prev, curr) => prev + curr, 0)], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`A_b2`, [1, 1, actionsNum.reduce((prev, curr) => prev + curr, 0)], \"float32\", tf.initializers.zeros({})))\r\n                }\r\n                // this.weights.forEach(w => w.sum().print())\r\n                console.log(this.scope.variables)\r\n            }\r\n\r\n            predict(x) {\r\n                return tf.tidy(() => {\r\n                    let jumperLayers = []\r\n                    let AELayer = tf.conv1d(\r\n                        x,\r\n                        this.scope.getVariable(`input_w`),\r\n                        1,\r\n                        \"same\"\r\n                    )\r\n                    AELayer = tf.add(AELayer, this.scope.getVariable(`input_b`))\r\n                    AELayer = tfex.funcs.mish(AELayer)\r\n                    jumperLayers.push(\r\n                        tfex.funcs.mish(\r\n                            tf.conv1d(\r\n                                AELayer,\r\n                                this.scope.getVariable(`sc_w0`),\r\n                                1,\r\n                                \"same\"\r\n                            ).add(this.scope.getVariable(`sc_b0`))\r\n                        )\r\n                    )\r\n\r\n                    let coderNum = Math.ceil(layerNum / 4) * 2\r\n                    for (let i = 1; i <= coderNum; i++) {\r\n                        AELayer = tf.conv1d(\r\n                            AELayer,\r\n                            this.scope.getVariable(`ae_w${i}`),\r\n                            1,\r\n                            \"same\"\r\n                        )\r\n                        AELayer = tf.add(AELayer, this.scope.getVariable(`ae_b${i}`))\r\n                        AELayer = tfex.funcs.mish(AELayer)\r\n                        jumperLayers.push(\r\n                            tfex.funcs.mish(\r\n                                tf.conv1d(\r\n                                    AELayer,\r\n                                    this.scope.getVariable(`sc_w${i}`),\r\n                                    1,\r\n                                    \"same\"\r\n                                ).add(this.scope.getVariable(`sc_b${i}`))\r\n                            )\r\n                        )\r\n                    }\r\n\r\n                    AELayer = tf.conv1d(\r\n                        AELayer,\r\n                        this.scope.getVariable(`ae_w${coderNum + 1}`),\r\n                        1,\r\n                        \"same\"\r\n                    )\r\n                    AELayer = tf.add(AELayer, this.scope.getVariable(`ae_b${coderNum + 1}`))\r\n                    AELayer = tfex.funcs.mish(AELayer)\r\n                    AELayer = tf.add(AELayer, jumperLayers.pop())\r\n\r\n                    for (let i = 0; i < coderNum; i++) {\r\n                        AELayer = tf.conv1d(\r\n                            AELayer,\r\n                            tf.transpose(\r\n                                this.scope.getVariable(`ae_w${coderNum - i}`),\r\n                                [0, 2, 1]\r\n                            ),\r\n                            1,\r\n                            \"same\"\r\n                        )\r\n                        AELayer = tf.add(AELayer, this.scope.getVariable(`ae_b${coderNum + i + 2}`))\r\n                        AELayer = tfex.funcs.mish(AELayer)\r\n                        AELayer = tf.add(AELayer, jumperLayers.pop())\r\n                    }\r\n\r\n                    let value = AELayer\r\n                    {\r\n                        value = tf.transpose(value, [0, 2, 1])\r\n                        value = tf.conv1d(\r\n                            value,\r\n                            this.scope.getVariable(`value_w1`),\r\n                            1, 0\r\n                        )\r\n                        value = tf.add(value, this.scope.getVariable(`value_b1`))\r\n\r\n                        value = tf.transpose(value, [0, 2, 1])\r\n                        value = tf.conv1d(\r\n                            value,\r\n                            this.scope.getVariable(`value_w2`),\r\n                            1, 0\r\n                        )\r\n                        value = tf.add(value, this.scope.getVariable(`value_b2`))\r\n                        value = tf.reshape(value, [-1, 1])\r\n                    }\r\n\r\n                    let A = AELayer\r\n\r\n                    {\r\n                        A = tf.transpose(A, [0, 2, 1])\r\n                        A = tf.conv1d(\r\n                            A,\r\n                            this.scope.getVariable(`A_w1`),\r\n                            1, 0\r\n                        )\r\n                        A = tf.add(A, this.scope.getVariable(`A_b1`))\r\n                        A = tf.transpose(A, [0, 2, 1])\r\n                        A = tf.conv1d(\r\n                            A,\r\n                            this.scope.getVariable(`A_w2`),\r\n                            1, 0\r\n                        )\r\n                        A = tf.add(A, this.scope.getVariable(`A_b2`))\r\n                        A = tf.reshape(A, [-1, this.actionsNum.reduce((prev, curr) => prev + curr, 0)])\r\n\r\n                        A = tf.sub(A, tf.mean(A, 1, true))\r\n                    }\r\n\r\n                    let Q = tf.add(value, A)\r\n\r\n                    let outputs\r\n                    if (this.actionsNum.length == 1) {\r\n                        outputs = Q\r\n                    } else {\r\n                        outputs = tf.split(Q, this.actionsNum, 1)\r\n                    }\r\n\r\n                    return outputs\r\n                })\r\n            }\r\n\r\n            getWeights() {\r\n                return this.weights\r\n            }\r\n\r\n            setWeights(weights) {\r\n                this.weights.forEach((w, idx) => w.assign(weights[idx]))\r\n            }\r\n        }\r\n\r\n        return new m({\r\n            sequenceLen,\r\n            stateVectorLen,\r\n            layerNum,\r\n            actionsNum,\r\n            maxCoderSize\r\n        }, scope)\r\n    }\r\n\r\n    tQandQ(batchPrevS, batchAs, batchRs, batchNextS, batchDiscount) {\r\n        return tf.tidy(() => {\r\n            let evalNet = this.model.predict(batchPrevS)\r\n            if (this.actionsNum.length == 1) {\r\n                evalNet = [evalNet]\r\n            }\r\n            const Qs = this.actionsNum.map((actionNum, actionType) => {\r\n                return tf.mul(\r\n                    tf.oneHot(\r\n                        batchAs[actionType],\r\n                        actionNum\r\n                    ),\r\n                    evalNet[actionType]\r\n                ).sum(1)\r\n            })\r\n\r\n            let predictions = this.model.predict(batchNextS)\r\n            if (this.actionsNum.length == 1) {\r\n                predictions = [predictions]\r\n            }\r\n            let targetPredictions = this.targetModel.predict(batchNextS)\r\n            if (this.actionsNum.length == 1) {\r\n                targetPredictions = [targetPredictions]\r\n            }\r\n            const targetQs = this.actionsNum.map((actionNum, actionType) => {\r\n                const maxQ = tf.mul(\r\n                    tf.oneHot(\r\n                        tf.argMax(\r\n                            predictions[actionType],\r\n                            1\r\n                        ),\r\n                        actionNum\r\n                    ),\r\n                    targetPredictions[actionType]\r\n                ).sum(1)\r\n                const targets = batchRs[actionType].add(maxQ.mul(batchDiscount));\r\n                return targets;\r\n            })\r\n            return [targetQs, Qs]\r\n        })\r\n    }\r\n\r\n    train(replayNum = 100, loadIdxes = [null], usePrioritizedReplay = false) {\r\n        tf.tidy(() => {\r\n            let train_ = (replayIdxes) => {\r\n                tf.tidy(() => {\r\n                    let replayIdxes_ = replayIdxes.slice()\r\n\r\n                    let arrayPrevS = []\r\n                    let arrayAs = new Array(this.actionsNum.length).fill([])\r\n                    let arrayRs = new Array(this.actionsNum.length).fill([])\r\n                    let arrayNextS = []\r\n                    let arrayDiscount = []\r\n\r\n                    for (let i = 0; i < replayNum; i++) {\r\n                        if (replayIdxes_[i] == null || replayIdxes_[i] >= this.memory.length) {\r\n                            replayIdxes_[i] = Math.floor(Math.random() * this.memory.length);\r\n                        }\r\n                        let data = this.memory[replayIdxes_[i]]\r\n                        // console.log(data)\r\n                        arrayPrevS.push(data.prevS)\r\n                        for (let j = 0; j < this.actionsNum.length; j++) {\r\n                            arrayAs[j][i] = data.As[j]\r\n                            arrayRs[j][i] = data.Rs[j]\r\n                        }\r\n                        arrayNextS.push(data.nextS)\r\n                        arrayDiscount.push(data.discount)\r\n                    }\r\n\r\n                    let batchPrevS = tf.tensor3d(arrayPrevS)\r\n                    let batchAs = arrayAs.map((arrayA) => {\r\n                        return tf.tensor1d(arrayA, 'int32')\r\n                    })\r\n                    let batchRs = arrayRs.map((arrayR) => {\r\n                        return tf.tensor1d(arrayR, 'float32')\r\n                    })\r\n                    let batchNextS = tf.tensor3d(arrayNextS)\r\n                    let batchDiscount = tf.tensor1d(arrayDiscount)\r\n\r\n                    let grads = this.optimizer.computeGradients(\r\n                        () => {\r\n                            let [targetQs, Qs] = this.tQandQ(\r\n                                batchPrevS,\r\n                                batchAs,\r\n                                batchRs,\r\n                                batchNextS,\r\n                                batchDiscount\r\n                            )\r\n                            let loss = tf.mean(\r\n                                tf.stack(\r\n                                    this.actionsNum.map((actionNum, actionType) => {\r\n                                        // return tf.losses.huberLoss(targetQs[actionType], Qs[actionType])\r\n                                        return tf.losses.meanSquaredError(targetQs[actionType], Qs[actionType])\r\n                                    })\r\n                                )\r\n                            )\r\n                            loss.print()\r\n                            return loss\r\n                        }, this.model.getWeights(true)).grads\r\n\r\n                    // let gradsName = Object.keys(grads)\r\n                    // grads = tfex.funcs.clipByGlobalNorm(Object.values(grads), 1)[0]\r\n\r\n                    // this.optimizer.applyGradients(gradsName.reduce((acc, gn, idx) => {\r\n                    //     acc[gn] = grads[idx]\r\n                    //     // if (gn == \"weighted_average_WeightedAverage1/w\") {\r\n                    //     //     acc[gn].print()\r\n                    //     // }\r\n                    //     return acc\r\n                    // }, {}))\r\n                    this.optimizer.applyGradients(grads)\r\n\r\n                    {\r\n                        let [targetQs, Qs] = this.tQandQ(\r\n                            batchPrevS,\r\n                            batchAs,\r\n                            batchRs,\r\n                            batchNextS,\r\n                            batchDiscount\r\n                        )\r\n                        tf.addN(\r\n                            this.actionsNum.map((actionNum, actionType) => {\r\n                                return tf.abs(tf.sub(targetQs[actionType], Qs[actionType]))\r\n                            })\r\n                        ).arraySync()\r\n                            .forEach((absTD, idx) => {\r\n                                this.memory[replayIdxes_[idx]].p = absTD\r\n                            })\r\n                    }\r\n\r\n                    this.count++\r\n\r\n                    this.optimizer.learningRate = Math.max(this.initLearningRate / (this.count ** 0.5), this.minLearningRate)\r\n\r\n                    if (this.updateTargetStep < 1) {\r\n                        this.targetModel.setWeights(\r\n                            this.targetModel.getWeights().map((weight, idx) => {\r\n                                return tf.add(\r\n                                    tf.mul(this.model.getWeights()[idx], this.updateTargetStep),\r\n                                    tf.mul(weight, 1 - this.updateTargetStep),\r\n                                )\r\n                            })\r\n                        )\r\n                    } else {\r\n                        if (this.count % Math.round(this.updateTargetStep) == 0) {\r\n                            this.targetModel.setWeights(this.model.getWeights())\r\n                        }\r\n                    }\r\n                })\r\n            }\r\n            if (this.memory.length != 0) {\r\n                if (usePrioritizedReplay) {\r\n                    let prioritizedReplayBuffer = tf.tidy(() => {\r\n                        let prioritys = tf.tensor(this.memory.map(mem => mem.p))\r\n                        prioritys = tf.div(prioritys, tf.sum(prioritys, 0, true))\r\n                        // prioritys.print()\r\n                        return tf.multinomial(prioritys, replayNum, null, true).arraySync()\r\n                    })\r\n                    // console.log(prioritizedReplayBuffer)\r\n                    train_(prioritizedReplayBuffer.map((prioritizedReplayIdx, idx) => {\r\n                        return loadIdxes[idx] == null || loadIdxes[idx] == undefined ? prioritizedReplayIdx : loadIdxes[idx]\r\n                    }))\r\n                } else {\r\n                    train_(loadIdxes)\r\n                }\r\n            }\r\n        })\r\n    }\r\n\r\n    store(preState, actions, rewards, nextState, discount) {\r\n        if (this.memory.length == this.memorySize) {\r\n            this.memory.pop()\r\n        }\r\n        this.memory.unshift({\r\n            prevS: preState,\r\n            As: actions,\r\n            Rs: rewards,\r\n            nextS: nextState,\r\n            discount: discount,\r\n            p: 1e+9\r\n        })\r\n    }\r\n\r\n    load(index) {\r\n        if (index == null || index >= this.memory.length) {\r\n            index = Math.floor(Math.random() * this.memory.length);\r\n        }\r\n        return this.memory[index]\r\n    }\r\n\r\n    updatePrioritys(bsz = 64) {\r\n\r\n        if (this.memory.length != 0) {\r\n            for (let begin = 0; begin < this.memory.length; begin += bsz) {\r\n                tf.tidy(() => {\r\n                    let arrayPrevS = []\r\n                    let arrayAs = new Array(this.actionsNum.length).fill([])\r\n                    let arrayRs = new Array(this.actionsNum.length).fill([])\r\n                    let arrayNextS = []\r\n                    let arrayDiscount = []\r\n\r\n                    for (let i = begin; i < Math.min(this.memory.length, begin + bsz); i++) {\r\n                        let data = this.memory[i]\r\n                        arrayPrevS.push(data.prevS)\r\n                        for (let j = 0; j < this.actionsNum.length; j++) {\r\n                            arrayAs[j][i - begin] = data.As[j]\r\n                            arrayRs[j][i - begin] = data.Rs[j]\r\n                        }\r\n                        arrayNextS.push(data.nextS)\r\n                        arrayDiscount.push(data.discount)\r\n                    }\r\n\r\n                    let batchPrevS = tf.tensor3d(arrayPrevS)\r\n                    let batchAs = arrayAs.map((arrayA) => {\r\n                        return tf.tensor1d(arrayA, 'int32')\r\n                    })\r\n                    let batchRs = arrayRs.map((arrayR) => {\r\n                        return tf.tensor1d(arrayR, 'float32')\r\n                    })\r\n                    let batchNextS = tf.tensor3d(arrayNextS)\r\n                    let batchDiscount = tf.tensor1d(arrayDiscount)\r\n\r\n                    let [targetQs, Qs] = this.tQandQ(\r\n                        batchPrevS,\r\n                        batchAs,\r\n                        batchRs,\r\n                        batchNextS,\r\n                        batchDiscount\r\n                    )\r\n                    tf.addN(\r\n                        this.actionsNum.map((actionNum, actionType) => {\r\n                            return tf.abs(tf.sub(targetQs[actionType], Qs[actionType]))\r\n                        })\r\n                    ).arraySync()\r\n                        .forEach((absTD, idx) => {\r\n                            this.memory[begin + idx].p = absTD\r\n                        })\r\n\r\n                })\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n\r\nexport function dddqn({\r\n    sequenceLen = 4,\r\n    stateVectorLen = 59,\r\n    layerNum = 8,\r\n    actionsNum = [2, 2, 2, 2, 2, 2, 2],\r\n    memorySize = 1000,\r\n    updateTargetStep = 0.05,\r\n    initLearningRate = 1e-3,\r\n    minLearningRate = 1e-5,\r\n    discount = 0.63,\r\n    maxCoderSize = 4\r\n}) {\r\n    return new DDDQN({\r\n        sequenceLen,\r\n        stateVectorLen,\r\n        layerNum,\r\n        actionsNum,\r\n        memorySize,\r\n        updateTargetStep,\r\n        initLearningRate,\r\n        minLearningRate,\r\n        discount,\r\n        maxCoderSize\r\n    })\r\n}","export * from './model'","import * as tf from \"@tensorflow/tfjs\"\r\nimport { dddqn } from \"../../src/js/MirageNet/dddqn10\"\r\nimport { registerTfex } from \"../../src/lib/tfjs-extensions/src\"\r\nconst tfex = registerTfex(tf)\r\nimport * as fs from \"fs\"\r\nlet initWeights = tfex.sl.load(fs.readFileSync(__dirname + \"/../w.bin\"))\r\n\r\ntf.enableProdMode()\r\n\r\nlet actionsNum = [128]\r\n\r\nlet dddqnModel = dddqn({\r\n    sequenceLen: 4,\r\n    stateVectorLen: 59,\r\n    layerNum: 64,\r\n    actionsNum: actionsNum,\r\n    memorySize: 8192,\r\n    minLearningRate: 1e-4,\r\n    initLearningRate: 1e-3,\r\n    updateTargetStep: 0.01,\r\n    discount: 0.8,\r\n    maxCoderSize: 4\r\n})\r\ndddqnModel.model.getWeights().forEach((w) => {\r\n    w.assign(initWeights[w.name])\r\n})\r\ndddqnModel.targetModel.setWeights(\r\n    dddqnModel.model.getWeights()\r\n)\r\n\r\nlet preArchives = {\r\n    \"player1\": {\r\n        state: null,\r\n        expired: true\r\n    },\r\n    \"player2\": {\r\n        state: null,\r\n        expired: true\r\n    }\r\n}\r\n\r\ntf.ready().then(() => {\r\n    let channel = self\r\n    channel.addEventListener(\"message\", (e) => {\r\n        tf.tidy(() => {\r\n            switch (e.data.instruction) {\r\n                case 'init':\r\n                    {\r\n                        channel.postMessage({ instruction: \"init\" })\r\n                        break\r\n                    }\r\n                case 'ctrl':\r\n                    {\r\n                        if (Object.keys(e.data.args.archives).length != 0) {\r\n                            let outputActions = dddqnModel\r\n                                .model\r\n                                .predict(\r\n                                    tf.tensor(\r\n                                        Object.values(e.data.args.archives)\r\n                                            .map(archive => {\r\n                                                return archive.state\r\n                                            })\r\n                                    )\r\n                                )\r\n                            if (actionsNum.length == 1) {\r\n                                outputActions = [outputActions]\r\n                            }\r\n                            outputActions = outputActions.map(outputAction => {\r\n                                outputAction = tf.softmax(outputAction, 1)\r\n                                if (e.data.args.CP) { //如果有補正機率就執行這段\r\n                                    outputAction = tf.div(\r\n                                        tf.add(\r\n                                            outputAction,\r\n                                            1 / outputAction.shape[1]\r\n                                        ),\r\n                                        2\r\n                                    )\r\n                                }\r\n                                return outputAction\r\n                            })\r\n\r\n                            let actions = {}\r\n                            let chooseByArgMax = tf.concat(\r\n                                outputActions.map((action) => {\r\n                                    return tf.argMax(action, 1).reshape([-1, 1])\r\n                                }), 1\r\n                            ).arraySync()\r\n\r\n                            let chooseByMultinomial = tf.concat(\r\n                                outputActions.map((action) => {\r\n                                    return tf.multinomial(action, 1, null, true)\r\n                                }), 1\r\n                            ).arraySync()\r\n\r\n                            Object.keys(e.data.args.archives)\r\n                                .forEach((playerName, idx) => {\r\n                                    if (Math.random() < e.data.args.archives[playerName].chooseActionRandomValue) {\r\n                                        actions[playerName] = chooseByMultinomial[idx]\r\n                                    } else {\r\n                                        actions[playerName] = chooseByArgMax[idx]\r\n                                    }\r\n                                })\r\n\r\n                            Object.keys(preArchives).forEach((playerName) => {\r\n                                if (Object.keys(e.data.args.archives).find(name => name === playerName) !== undefined) {\r\n                                    if (preArchives[playerName].expired == false) {\r\n                                        dddqnModel.store(\r\n                                            preArchives[playerName].state,\r\n                                            e.data.args.archives[playerName].actions,\r\n                                            e.data.args.archives[playerName].rewards,\r\n                                            e.data.args.archives[playerName].state,\r\n                                            e.data.args.archives[playerName].discount\r\n                                        )\r\n                                    }\r\n                                    preArchives[playerName].expired = false\r\n                                } else {\r\n                                    preArchives[playerName].expired = true\r\n                                }\r\n                            })\r\n\r\n                            Object.keys(e.data.args.archives).forEach((playerName, idx) => {\r\n                                preArchives[playerName].state = e.data.args.archives[playerName].state\r\n                            })\r\n                            channel.postMessage({\r\n                                instruction: \"ctrl\",\r\n                                args: {\r\n                                    archives: Object.keys(e.data.args.archives).reduce((acc, playerName) => {\r\n                                        acc[playerName] = {\r\n                                            actions: actions[playerName],\r\n                                            aiCtrl: e.data.args.archives[playerName].aiCtrl\r\n                                        }\r\n                                        return acc\r\n                                    }, {})\r\n                                }\r\n                            })\r\n                        } else {\r\n                            channel.postMessage({\r\n                                instruction: \"ctrl\",\r\n                                args: {\r\n                                    archive: {}\r\n                                }\r\n                            })\r\n                        }\r\n                        // console.log(\"ctrl\")\r\n                        break\r\n                    }\r\n                case 'train':\r\n                    {\r\n                        dddqnModel.train(e.data.args.bsz, e.data.args.replayIdxes, e.data.args.usePrioritizedReplay)\r\n                        channel.postMessage({ instruction: \"train\" })\r\n                        break\r\n                    }\r\n                case 'save':\r\n                    {\r\n                        tf.tidy(() => {\r\n                            let Ws = dddqnModel.model.getWeights()\r\n                            let tList = Ws.reduce((acc, w) => {\r\n                                acc[w.name] = w\r\n                                return acc\r\n                            }, {})\r\n                            channel.postMessage({\r\n                                instruction: \"save\",\r\n                                args: {\r\n                                    weightsBuffer: tfex.sl.save(tList)\r\n                                }\r\n                            })\r\n                        })\r\n\r\n                        break\r\n                    }\r\n                case 'load':\r\n                    {\r\n                        let loadWeights = tfex.sl.load(e.data.args.weightsBuffer)\r\n                        dddqnModel.model.getWeights().forEach((w) => {\r\n                            w.assign(loadWeights[w.name])\r\n                        })\r\n                        dddqnModel.targetModel.setWeights(\r\n                            dddqnModel.model.getWeights()\r\n                        )\r\n                        channel.postMessage({ instruction: \"load\" })\r\n                        break\r\n                    }\r\n                case \"updatePrioritys\":\r\n                    {\r\n                        dddqnModel.updatePrioritys()\r\n                        channel.postMessage({ instruction: \"updatePrioritys\" })\r\n                    }\r\n            }\r\n        })\r\n    })\r\n})"]}