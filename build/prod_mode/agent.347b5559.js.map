{"version":3,"sources":["../src/js/MirageNet/dddqn10/model.js","../src/js/MirageNet/dddqn10/index.js","js/agent.js"],"names":["tfex","tf","DDDQN","sequenceLen","stateVectorLen","layerNum","actionsNum","memorySize","updateTargetStep","initLearningRate","minLearningRate","maxCoderSize","count","model","buildModel","scope","variableScope","targetModel","setWeights","getWeights","memory","optimizer","train","adam","weights","inputSize","outputSize","push","getVariable","initializers","truncatedNormal","stddev","mean","zeros","coderNum","Math","ceil","i","reduce","prev","curr","console","log","variables","x","tidy","jumperLayers","AELayer","conv1d","add","funcs","mish","pop","transpose","value","reshape","A","sub","Q","outputs","length","split","forEach","w","idx","assign","batchPrevS","batchAs","batchRs","batchNextS","batchDiscount","evalNet","predict","Qs","map","actionNum","actionType","mul","oneHot","sum","predictions","targetPredictions","maxQ","argMax","targets","replayNum","loadIdxes","usePrioritizedReplay","train_","replayIdxes","replayIdxes_","slice","arrayPrevS","arrayAs","Array","fill","arrayRs","arrayNextS","arrayDiscount","floor","random","data","prevS","j","As","Rs","nextS","discount","tensor3d","arrayA","tensor1d","arrayR","grads","computeGradients","tQandQ","targetQs","loss","stack","losses","meanSquaredError","print","applyGradients","addN","abs","arraySync","absTD","p","learningRate","max","weight","round","prioritys","tensor","mem","div","multinomial","prioritizedReplayIdx","undefined","preState","actions","rewards","nextState","unshift","index","bsz","begin","min","dddqn","initWeights","sl","load","enableProdMode","dddqnModel","name","preArchives","state","expired","ready","then","channel","self","addEventListener","e","instruction","postMessage","Object","keys","args","archives","outputActions","values","archive","outputAction","softmax","CP","shape","chooseByArgMax","concat","action","chooseByMultinomial","playerName","chooseActionRandomValue","find","store","acc","aiCtrl","Ws","tList","weightsBuffer","save","loadWeights","updatePrioritys"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0hBC,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,MAAA,EAAA,QAAA,WAAA,EA1hBD,IAAA,EAAA,EAAA,QAAA,qBACA,EAAA,QAAA,oCAyhBC,SAAA,IAAA,GAAA,mBAAA,QAAA,OAAA,KAAA,IAAA,EAAA,IAAA,QAAA,OAAA,EAAA,WAAA,OAAA,GAAA,EAAA,SAAA,EAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,IAAA,GAAA,GAAA,EAAA,IAAA,GAAA,OAAA,EAAA,IAAA,GAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,CAAA,IAAA,EAAA,OAAA,gBAAA,OAAA,yBAAA,IAAA,IAAA,KAAA,EAAA,GAAA,OAAA,UAAA,eAAA,KAAA,EAAA,GAAA,CAAA,IAAA,EAAA,EAAA,OAAA,yBAAA,EAAA,GAAA,KAAA,IAAA,EAAA,KAAA,EAAA,KAAA,OAAA,eAAA,EAAA,EAAA,GAAA,EAAA,GAAA,EAAA,IAAA,OAAA,EAAA,QAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EAAA,SAAA,EAAA,EAAA,GAAA,OAAA,EAAA,IAAA,EAAA,EAAA,IAAA,IAAA,SAAA,IAAA,MAAA,IAAA,UAAA,wDAAA,SAAA,EAAA,EAAA,GAAA,GAAA,OAAA,YAAA,OAAA,IAAA,uBAAA,OAAA,UAAA,SAAA,KAAA,GAAA,CAAA,IAAA,EAAA,GAAA,GAAA,EAAA,GAAA,EAAA,OAAA,EAAA,IAAA,IAAA,IAAA,EAAA,EAAA,EAAA,OAAA,cAAA,GAAA,EAAA,EAAA,QAAA,QAAA,EAAA,KAAA,EAAA,QAAA,GAAA,EAAA,SAAA,GAAA,GAAA,IAAA,MAAA,GAAA,GAAA,EAAA,EAAA,EAAA,QAAA,IAAA,GAAA,MAAA,EAAA,QAAA,EAAA,SAAA,QAAA,GAAA,EAAA,MAAA,GAAA,OAAA,GAAA,SAAA,EAAA,GAAA,GAAA,MAAA,QAAA,GAAA,OAAA,EAAA,SAAA,EAAA,EAAA,GAAA,KAAA,aAAA,GAAA,MAAA,IAAA,UAAA,qCAAA,SAAA,EAAA,EAAA,GAAA,IAAA,IAAA,EAAA,EAAA,EAAA,EAAA,OAAA,IAAA,CAAA,IAAA,EAAA,EAAA,GAAA,EAAA,WAAA,EAAA,aAAA,EAAA,EAAA,cAAA,EAAA,UAAA,IAAA,EAAA,UAAA,GAAA,OAAA,eAAA,EAAA,EAAA,IAAA,IAAA,SAAA,EAAA,EAAA,EAAA,GAAA,OAAA,GAAA,EAAA,EAAA,UAAA,GAAA,GAAA,EAAA,EAAA,GAAA,EAxhBD,IAAMA,GAAO,EAAaC,EAAAA,cAAAA,GAEbC,EAshBZ,WA3gBM,SAAA,EAAA,GATCC,IAAAA,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,EASf,EARCC,EAAAA,EAAAA,eAAAA,OAAiB,IAAA,EAAA,GAQlB,EAPCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,EAOZ,EANCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAMjC,EALCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,IAKd,EAJCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,IAIpB,EAHCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,KAGpB,EAFCC,EAAAA,EAAAA,gBAAAA,OAAkB,IAAA,EAAA,KAEnB,EADCC,EAAAA,EAAAA,aAAAA,OAAe,IAAA,EAAA,EAChB,EAAA,EAAA,KAAA,GAGUH,KAAAA,iBAAmBA,EAEnBI,KAAAA,MAAQ,EAERN,KAAAA,WAAaA,EAIbO,KAAAA,MAAQ,KAAKC,WAAW,CACzBX,YAAaA,EACbC,eAAgBA,EAChBC,SAAUA,EACVC,WAAYA,EACZK,aAAcA,GACfX,EAAKe,MAAMC,cAAc,SAGvBC,KAAAA,YAAc,KAAKH,WAAW,CAC/BX,YAAaA,EACbC,eAAgBA,EAChBC,SAAUA,EACVC,WAAYA,EACZK,aAAcA,GACfX,EAAKe,MAAMC,cAAc,WAEvBC,KAAAA,YAAYC,WAAW,KAAKL,MAAMM,cAIlCZ,KAAAA,WAAaA,EACba,KAAAA,OAAS,GAITV,KAAAA,gBAAkBA,EAClBD,KAAAA,iBAAmBA,EACnBY,KAAAA,UAAYpB,EAAGqB,MAAMC,KAAK,KAAKd,kBAoe/C,OAAA,EAAA,EAAA,CAAA,CAAA,IAAA,aAzd0B,MAAA,SAAA,GALnBN,IAAAA,EAAAA,EAAAA,YACAC,EAAAA,EAAAA,eACAC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,GAGQ,EAFnBC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,CAAC,EAAG,EAAG,GAED,EADnBK,EAAAA,EAAAA,aAAAA,OAAe,IAAA,EAAA,EACI,EAApBI,EAAQf,UAAAA,OAAAA,QAAAA,IAAAA,UAAAA,GAAAA,UAAAA,GAAAA,EAAKe,MAqML,OAAA,IArMY,WAQQ,SAAA,EAAA,GALnBZ,IAAAA,EAAAA,EAAAA,YACAC,EAAAA,EAAAA,eACAC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,GAGQ,EAFnBC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,CAAC,EAAG,EAAG,GAED,EADnBK,EAAAA,EAAAA,aAAAA,OAAe,IAAA,EAAA,EACI,EAApBI,EAAQf,UAAAA,OAAAA,QAAAA,IAAAA,UAAAA,GAAAA,UAAAA,GAAAA,EAAKe,MAAO,EAAA,KAAA,GACdZ,KAAAA,YAAcA,EACdC,KAAAA,eAAiBA,EACjBC,KAAAA,SAAWA,EACXC,KAAAA,WAAaA,EACbS,KAAAA,MAAQA,EACRS,KAAAA,QAAU,GAEXC,IAAAA,EAAYrB,EACZsB,EAAatB,EAAiBO,EAC7Ba,KAAAA,QAAQG,KAAKZ,EAAMa,YAAuB,UAAA,CAAC,EAAGH,EAAWC,GAAa,UAAWzB,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MACtIR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAuB,UAAA,CAAC,EAAG,EAAGF,GAAa,UAAWzB,EAAG4B,aAAaI,MAAM,MAE/FT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAqB,QAAA,CAAC,EAAGF,EAAYA,GAAa,UAAWzB,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MACrIR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAqB,QAAA,CAAC,EAAG,EAAGF,GAAa,UAAWzB,EAAG4B,aAAaI,MAAM,MAG7F,IADDC,IAAAA,EAAqC,EAA1BC,KAAKC,KAAK/B,EAAW,GAC3BgC,EAAI,EAAGA,GAAKH,EAAUG,IAC3BZ,EAAYC,EACZA,EAActB,EAAiB,GAAMiC,EAAIH,GAAY9B,EAAiBO,GAAgBuB,EAAWG,GAAKH,EACtGR,EAAaS,KAAKC,KAAKV,GAClBF,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBS,OAAAA,OAAAA,GAAK,CAACF,KAAKC,KAAKjC,EAAe+B,GAAa,EAAGT,EAAWC,GAAa,UAAWzB,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAC7KR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBS,OAAAA,OAAAA,GAAK,CAAC,EAAG,EAAGX,GAAa,UAAWzB,EAAG4B,aAAaI,MAAM,MAChGT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBS,OAAAA,OAAAA,GAAK,CAAC,EAAGX,EAAYA,GAAa,UAAWzB,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MACxIR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBS,OAAAA,OAAAA,GAAK,CAAC,EAAG,EAAGX,GAAa,UAAWzB,EAAG4B,aAAaI,MAAM,MAGzGR,EAAYC,EACPF,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBM,OAAAA,OAAAA,EAAW,GAAK,CAACC,KAAKC,KAAKjC,EAAe+B,GAAa,EAAGT,EAAWC,GAAa,UAAWzB,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MACxLR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBM,OAAAA,OAAAA,EAAW,GAAK,CAAC,EAAG,EAAGR,GAAa,UAAWzB,EAAG4B,aAAaI,MAAM,MAE3G,IAAA,IAAII,EAAI,EAAGA,GAAKH,EAAUG,IAC3BX,EAActB,EAAiB,IAAO8B,EAAWG,GAAKH,GAAY9B,EAAiBO,EAAe0B,EAAIH,EACtGR,EAAaS,KAAKC,KAAKV,GAClBF,KAAAA,QAAQG,KAAKZ,EAAMa,YAAmBM,OAAAA,OAAAA,EAAWG,EAAI,GAAK,CAAC,EAAG,EAAGX,GAAa,UAAWzB,EAAG4B,aAAaI,MAAM,MAI/GT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAwB,WAAA,CAAC,EAAGzB,EAAa,GAAI,UAAWF,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAChIR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAwB,WAAA,CAAC,EAAG,EAAG,GAAI,UAAW3B,EAAG4B,aAAaI,MAAM,MAEvFT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAwB,WAAA,CAAC,EAAGxB,EAAiBO,EAAc,GAAI,UAAWV,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAClJR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAwB,WAAA,CAAC,EAAG,EAAG,GAAI,UAAW3B,EAAG4B,aAAaI,MAAM,MAIvFT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAoB,OAAA,CAAC,EAAGzB,EAAa,GAAI,UAAWF,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAC5HR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAoB,OAAA,CAAC,EAAG,EAAG,GAAI,UAAW3B,EAAG4B,aAAaI,MAAM,MAEnFT,KAAAA,QAAQG,KAAKZ,EAAMa,YAAoB,OAAA,CAAC,EAAGxB,EAAiBO,EAAcL,EAAWgC,OAAO,SAACC,EAAMC,GAASD,OAAAA,EAAOC,GAAM,IAAK,UAAWvC,EAAG4B,aAAaC,gBAAgB,CAAEC,OAAQ,GAAKC,KAAM,MAC9LR,KAAAA,QAAQG,KAAKZ,EAAMa,YAAoB,OAAA,CAAC,EAAG,EAAGtB,EAAWgC,OAAO,SAACC,EAAMC,GAASD,OAAAA,EAAOC,GAAM,IAAK,UAAWvC,EAAG4B,aAAaI,MAAM,MAG5IQ,QAAQC,IAAI,KAAK3B,MAAM4B,WA7DZ,OAAA,EAAA,EAAA,CAAA,CAAA,IAAA,UAgEPC,MAAAA,SAAAA,GAAG,IAAA,EAAA,KACA3C,OAAAA,EAAG4C,KAAK,WACPC,IAAAA,EAAe,GACfC,EAAU9C,EAAG+C,OACbJ,EACA,EAAK7B,MAAMa,YAFD,WAGV,EACA,QAEJmB,EAAU9C,EAAGgD,IAAIF,EAAS,EAAKhC,MAAMa,YAA3B,YACVmB,EAAU/C,EAAKkD,MAAMC,KAAKJ,GAC1BD,EAAanB,KACT3B,EAAKkD,MAAMC,KACPlD,EAAG+C,OACCD,EACA,EAAKhC,MAAMa,YAFf,SAGI,EACA,QACFqB,IAAI,EAAKlC,MAAMa,YALjB,YAUH,IADDM,IAAAA,EAAqC,EAA1BC,KAAKC,KAAK/B,EAAW,GAC3BgC,EAAI,EAAGA,GAAKH,EAAUG,IAC3BU,EAAU9C,EAAG+C,OACTD,EACA,EAAKhC,MAAMa,YAAmBS,OAAAA,OAAAA,IAC9B,EACA,QAEJU,EAAU9C,EAAGgD,IAAIF,EAAS,EAAKhC,MAAMa,YAAmBS,OAAAA,OAAAA,KACxDU,EAAU/C,EAAKkD,MAAMC,KAAKJ,GAC1BD,EAAanB,KACT3B,EAAKkD,MAAMC,KACPlD,EAAG+C,OACCD,EACA,EAAKhC,MAAMa,YAAmBS,OAAAA,OAAAA,IAC9B,EACA,QACFY,IAAI,EAAKlC,MAAMa,YAAmBS,OAAAA,OAAAA,OAKhDU,EAAU9C,EAAG+C,OACTD,EACA,EAAKhC,MAAMa,YAAmBM,OAAAA,OAAAA,EAAW,IACzC,EACA,QAEJa,EAAU9C,EAAGgD,IAAIF,EAAS,EAAKhC,MAAMa,YAAmBM,OAAAA,OAAAA,EAAW,KACnEa,EAAU/C,EAAKkD,MAAMC,KAAKJ,GAC1BA,EAAU9C,EAAGgD,IAAIF,EAASD,EAAaM,OAElC,IAAA,IAAIf,EAAI,EAAGA,EAAIH,EAAUG,IAC1BU,EAAU9C,EAAG+C,OACTD,EACA9C,EAAGoD,UACC,EAAKtC,MAAMa,YAAmBM,OAAAA,OAAAA,EAAWG,IACzC,CAAC,EAAG,EAAG,IAEX,EACA,QAEJU,EAAU9C,EAAGgD,IAAIF,EAAS,EAAKhC,MAAMa,YAAmBM,OAAAA,OAAAA,EAAWG,EAAI,KACvEU,EAAU/C,EAAKkD,MAAMC,KAAKJ,GAC1BA,EAAU9C,EAAGgD,IAAIF,EAASD,EAAaM,OAGvCE,IAAAA,EAAQP,EAERO,EAAQrD,EAAGoD,UAAUC,EAAO,CAAC,EAAG,EAAG,IACnCA,EAAQrD,EAAG+C,OACPM,EACA,EAAKvC,MAAMa,YAFP,YAGJ,EAAG,GAEP0B,EAAQrD,EAAGgD,IAAIK,EAAO,EAAKvC,MAAMa,YAAzB,aAER0B,EAAQrD,EAAGoD,UAAUC,EAAO,CAAC,EAAG,EAAG,IACnCA,EAAQrD,EAAG+C,OACPM,EACA,EAAKvC,MAAMa,YAFP,YAGJ,EAAG,GAEP0B,EAAQrD,EAAGgD,IAAIK,EAAO,EAAKvC,MAAMa,YAAzB,aACR0B,EAAQrD,EAAGsD,QAAQD,EAAO,EAAE,EAAG,IAG/BE,IAAAA,EAAIT,EAGJS,EAAIvD,EAAGoD,UAAUG,EAAG,CAAC,EAAG,EAAG,IAC3BA,EAAIvD,EAAG+C,OACHQ,EACA,EAAKzC,MAAMa,YAFX,QAGA,EAAG,GAEP4B,EAAIvD,EAAGgD,IAAIO,EAAG,EAAKzC,MAAMa,YAArB,SACJ4B,EAAIvD,EAAGoD,UAAUG,EAAG,CAAC,EAAG,EAAG,IAC3BA,EAAIvD,EAAG+C,OACHQ,EACA,EAAKzC,MAAMa,YAFX,QAGA,EAAG,GAEP4B,EAAIvD,EAAGgD,IAAIO,EAAG,EAAKzC,MAAMa,YAArB,SACJ4B,EAAIvD,EAAGsD,QAAQC,EAAG,EAAE,EAAG,EAAKlD,WAAWgC,OAAO,SAACC,EAAMC,GAASD,OAAAA,EAAOC,GAAM,KAE3EgB,EAAIvD,EAAGwD,IAAID,EAAGvD,EAAG+B,KAAKwB,EAAG,GAAG,IAG5BE,IAAAA,EAAIzD,EAAGgD,IAAIK,EAAOE,GASfG,OANuB,GAA1B,EAAKrD,WAAWsD,OACNF,EAEAzD,EAAG4D,MAAMH,EAAG,EAAKpD,WAAY,OArLpC,CAAA,IAAA,aA4LF,MAAA,WACF,OAAA,KAAKkB,UA7LD,CAAA,IAAA,aAgMJA,MAAAA,SAAAA,GACFA,KAAAA,QAAQsC,QAAQ,SAACC,EAAGC,GAAQD,OAAAA,EAAEE,OAAOzC,EAAQwC,UAjMvC,EAAA,GAqMZ,CAAM,CACT7D,YAAAA,EACAC,eAAAA,EACAC,SAAAA,EACAC,WAAAA,EACAK,aAAAA,GACDI,KA8QV,CAAA,IAAA,SA3QUmD,MAAAA,SAAAA,EAAYC,EAASC,EAASC,EAAYC,GAAe,IAAA,EAAA,KACrDrE,OAAAA,EAAG4C,KAAK,WACP0B,IAAAA,EAAU,EAAK1D,MAAM2D,QAAQN,GACH,GAA1B,EAAK5D,WAAWsD,SAChBW,EAAU,CAACA,IAETE,IAAAA,EAAK,EAAKnE,WAAWoE,IAAI,SAACC,EAAWC,GAChC3E,OAAAA,EAAG4E,IACN5E,EAAG6E,OACCX,EAAQS,GACRD,GAEJJ,EAAQK,IACVG,IAAI,KAGNC,EAAc,EAAKnE,MAAM2D,QAAQH,GACP,GAA1B,EAAK/D,WAAWsD,SAChBoB,EAAc,CAACA,IAEfC,IAAAA,EAAoB,EAAKhE,YAAYuD,QAAQH,GAkB1C,OAjBuB,GAA1B,EAAK/D,WAAWsD,SAChBqB,EAAoB,CAACA,IAgBlB,CAdU,EAAK3E,WAAWoE,IAAI,SAACC,EAAWC,GACvCM,IAAAA,EAAOjF,EAAG4E,IACZ5E,EAAG6E,OACC7E,EAAGkF,OACCH,EAAYJ,GACZ,GAEJD,GAEJM,EAAkBL,IACpBG,IAAI,GAECK,OADShB,EAAQQ,GAAY3B,IAAIiC,EAAKL,IAAIP,MAGnCG,OAqO7B,CAAA,IAAA,QAjO4E,MAAA,WAAA,IAAA,EAAA,KAAnEY,EAAY,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,IAAKC,EAAY,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,CAAC,MAAOC,EAAuB,UAAA,OAAA,QAAA,IAAA,UAAA,IAAA,UAAA,GAC9DtF,EAAG4C,KAAK,WACA2C,IAAAA,EAAS,SAACC,GACVxF,EAAG4C,KAAK,WASC,IARD6C,IAAAA,EAAeD,EAAYE,QAE3BC,EAAa,GACbC,EAAU,IAAIC,MAAM,EAAKxF,WAAWsD,QAAQmC,KAAK,IACjDC,EAAU,IAAIF,MAAM,EAAKxF,WAAWsD,QAAQmC,KAAK,IACjDE,EAAa,GACbC,EAAgB,GAEX7D,EAAI,EAAGA,EAAIgD,EAAWhD,IAAK,EACT,MAAnBqD,EAAarD,IAAcqD,EAAarD,IAAM,EAAKjB,OAAOwC,UAC1D8B,EAAarD,GAAKF,KAAKgE,MAAMhE,KAAKiE,SAAW,EAAKhF,OAAOwC,SAEzDyC,IAAAA,EAAO,EAAKjF,OAAOsE,EAAarD,IAEpCuD,EAAWjE,KAAK0E,EAAKC,OAChB,IAAA,IAAIC,EAAI,EAAGA,EAAI,EAAKjG,WAAWsD,OAAQ2C,IACxCV,EAAQU,GAAGlE,GAAKgE,EAAKG,GAAGD,GACxBP,EAAQO,GAAGlE,GAAKgE,EAAKI,GAAGF,GAE5BN,EAAWtE,KAAK0E,EAAKK,OACrBR,EAAcvE,KAAK0E,EAAKM,UAGxBzC,IAAAA,EAAajE,EAAG2G,SAAShB,GACzBzB,EAAU0B,EAAQnB,IAAI,SAACmC,GAChB5G,OAAAA,EAAG6G,SAASD,EAAQ,WAE3BzC,EAAU4B,EAAQtB,IAAI,SAACqC,GAChB9G,OAAAA,EAAG6G,SAASC,EAAQ,aAE3B1C,EAAapE,EAAG2G,SAASX,GACzB3B,EAAgBrE,EAAG6G,SAASZ,GAE5Bc,EAAQ,EAAK3F,UAAU4F,iBACvB,WACyB,IADnB,EAAA,EACmB,EAAKC,OACtBhD,EACAC,EACAC,EACAC,EACAC,GANF,GACG6C,EADH,EAAA,GACa1C,EADb,EAAA,GAQE2C,EAAOnH,EAAG+B,KACV/B,EAAGoH,MACC,EAAK/G,WAAWoE,IAAI,SAACC,EAAWC,GAErB3E,OAAAA,EAAGqH,OAAOC,iBAAiBJ,EAASvC,GAAaH,EAAGG,QAKhEwC,OADPA,EAAKI,QACEJ,GACR,EAAKvG,MAAMM,YAAW,IAAO6F,MAYpC,EAAK3F,UAAUoG,eAAeT,GAGL,IADzB,EAAA,EACyB,EAAKE,OACtBhD,EACAC,EACAC,EACAC,EACAC,GANR,GACS6C,EADT,EAAA,GACmB1C,EADnB,EAAA,GAQIxE,EAAGyH,KACC,EAAKpH,WAAWoE,IAAI,SAACC,EAAWC,GACrB3E,OAAAA,EAAG0H,IAAI1H,EAAGwD,IAAI0D,EAASvC,GAAaH,EAAGG,QAEpDgD,YACG9D,QAAQ,SAAC+D,EAAO7D,GACb,EAAK5C,OAAOsE,EAAa1B,IAAM8D,EAAID,IAI/C,EAAKjH,QAEL,EAAKS,UAAU0G,aAAe5F,KAAK6F,IAAI,EAAKvH,iBAAoB,KAAA,IAAA,EAAKG,MAAS,IAAM,EAAKF,iBAErF,EAAKF,iBAAmB,EACxB,EAAKS,YAAYC,WACb,EAAKD,YAAYE,aAAauD,IAAI,SAACuD,EAAQjE,GAChC/D,OAAAA,EAAGgD,IACNhD,EAAG4E,IAAI,EAAKhE,MAAMM,aAAa6C,GAAM,EAAKxD,kBAC1CP,EAAG4E,IAAIoD,EAAQ,EAAI,EAAKzH,sBAKhC,EAAKI,MAAQuB,KAAK+F,MAAM,EAAK1H,mBAAqB,GAClD,EAAKS,YAAYC,WAAW,EAAKL,MAAMM,iBAK7B,GAAtB,EAAKC,OAAOwC,QASR4B,EARAD,EAC8BtF,EAAG4C,KAAK,WAC9BsF,IAAAA,EAAYlI,EAAGmI,OAAO,EAAKhH,OAAOsD,IAAI,SAAA2D,GAAOA,OAAAA,EAAIP,KAG9C7H,OAFPkI,EAAYlI,EAAGqI,IAAIH,EAAWlI,EAAG8E,IAAIoD,EAAW,GAAG,IAE5ClI,EAAGsI,YAAYJ,EAAW9C,EAAW,MAAM,GAAMuC,cAG7BlD,IAAI,SAAC8D,EAAsBxE,GAC/CsB,OAAkB,MAAlBA,EAAUtB,IAAkCyE,MAAlBnD,EAAUtB,GAAoBwE,EAAuBlD,EAAUtB,KAG7FsB,OAwG1B,CAAA,IAAA,QAlGSoD,MAAAA,SAAAA,EAAUC,EAASC,EAASC,EAAWlC,GACrC,KAAKvF,OAAOwC,QAAU,KAAKrD,YACtBa,KAAAA,OAAOgC,MAEXhC,KAAAA,OAAO0H,QAAQ,CAChBxC,MAAOoC,EACPlC,GAAImC,EACJlC,GAAImC,EACJlC,MAAOmC,EACPlC,SAAUA,EACVmB,EAAG,QAwFd,CAAA,IAAA,OApFQiB,MAAAA,SAAAA,GAIM,OAHM,MAATA,GAAiBA,GAAS,KAAK3H,OAAOwC,UACtCmF,EAAQ5G,KAAKgE,MAAMhE,KAAKiE,SAAW,KAAKhF,OAAOwC,SAE5C,KAAKxC,OAAO2H,KAgF1B,CAAA,IAAA,kBA7E6B,MAAA,WAAA,IAAA,EAAA,KAAVC,EAAM,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,GAEd,GAAsB,GAAtB,KAAK5H,OAAOwC,OACP,IAAIqF,IAAAA,EAAAA,SAAAA,GACLhJ,EAAG4C,KAAK,WAOC,IAND+C,IAAAA,EAAa,GACbC,EAAU,IAAIC,MAAM,EAAKxF,WAAWsD,QAAQmC,KAAK,IACjDC,EAAU,IAAIF,MAAM,EAAKxF,WAAWsD,QAAQmC,KAAK,IACjDE,EAAa,GACbC,EAAgB,GAEX7D,EAAI4G,EAAO5G,EAAIF,KAAK+G,IAAI,EAAK9H,OAAOwC,OAAQqF,EAAQD,GAAM3G,IAAK,CAChEgE,IAAAA,EAAO,EAAKjF,OAAOiB,GACvBuD,EAAWjE,KAAK0E,EAAKC,OAChB,IAAA,IAAIC,EAAI,EAAGA,EAAI,EAAKjG,WAAWsD,OAAQ2C,IACxCV,EAAQU,GAAGlE,EAAI4G,GAAS5C,EAAKG,GAAGD,GAChCP,EAAQO,GAAGlE,EAAI4G,GAAS5C,EAAKI,GAAGF,GAEpCN,EAAWtE,KAAK0E,EAAKK,OACrBR,EAAcvE,KAAK0E,EAAKM,UAGxBzC,IAAAA,EAAajE,EAAG2G,SAAShB,GACzBzB,EAAU0B,EAAQnB,IAAI,SAACmC,GAChB5G,OAAAA,EAAG6G,SAASD,EAAQ,WAE3BzC,EAAU4B,EAAQtB,IAAI,SAACqC,GAChB9G,OAAAA,EAAG6G,SAASC,EAAQ,aAE3B1C,EAAapE,EAAG2G,SAASX,GACzB3B,EAAgBrE,EAAG6G,SAASZ,GA1BtB,EAAA,EA4BW,EAAKgB,OACtBhD,EACAC,EACAC,EACAC,EACAC,GAjCM,GA4BL6C,EA5BK,EAAA,GA4BK1C,EA5BL,EAAA,GAmCVxE,EAAGyH,KACC,EAAKpH,WAAWoE,IAAI,SAACC,EAAWC,GACrB3E,OAAAA,EAAG0H,IAAI1H,EAAGwD,IAAI0D,EAASvC,GAAaH,EAAGG,QAEpDgD,YACG9D,QAAQ,SAAC+D,EAAO7D,GACb,EAAK5C,OAAO6H,EAAQjF,GAAK8D,EAAID,OA1CpCoB,EAAQ,EAAGA,EAAQ,KAAK7H,OAAOwC,OAAQqF,GAASD,EAAhDC,EAAAA,OA0EpB,EAAA,GAtBM,SAASE,EAUb,GATChJ,IAAAA,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,EASf,EARCC,EAAAA,EAAAA,eAAAA,OAAiB,IAAA,EAAA,GAQlB,EAPCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,EAOZ,EANCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAMjC,EALCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,IAKd,EAJCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,IAIpB,EAHCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,KAGpB,EAFCC,EAAAA,EAAAA,gBAAAA,OAAkB,IAAA,EAAA,KAEnB,EADCC,EAAAA,EAAAA,aAEO,OAAA,IAAIT,EAAM,CACbC,YAAAA,EACAC,eAAAA,EACAC,SAAAA,EACAC,WAAAA,EACAC,WAAAA,EACAC,iBAAAA,EACAC,iBAAAA,EACAC,gBAAAA,EACAC,kBAXW,IAAA,EAAA,EAChB,IAYF,QAAA,MAAA;;AC1hBD,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,IAAA,EAAA,QAAA,WAAA,OAAA,KAAA,GAAA,QAAA,SAAA,GAAA,YAAA,GAAA,eAAA,GAAA,OAAA,eAAA,QAAA,EAAA,CAAA,YAAA,EAAA,IAAA,WAAA,OAAA,EAAA;;;ACwCA,IAAA,EAAA,QAAA,UAAA,OAxCA,EAAA,EAAA,QAAA,qBACA,EAAA,QAAA,kCACA,EAAA,QAAA,qCAEA,EAAA,EAAA,QAAA,OAoCA,SAAA,IAAA,GAAA,mBAAA,QAAA,OAAA,KAAA,IAAA,EAAA,IAAA,QAAA,OAAA,EAAA,WAAA,OAAA,GAAA,EAAA,SAAA,EAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,IAAA,GAAA,GAAA,EAAA,IAAA,GAAA,OAAA,EAAA,IAAA,GAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,CAAA,IAAA,EAAA,OAAA,gBAAA,OAAA,yBAAA,IAAA,IAAA,KAAA,EAAA,GAAA,OAAA,UAAA,eAAA,KAAA,EAAA,GAAA,CAAA,IAAA,EAAA,EAAA,OAAA,yBAAA,EAAA,GAAA,KAAA,IAAA,EAAA,KAAA,EAAA,KAAA,OAAA,eAAA,EAAA,EAAA,GAAA,EAAA,GAAA,EAAA,IAAA,OAAA,EAAA,QAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EArCA,IAAMX,GAAO,EAAaC,EAAAA,cAAAA,GAEtBmJ,EAAcpJ,EAAKqJ,GAAGC,KAA1B,EAAA,2rmtrBAAA,WAEArJ,EAAGsJ,iBAEH,IAAIjJ,EAAa,CAAC,KAEdkJ,GAAa,EAAM,EAAA,OAAA,CACnBrJ,YAAa,EACbC,eAAgB,GAChBC,SAAU,GACVC,WAAYA,EACZC,WAAY,KACZG,gBAAiB,KACjBD,iBAAkB,KAClBD,iBAAkB,IAClBG,aAAc,IAElB6I,EAAW3I,MAAMM,aAAa2C,QAAQ,SAACC,GACnCA,EAAEE,OAAOmF,EAAYrF,EAAE0F,SAE3BD,EAAWvI,YAAYC,WACnBsI,EAAW3I,MAAMM,cAGrB,IAAIuI,EAAc,CACH,QAAA,CACPC,MAAO,KACPC,SAAS,GAEF,QAAA,CACPD,MAAO,KACPC,SAAS,IAIjB3J,EAAG4J,QAAQC,KAAK,WACRC,IAAAA,EAAUC,KACdD,EAAQE,iBAAiB,UAAW,SAACC,GACjCjK,EAAG4C,KAAK,WACIqH,OAAAA,EAAE7D,KAAK8D,aACN,IAAA,OAEGJ,EAAQK,YAAY,CAAED,YAAa,SACnC,MAEH,IAAA,OAEOE,GAA4C,GAA5CA,OAAOC,KAAKJ,EAAE7D,KAAKkE,KAAKC,UAAU5G,OAAa,CAC3C6G,IAAAA,EAAgBjB,EACf3I,MACA2D,QACGvE,EAAGmI,OACCiC,OAAOK,OAAOR,EAAE7D,KAAKkE,KAAKC,UACrB9F,IAAI,SAAAiG,GACMA,OAAAA,EAAQhB,UAIV,GAArBrJ,EAAWsD,SACX6G,EAAgB,CAACA,IAErBA,EAAgBA,EAAc/F,IAAI,SAAAkG,GAWvBA,OAVPA,EAAe3K,EAAG4K,QAAQD,EAAc,GACpCV,EAAE7D,KAAKkE,KAAKO,KACZF,EAAe3K,EAAGqI,IACdrI,EAAGgD,IACC2H,EACA,EAAIA,EAAaG,MAAM,IAE3B,IAGDH,IAGPjC,IAAAA,EAAU,GACVqC,EAAiB/K,EAAGgL,OACpBR,EAAc/F,IAAI,SAACwG,GACRjL,OAAAA,EAAGkF,OAAO+F,EAAQ,GAAG3H,QAAQ,EAAE,EAAG,MACzC,GACNqE,YAEEuD,EAAsBlL,EAAGgL,OACzBR,EAAc/F,IAAI,SAACwG,GACRjL,OAAAA,EAAGsI,YAAY2C,EAAQ,EAAG,MAAM,KACvC,GACNtD,YAEFyC,OAAOC,KAAKJ,EAAE7D,KAAKkE,KAAKC,UACnB1G,QAAQ,SAACsH,EAAYpH,GACd7B,KAAKiE,SAAW8D,EAAE7D,KAAKkE,KAAKC,SAASY,GAAYC,wBACjD1C,EAAQyC,GAAcD,EAAoBnH,GAE1C2E,EAAQyC,GAAcJ,EAAehH,KAIjDqG,OAAOC,KAAKZ,GAAa5F,QAAQ,SAACsH,QAC8C3C,IAAxE4B,OAAOC,KAAKJ,EAAE7D,KAAKkE,KAAKC,UAAUc,KAAK,SAAA7B,GAAQA,OAAAA,IAAS2B,KACjB,GAAnC1B,EAAY0B,GAAYxB,SACxBJ,EAAW+B,MACP7B,EAAY0B,GAAYzB,MACxBO,EAAE7D,KAAKkE,KAAKC,SAASY,GAAYzC,QACjCuB,EAAE7D,KAAKkE,KAAKC,SAASY,GAAYxC,QACjCsB,EAAE7D,KAAKkE,KAAKC,SAASY,GAAYzB,MACjCO,EAAE7D,KAAKkE,KAAKC,SAASY,GAAYzE,UAGzC+C,EAAY0B,GAAYxB,SAAU,GAElCF,EAAY0B,GAAYxB,SAAU,IAI1CS,OAAOC,KAAKJ,EAAE7D,KAAKkE,KAAKC,UAAU1G,QAAQ,SAACsH,EAAYpH,GACnD0F,EAAY0B,GAAYzB,MAAQO,EAAE7D,KAAKkE,KAAKC,SAASY,GAAYzB,QAErEI,EAAQK,YAAY,CAChBD,YAAa,OACbI,KAAM,CACFC,SAAUH,OAAOC,KAAKJ,EAAE7D,KAAKkE,KAAKC,UAAUlI,OAAO,SAACkJ,EAAKJ,GAK9CI,OAJPA,EAAIJ,GAAc,CACdzC,QAASA,EAAQyC,GACjBK,OAAQvB,EAAE7D,KAAKkE,KAAKC,SAASY,GAAYK,QAEtCD,GACR,YAIXzB,EAAQK,YAAY,CAChBD,YAAa,OACbI,KAAM,CACFI,QAAS,MAKrB,MAEH,IAAA,QAEGnB,EAAWlI,MAAM4I,EAAE7D,KAAKkE,KAAKvB,IAAKkB,EAAE7D,KAAKkE,KAAK9E,YAAayE,EAAE7D,KAAKkE,KAAKhF,sBACvEwE,EAAQK,YAAY,CAAED,YAAa,UACnC,MAEH,IAAA,OAEGlK,EAAG4C,KAAK,WACA6I,IACAC,EADKnC,EAAW3I,MAAMM,aACXmB,OAAO,SAACkJ,EAAKzH,GAEjByH,OADPA,EAAIzH,EAAE0F,MAAQ1F,EACPyH,GACR,IACHzB,EAAQK,YAAY,CAChBD,YAAa,OACbI,KAAM,CACFqB,cAAe5L,EAAKqJ,GAAGwC,KAAKF,QAKxC,MAEH,IAAA,OAEOG,IAAAA,EAAc9L,EAAKqJ,GAAGC,KAAKY,EAAE7D,KAAKkE,KAAKqB,eAC3CpC,EAAW3I,MAAMM,aAAa2C,QAAQ,SAACC,GACnCA,EAAEE,OAAO6H,EAAY/H,EAAE0F,SAE3BD,EAAWvI,YAAYC,WACnBsI,EAAW3I,MAAMM,cAErB4I,EAAQK,YAAY,CAAED,YAAa,SACnC,MAEH,IAAA,kBAEGX,EAAWuC,kBACXhC,EAAQK,YAAY,CAAED,YAAa","file":"agent.347b5559.js","sourceRoot":"..\\..\\prod_mode","sourcesContent":["import * as tf from \"@tensorflow/tfjs\"\r\nimport { registerTfex } from \"../../../lib/tfjs-extensions/src\"\r\nconst tfex = registerTfex(tf)\r\n\r\nexport class DDDQN {\r\n    constructor({\r\n        sequenceLen = 4,\r\n        stateVectorLen = 59,\r\n        layerNum = 8,\r\n        actionsNum = [2, 2, 2, 2, 2, 2, 2],\r\n        memorySize = 1000,\r\n        updateTargetStep = 0.05,\r\n        initLearningRate = 1e-3,\r\n        minLearningRate = 1e-5,\r\n        maxCoderSize = 4\r\n    }) {\r\n\r\n        {\r\n            this.updateTargetStep = updateTargetStep\r\n\r\n            this.count = 0\r\n\r\n            this.actionsNum = actionsNum\r\n        }\r\n\r\n        {\r\n            this.model = this.buildModel({\r\n                sequenceLen: sequenceLen,\r\n                stateVectorLen: stateVectorLen,\r\n                layerNum: layerNum,\r\n                actionsNum: actionsNum,\r\n                maxCoderSize: maxCoderSize\r\n            }, tfex.scope.variableScope(\"eval\"))\r\n            // this.model.summary()\r\n\r\n            this.targetModel = this.buildModel({\r\n                sequenceLen: sequenceLen,\r\n                stateVectorLen: stateVectorLen,\r\n                layerNum: layerNum,\r\n                actionsNum: actionsNum,\r\n                maxCoderSize: maxCoderSize\r\n            }, tfex.scope.variableScope(\"target\"))\r\n\r\n            this.targetModel.setWeights(this.model.getWeights())\r\n        }\r\n\r\n        {\r\n            this.memorySize = memorySize\r\n            this.memory = []\r\n        }\r\n\r\n        {\r\n            this.minLearningRate = minLearningRate\r\n            this.initLearningRate = initLearningRate\r\n            this.optimizer = tf.train.adam(this.initLearningRate)\r\n        }\r\n\r\n    }\r\n\r\n    buildModel({\r\n        sequenceLen,\r\n        stateVectorLen,\r\n        layerNum = 32,\r\n        actionsNum = [3, 3, 4],\r\n        maxCoderSize = 4\r\n    }, scope = tfex.scope) {\r\n        class m {\r\n            constructor({\r\n                sequenceLen,\r\n                stateVectorLen,\r\n                layerNum = 32,\r\n                actionsNum = [3, 3, 4],\r\n                maxCoderSize = 4\r\n            }, scope = tfex.scope) {\r\n                this.sequenceLen = sequenceLen\r\n                this.stateVectorLen = stateVectorLen\r\n                this.layerNum = layerNum\r\n                this.actionsNum = actionsNum\r\n                this.scope = scope\r\n                this.weights = []\r\n\r\n                let inputSize = stateVectorLen\r\n                let outputSize = stateVectorLen * maxCoderSize\r\n                this.weights.push(scope.getVariable(`input_w`, [1, inputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                this.weights.push(scope.getVariable(`input_b`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n\r\n                this.weights.push(scope.getVariable(`sc_w0`, [1, outputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                this.weights.push(scope.getVariable(`sc_b0`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n\r\n                let coderNum = Math.ceil(layerNum / 4) * 2\r\n                for (let i = 1; i <= coderNum; i++) {\r\n                    inputSize = outputSize\r\n                    outputSize = (stateVectorLen / 2) * (i / coderNum) + stateVectorLen * maxCoderSize * (coderNum - i) / coderNum\r\n                    outputSize = Math.ceil(outputSize)\r\n                    this.weights.push(scope.getVariable(`ae_w${i}`, [Math.ceil(sequenceLen / (coderNum)) + 1, inputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`ae_b${i}`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n                    this.weights.push(scope.getVariable(`sc_w${i}`, [1, outputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`sc_b${i}`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n                }\r\n\r\n                inputSize = outputSize\r\n                this.weights.push(scope.getVariable(`ae_w${coderNum + 1}`, [Math.ceil(sequenceLen / (coderNum)) + 1, inputSize, outputSize], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                this.weights.push(scope.getVariable(`ae_b${coderNum + 1}`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n\r\n                for (let i = 1; i <= coderNum; i++) {\r\n                    outputSize = (stateVectorLen / 2) * ((coderNum - i) / coderNum) + stateVectorLen * maxCoderSize * i / coderNum\r\n                    outputSize = Math.ceil(outputSize)\r\n                    this.weights.push(scope.getVariable(`ae_b${coderNum + i + 1}`, [1, 1, outputSize], \"float32\", tf.initializers.zeros({})))\r\n                }\r\n\r\n                {\r\n                    this.weights.push(scope.getVariable(`value_w1`, [1, sequenceLen, 1], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`value_b1`, [1, 1, 1], \"float32\", tf.initializers.zeros({})))\r\n\r\n                    this.weights.push(scope.getVariable(`value_w2`, [1, stateVectorLen * maxCoderSize, 1], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`value_b2`, [1, 1, 1], \"float32\", tf.initializers.zeros({})))\r\n                }\r\n\r\n                {\r\n                    this.weights.push(scope.getVariable(`A_w1`, [1, sequenceLen, 1], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`A_b1`, [1, 1, 1], \"float32\", tf.initializers.zeros({})))\r\n\r\n                    this.weights.push(scope.getVariable(`A_w2`, [1, stateVectorLen * maxCoderSize, actionsNum.reduce((prev, curr) => prev + curr, 0)], \"float32\", tf.initializers.truncatedNormal({ stddev: 0.1, mean: 0 })))\r\n                    this.weights.push(scope.getVariable(`A_b2`, [1, 1, actionsNum.reduce((prev, curr) => prev + curr, 0)], \"float32\", tf.initializers.zeros({})))\r\n                }\r\n                // this.weights.forEach(w => w.sum().print())\r\n                console.log(this.scope.variables)\r\n            }\r\n\r\n            predict(x) {\r\n                return tf.tidy(() => {\r\n                    let jumperLayers = []\r\n                    let AELayer = tf.conv1d(\r\n                        x,\r\n                        this.scope.getVariable(`input_w`),\r\n                        1,\r\n                        \"same\"\r\n                    )\r\n                    AELayer = tf.add(AELayer, this.scope.getVariable(`input_b`))\r\n                    AELayer = tfex.funcs.mish(AELayer)\r\n                    jumperLayers.push(\r\n                        tfex.funcs.mish(\r\n                            tf.conv1d(\r\n                                AELayer,\r\n                                this.scope.getVariable(`sc_w0`),\r\n                                1,\r\n                                \"same\"\r\n                            ).add(this.scope.getVariable(`sc_b0`))\r\n                        )\r\n                    )\r\n\r\n                    let coderNum = Math.ceil(layerNum / 4) * 2\r\n                    for (let i = 1; i <= coderNum; i++) {\r\n                        AELayer = tf.conv1d(\r\n                            AELayer,\r\n                            this.scope.getVariable(`ae_w${i}`),\r\n                            1,\r\n                            \"same\"\r\n                        )\r\n                        AELayer = tf.add(AELayer, this.scope.getVariable(`ae_b${i}`))\r\n                        AELayer = tfex.funcs.mish(AELayer)\r\n                        jumperLayers.push(\r\n                            tfex.funcs.mish(\r\n                                tf.conv1d(\r\n                                    AELayer,\r\n                                    this.scope.getVariable(`sc_w${i}`),\r\n                                    1,\r\n                                    \"same\"\r\n                                ).add(this.scope.getVariable(`sc_b${i}`))\r\n                            )\r\n                        )\r\n                    }\r\n\r\n                    AELayer = tf.conv1d(\r\n                        AELayer,\r\n                        this.scope.getVariable(`ae_w${coderNum + 1}`),\r\n                        1,\r\n                        \"same\"\r\n                    )\r\n                    AELayer = tf.add(AELayer, this.scope.getVariable(`ae_b${coderNum + 1}`))\r\n                    AELayer = tfex.funcs.mish(AELayer)\r\n                    AELayer = tf.add(AELayer, jumperLayers.pop())\r\n\r\n                    for (let i = 0; i < coderNum; i++) {\r\n                        AELayer = tf.conv1d(\r\n                            AELayer,\r\n                            tf.transpose(\r\n                                this.scope.getVariable(`ae_w${coderNum - i}`),\r\n                                [0, 2, 1]\r\n                            ),\r\n                            1,\r\n                            \"same\"\r\n                        )\r\n                        AELayer = tf.add(AELayer, this.scope.getVariable(`ae_b${coderNum + i + 2}`))\r\n                        AELayer = tfex.funcs.mish(AELayer)\r\n                        AELayer = tf.add(AELayer, jumperLayers.pop())\r\n                    }\r\n\r\n                    let value = AELayer\r\n                    {\r\n                        value = tf.transpose(value, [0, 2, 1])\r\n                        value = tf.conv1d(\r\n                            value,\r\n                            this.scope.getVariable(`value_w1`),\r\n                            1, 0\r\n                        )\r\n                        value = tf.add(value, this.scope.getVariable(`value_b1`))\r\n\r\n                        value = tf.transpose(value, [0, 2, 1])\r\n                        value = tf.conv1d(\r\n                            value,\r\n                            this.scope.getVariable(`value_w2`),\r\n                            1, 0\r\n                        )\r\n                        value = tf.add(value, this.scope.getVariable(`value_b2`))\r\n                        value = tf.reshape(value, [-1, 1])\r\n                    }\r\n\r\n                    let A = AELayer\r\n\r\n                    {\r\n                        A = tf.transpose(A, [0, 2, 1])\r\n                        A = tf.conv1d(\r\n                            A,\r\n                            this.scope.getVariable(`A_w1`),\r\n                            1, 0\r\n                        )\r\n                        A = tf.add(A, this.scope.getVariable(`A_b1`))\r\n                        A = tf.transpose(A, [0, 2, 1])\r\n                        A = tf.conv1d(\r\n                            A,\r\n                            this.scope.getVariable(`A_w2`),\r\n                            1, 0\r\n                        )\r\n                        A = tf.add(A, this.scope.getVariable(`A_b2`))\r\n                        A = tf.reshape(A, [-1, this.actionsNum.reduce((prev, curr) => prev + curr, 0)])\r\n\r\n                        A = tf.sub(A, tf.mean(A, 1, true))\r\n                    }\r\n\r\n                    let Q = tf.add(value, A)\r\n\r\n                    let outputs\r\n                    if (this.actionsNum.length == 1) {\r\n                        outputs = Q\r\n                    } else {\r\n                        outputs = tf.split(Q, this.actionsNum, 1)\r\n                    }\r\n\r\n                    return outputs\r\n                })\r\n            }\r\n\r\n            getWeights() {\r\n                return this.weights\r\n            }\r\n\r\n            setWeights(weights) {\r\n                this.weights.forEach((w, idx) => w.assign(weights[idx]))\r\n            }\r\n        }\r\n\r\n        return new m({\r\n            sequenceLen,\r\n            stateVectorLen,\r\n            layerNum,\r\n            actionsNum,\r\n            maxCoderSize\r\n        }, scope)\r\n    }\r\n\r\n    tQandQ(batchPrevS, batchAs, batchRs, batchNextS, batchDiscount) {\r\n        return tf.tidy(() => {\r\n            let evalNet = this.model.predict(batchPrevS)\r\n            if (this.actionsNum.length == 1) {\r\n                evalNet = [evalNet]\r\n            }\r\n            const Qs = this.actionsNum.map((actionNum, actionType) => {\r\n                return tf.mul(\r\n                    tf.oneHot(\r\n                        batchAs[actionType],\r\n                        actionNum\r\n                    ),\r\n                    evalNet[actionType]\r\n                ).sum(1)\r\n            })\r\n\r\n            let predictions = this.model.predict(batchNextS)\r\n            if (this.actionsNum.length == 1) {\r\n                predictions = [predictions]\r\n            }\r\n            let targetPredictions = this.targetModel.predict(batchNextS)\r\n            if (this.actionsNum.length == 1) {\r\n                targetPredictions = [targetPredictions]\r\n            }\r\n            const targetQs = this.actionsNum.map((actionNum, actionType) => {\r\n                const maxQ = tf.mul(\r\n                    tf.oneHot(\r\n                        tf.argMax(\r\n                            predictions[actionType],\r\n                            1\r\n                        ),\r\n                        actionNum\r\n                    ),\r\n                    targetPredictions[actionType]\r\n                ).sum(1)\r\n                const targets = batchRs[actionType].add(maxQ.mul(batchDiscount));\r\n                return targets;\r\n            })\r\n            return [targetQs, Qs]\r\n        })\r\n    }\r\n\r\n    train(replayNum = 100, loadIdxes = [null], usePrioritizedReplay = false) {\r\n        tf.tidy(() => {\r\n            let train_ = (replayIdxes) => {\r\n                tf.tidy(() => {\r\n                    let replayIdxes_ = replayIdxes.slice()\r\n\r\n                    let arrayPrevS = []\r\n                    let arrayAs = new Array(this.actionsNum.length).fill([])\r\n                    let arrayRs = new Array(this.actionsNum.length).fill([])\r\n                    let arrayNextS = []\r\n                    let arrayDiscount = []\r\n\r\n                    for (let i = 0; i < replayNum; i++) {\r\n                        if (replayIdxes_[i] == null || replayIdxes_[i] >= this.memory.length) {\r\n                            replayIdxes_[i] = Math.floor(Math.random() * this.memory.length);\r\n                        }\r\n                        let data = this.memory[replayIdxes_[i]]\r\n                        // console.log(data)\r\n                        arrayPrevS.push(data.prevS)\r\n                        for (let j = 0; j < this.actionsNum.length; j++) {\r\n                            arrayAs[j][i] = data.As[j]\r\n                            arrayRs[j][i] = data.Rs[j]\r\n                        }\r\n                        arrayNextS.push(data.nextS)\r\n                        arrayDiscount.push(data.discount)\r\n                    }\r\n\r\n                    let batchPrevS = tf.tensor3d(arrayPrevS)\r\n                    let batchAs = arrayAs.map((arrayA) => {\r\n                        return tf.tensor1d(arrayA, 'int32')\r\n                    })\r\n                    let batchRs = arrayRs.map((arrayR) => {\r\n                        return tf.tensor1d(arrayR, 'float32')\r\n                    })\r\n                    let batchNextS = tf.tensor3d(arrayNextS)\r\n                    let batchDiscount = tf.tensor1d(arrayDiscount)\r\n\r\n                    let grads = this.optimizer.computeGradients(\r\n                        () => {\r\n                            let [targetQs, Qs] = this.tQandQ(\r\n                                batchPrevS,\r\n                                batchAs,\r\n                                batchRs,\r\n                                batchNextS,\r\n                                batchDiscount\r\n                            )\r\n                            let loss = tf.mean(\r\n                                tf.stack(\r\n                                    this.actionsNum.map((actionNum, actionType) => {\r\n                                        // return tf.losses.huberLoss(targetQs[actionType], Qs[actionType])\r\n                                        return tf.losses.meanSquaredError(targetQs[actionType], Qs[actionType])\r\n                                    })\r\n                                )\r\n                            )\r\n                            loss.print()\r\n                            return loss\r\n                        }, this.model.getWeights(true)).grads\r\n\r\n                    // let gradsName = Object.keys(grads)\r\n                    // grads = tfex.funcs.clipByGlobalNorm(Object.values(grads), 1)[0]\r\n\r\n                    // this.optimizer.applyGradients(gradsName.reduce((acc, gn, idx) => {\r\n                    //     acc[gn] = grads[idx]\r\n                    //     // if (gn == \"weighted_average_WeightedAverage1/w\") {\r\n                    //     //     acc[gn].print()\r\n                    //     // }\r\n                    //     return acc\r\n                    // }, {}))\r\n                    this.optimizer.applyGradients(grads)\r\n\r\n                    {\r\n                        let [targetQs, Qs] = this.tQandQ(\r\n                            batchPrevS,\r\n                            batchAs,\r\n                            batchRs,\r\n                            batchNextS,\r\n                            batchDiscount\r\n                        )\r\n                        tf.addN(\r\n                            this.actionsNum.map((actionNum, actionType) => {\r\n                                return tf.abs(tf.sub(targetQs[actionType], Qs[actionType]))\r\n                            })\r\n                        ).arraySync()\r\n                            .forEach((absTD, idx) => {\r\n                                this.memory[replayIdxes_[idx]].p = absTD\r\n                            })\r\n                    }\r\n\r\n                    this.count++\r\n\r\n                    this.optimizer.learningRate = Math.max(this.initLearningRate / (this.count ** 0.5), this.minLearningRate)\r\n\r\n                    if (this.updateTargetStep < 1) {\r\n                        this.targetModel.setWeights(\r\n                            this.targetModel.getWeights().map((weight, idx) => {\r\n                                return tf.add(\r\n                                    tf.mul(this.model.getWeights()[idx], this.updateTargetStep),\r\n                                    tf.mul(weight, 1 - this.updateTargetStep),\r\n                                )\r\n                            })\r\n                        )\r\n                    } else {\r\n                        if (this.count % Math.round(this.updateTargetStep) == 0) {\r\n                            this.targetModel.setWeights(this.model.getWeights())\r\n                        }\r\n                    }\r\n                })\r\n            }\r\n            if (this.memory.length != 0) {\r\n                if (usePrioritizedReplay) {\r\n                    let prioritizedReplayBuffer = tf.tidy(() => {\r\n                        let prioritys = tf.tensor(this.memory.map(mem => mem.p))\r\n                        prioritys = tf.div(prioritys, tf.sum(prioritys, 0, true))\r\n                        // prioritys.print()\r\n                        return tf.multinomial(prioritys, replayNum, null, true).arraySync()\r\n                    })\r\n                    // console.log(prioritizedReplayBuffer)\r\n                    train_(prioritizedReplayBuffer.map((prioritizedReplayIdx, idx) => {\r\n                        return loadIdxes[idx] == null || loadIdxes[idx] == undefined ? prioritizedReplayIdx : loadIdxes[idx]\r\n                    }))\r\n                } else {\r\n                    train_(loadIdxes)\r\n                }\r\n            }\r\n        })\r\n    }\r\n\r\n    store(preState, actions, rewards, nextState, discount) {\r\n        if (this.memory.length == this.memorySize) {\r\n            this.memory.pop()\r\n        }\r\n        this.memory.unshift({\r\n            prevS: preState,\r\n            As: actions,\r\n            Rs: rewards,\r\n            nextS: nextState,\r\n            discount: discount,\r\n            p: 1e+9\r\n        })\r\n    }\r\n\r\n    load(index) {\r\n        if (index == null || index >= this.memory.length) {\r\n            index = Math.floor(Math.random() * this.memory.length);\r\n        }\r\n        return this.memory[index]\r\n    }\r\n\r\n    updatePrioritys(bsz = 64) {\r\n\r\n        if (this.memory.length != 0) {\r\n            for (let begin = 0; begin < this.memory.length; begin += bsz) {\r\n                tf.tidy(() => {\r\n                    let arrayPrevS = []\r\n                    let arrayAs = new Array(this.actionsNum.length).fill([])\r\n                    let arrayRs = new Array(this.actionsNum.length).fill([])\r\n                    let arrayNextS = []\r\n                    let arrayDiscount = []\r\n\r\n                    for (let i = begin; i < Math.min(this.memory.length, begin + bsz); i++) {\r\n                        let data = this.memory[i]\r\n                        arrayPrevS.push(data.prevS)\r\n                        for (let j = 0; j < this.actionsNum.length; j++) {\r\n                            arrayAs[j][i - begin] = data.As[j]\r\n                            arrayRs[j][i - begin] = data.Rs[j]\r\n                        }\r\n                        arrayNextS.push(data.nextS)\r\n                        arrayDiscount.push(data.discount)\r\n                    }\r\n\r\n                    let batchPrevS = tf.tensor3d(arrayPrevS)\r\n                    let batchAs = arrayAs.map((arrayA) => {\r\n                        return tf.tensor1d(arrayA, 'int32')\r\n                    })\r\n                    let batchRs = arrayRs.map((arrayR) => {\r\n                        return tf.tensor1d(arrayR, 'float32')\r\n                    })\r\n                    let batchNextS = tf.tensor3d(arrayNextS)\r\n                    let batchDiscount = tf.tensor1d(arrayDiscount)\r\n\r\n                    let [targetQs, Qs] = this.tQandQ(\r\n                        batchPrevS,\r\n                        batchAs,\r\n                        batchRs,\r\n                        batchNextS,\r\n                        batchDiscount\r\n                    )\r\n                    tf.addN(\r\n                        this.actionsNum.map((actionNum, actionType) => {\r\n                            return tf.abs(tf.sub(targetQs[actionType], Qs[actionType]))\r\n                        })\r\n                    ).arraySync()\r\n                        .forEach((absTD, idx) => {\r\n                            this.memory[begin + idx].p = absTD\r\n                        })\r\n\r\n                })\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n\r\nexport function dddqn({\r\n    sequenceLen = 4,\r\n    stateVectorLen = 59,\r\n    layerNum = 8,\r\n    actionsNum = [2, 2, 2, 2, 2, 2, 2],\r\n    memorySize = 1000,\r\n    updateTargetStep = 0.05,\r\n    initLearningRate = 1e-3,\r\n    minLearningRate = 1e-5,\r\n    maxCoderSize = 4\r\n}) {\r\n    return new DDDQN({\r\n        sequenceLen,\r\n        stateVectorLen,\r\n        layerNum,\r\n        actionsNum,\r\n        memorySize,\r\n        updateTargetStep,\r\n        initLearningRate,\r\n        minLearningRate,\r\n        maxCoderSize\r\n    })\r\n}","export * from './model'","import * as tf from \"@tensorflow/tfjs\"\r\nimport { dddqn } from \"../../src/js/MirageNet/dddqn10\"\r\nimport { registerTfex } from \"../../src/lib/tfjs-extensions/src\"\r\nconst tfex = registerTfex(tf)\r\nimport * as fs from \"fs\"\r\nlet initWeights = tfex.sl.load(fs.readFileSync(__dirname + \"/../w2.bin\"))\r\n\r\ntf.enableProdMode()\r\n\r\nlet actionsNum = [128]\r\n\r\nlet dddqnModel = dddqn({\r\n    sequenceLen: 4,\r\n    stateVectorLen: 59,\r\n    layerNum: 64,\r\n    actionsNum: actionsNum,\r\n    memorySize: 8192,\r\n    minLearningRate: 1e-4,\r\n    initLearningRate: 1e-3,\r\n    updateTargetStep: 0.01,\r\n    maxCoderSize: 4\r\n})\r\ndddqnModel.model.getWeights().forEach((w) => {\r\n    w.assign(initWeights[w.name])\r\n})\r\ndddqnModel.targetModel.setWeights(\r\n    dddqnModel.model.getWeights()\r\n)\r\n\r\nlet preArchives = {\r\n    \"player1\": {\r\n        state: null,\r\n        expired: true\r\n    },\r\n    \"player2\": {\r\n        state: null,\r\n        expired: true\r\n    }\r\n}\r\n\r\ntf.ready().then(() => {\r\n    let channel = self\r\n    channel.addEventListener(\"message\", (e) => {\r\n        tf.tidy(() => {\r\n            switch (e.data.instruction) {\r\n                case 'init':\r\n                    {\r\n                        channel.postMessage({ instruction: \"init\" })\r\n                        break\r\n                    }\r\n                case 'ctrl':\r\n                    {\r\n                        if (Object.keys(e.data.args.archives).length != 0) {\r\n                            let outputActions = dddqnModel\r\n                                .model\r\n                                .predict(\r\n                                    tf.tensor(\r\n                                        Object.values(e.data.args.archives)\r\n                                            .map(archive => {\r\n                                                return archive.state\r\n                                            })\r\n                                    )\r\n                                )\r\n                            if (actionsNum.length == 1) {\r\n                                outputActions = [outputActions]\r\n                            }\r\n                            outputActions = outputActions.map(outputAction => {\r\n                                outputAction = tf.softmax(outputAction, 1)\r\n                                if (e.data.args.CP) { //如果有補正機率就執行這段\r\n                                    outputAction = tf.div(\r\n                                        tf.add(\r\n                                            outputAction,\r\n                                            1 / outputAction.shape[1]\r\n                                        ),\r\n                                        2\r\n                                    )\r\n                                }\r\n                                return outputAction\r\n                            })\r\n\r\n                            let actions = {}\r\n                            let chooseByArgMax = tf.concat(\r\n                                outputActions.map((action) => {\r\n                                    return tf.argMax(action, 1).reshape([-1, 1])\r\n                                }), 1\r\n                            ).arraySync()\r\n\r\n                            let chooseByMultinomial = tf.concat(\r\n                                outputActions.map((action) => {\r\n                                    return tf.multinomial(action, 1, null, true)\r\n                                }), 1\r\n                            ).arraySync()\r\n\r\n                            Object.keys(e.data.args.archives)\r\n                                .forEach((playerName, idx) => {\r\n                                    if (Math.random() < e.data.args.archives[playerName].chooseActionRandomValue) {\r\n                                        actions[playerName] = chooseByMultinomial[idx]\r\n                                    } else {\r\n                                        actions[playerName] = chooseByArgMax[idx]\r\n                                    }\r\n                                })\r\n\r\n                            Object.keys(preArchives).forEach((playerName) => {\r\n                                if (Object.keys(e.data.args.archives).find(name => name === playerName) !== undefined) {\r\n                                    if (preArchives[playerName].expired == false) {\r\n                                        dddqnModel.store(\r\n                                            preArchives[playerName].state,\r\n                                            e.data.args.archives[playerName].actions,\r\n                                            e.data.args.archives[playerName].rewards,\r\n                                            e.data.args.archives[playerName].state,\r\n                                            e.data.args.archives[playerName].discount\r\n                                        )\r\n                                    }\r\n                                    preArchives[playerName].expired = false\r\n                                } else {\r\n                                    preArchives[playerName].expired = true\r\n                                }\r\n                            })\r\n\r\n                            Object.keys(e.data.args.archives).forEach((playerName, idx) => {\r\n                                preArchives[playerName].state = e.data.args.archives[playerName].state\r\n                            })\r\n                            channel.postMessage({\r\n                                instruction: \"ctrl\",\r\n                                args: {\r\n                                    archives: Object.keys(e.data.args.archives).reduce((acc, playerName) => {\r\n                                        acc[playerName] = {\r\n                                            actions: actions[playerName],\r\n                                            aiCtrl: e.data.args.archives[playerName].aiCtrl\r\n                                        }\r\n                                        return acc\r\n                                    }, {})\r\n                                }\r\n                            })\r\n                        } else {\r\n                            channel.postMessage({\r\n                                instruction: \"ctrl\",\r\n                                args: {\r\n                                    archive: {}\r\n                                }\r\n                            })\r\n                        }\r\n                        // console.log(\"ctrl\")\r\n                        break\r\n                    }\r\n                case 'train':\r\n                    {\r\n                        dddqnModel.train(e.data.args.bsz, e.data.args.replayIdxes, e.data.args.usePrioritizedReplay)\r\n                        channel.postMessage({ instruction: \"train\" })\r\n                        break\r\n                    }\r\n                case 'save':\r\n                    {\r\n                        tf.tidy(() => {\r\n                            let Ws = dddqnModel.model.getWeights()\r\n                            let tList = Ws.reduce((acc, w) => {\r\n                                acc[w.name] = w\r\n                                return acc\r\n                            }, {})\r\n                            channel.postMessage({\r\n                                instruction: \"save\",\r\n                                args: {\r\n                                    weightsBuffer: tfex.sl.save(tList)\r\n                                }\r\n                            })\r\n                        })\r\n\r\n                        break\r\n                    }\r\n                case 'load':\r\n                    {\r\n                        let loadWeights = tfex.sl.load(e.data.args.weightsBuffer)\r\n                        dddqnModel.model.getWeights().forEach((w) => {\r\n                            w.assign(loadWeights[w.name])\r\n                        })\r\n                        dddqnModel.targetModel.setWeights(\r\n                            dddqnModel.model.getWeights()\r\n                        )\r\n                        channel.postMessage({ instruction: \"load\" })\r\n                        break\r\n                    }\r\n                case \"updatePrioritys\":\r\n                    {\r\n                        dddqnModel.updatePrioritys()\r\n                        channel.postMessage({ instruction: \"updatePrioritys\" })\r\n                    }\r\n            }\r\n        })\r\n    })\r\n})"]}