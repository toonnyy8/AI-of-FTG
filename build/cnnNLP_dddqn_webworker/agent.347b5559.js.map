{"version":3,"sources":["../src/js/MirageNet/dddqn/model.js","../src/js/MirageNet/dddqn/index.js","js/agent.js"],"names":["tfex","tf","DDDQN","sequenceLen","inputNum","embInner","filters","outputInner","actionNum","memorySize","updateTargetStep","minLearningRate","count","model","buildModel","summary","targetModel","setWeights","getWeights","memory","optimizer","train","adam","input","shape","cnnLayer","layers","conv1d","kernelSize","activation","padding","apply","batchNormalization","dropout","rate","strides","value","A","mean","lambda","func","x","outputShape","advantage","y","sub","Q","flatten","add","softmax","inputs","outputs","arrayPrevS","arrayA","arrayR","arrayNextS","tidy","batchPrevS","tensor3d","batchA","tensor1d","batchR","batchNextS","predictions","predict","predMask","oneHot","targets","maxQ","mul","argMax","sum","scalar","calcTarget","losses","softmaxCrossEntropy","asType","expandDims","square","replayNum","loadIdxes","usePrioritizedReplay","train_","replayIdxes","i","data","load","push","grads","computeGradients","loss","print","gradsName","Object","keys","funcs","clipByGlobalNorm","values","applyGradients","reduce","acc","gn","idx","learningRate","length","e","tensor","map","mem","abs","div","multinomial","arraySync","prioritizedReplayIdx","undefined","preState","action","reward","nextState","pop","unshift","index","Math","floor","random","dddqn","setBackend","dddqnModel","preArchive","state","expired","ready","then","channel","self","addEventListener","instruction","postMessage","args","archive","outputActions","actions","chooseByArgMax","reshape","chooseByMultinomial","chooseAction","forEach","playerName","find","name","store","bsz","Ws","tList","w","weightsBuffer","sl","save","loadWeights","assign"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+SC,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,MAAA,EAAA,QAAA,WAAA,EA/SD,IAAA,EAAA,EAAA,QAAA,qBACA,EAAA,QAAA,oCA8SC,SAAA,IAAA,GAAA,mBAAA,QAAA,OAAA,KAAA,IAAA,EAAA,IAAA,QAAA,OAAA,EAAA,WAAA,OAAA,GAAA,EAAA,SAAA,EAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,IAAA,GAAA,GAAA,EAAA,IAAA,GAAA,OAAA,EAAA,IAAA,GAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,CAAA,IAAA,EAAA,OAAA,gBAAA,OAAA,yBAAA,IAAA,IAAA,KAAA,EAAA,GAAA,OAAA,UAAA,eAAA,KAAA,EAAA,GAAA,CAAA,IAAA,EAAA,EAAA,OAAA,yBAAA,EAAA,GAAA,KAAA,IAAA,EAAA,KAAA,EAAA,KAAA,OAAA,eAAA,EAAA,EAAA,GAAA,EAAA,GAAA,EAAA,IAAA,OAAA,EAAA,QAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EAAA,SAAA,EAAA,EAAA,GAAA,KAAA,aAAA,GAAA,MAAA,IAAA,UAAA,qCAAA,SAAA,EAAA,EAAA,GAAA,IAAA,IAAA,EAAA,EAAA,EAAA,EAAA,OAAA,IAAA,CAAA,IAAA,EAAA,EAAA,GAAA,EAAA,WAAA,EAAA,aAAA,EAAA,EAAA,cAAA,EAAA,UAAA,IAAA,EAAA,UAAA,GAAA,OAAA,eAAA,EAAA,EAAA,IAAA,IAAA,SAAA,EAAA,EAAA,EAAA,GAAA,OAAA,GAAA,EAAA,EAAA,UAAA,GAAA,GAAA,EAAA,EAAA,GAAA,EA7SD,IAAMA,GAAO,EAAaC,EAAAA,cAAAA,GAEbC,EA2SZ,WAhSM,SAAA,EAAA,GATCC,IAAAA,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,GASf,EARCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,GAQZ,EAPCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,CAAC,GAAI,GAAI,IAOrB,EANCC,EAAAA,EAAAA,QAAAA,OAAU,IAAA,EAAA,CAAC,EAAG,EAAG,EAAG,GAMrB,EALCC,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,CAAC,GAAI,IAKpB,EAJCC,EAAAA,EAAAA,UAAAA,OAAY,IAAA,EAAA,EAIb,EAHCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,IAGd,EAFCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,GAEpB,EADCC,EAAAA,EAAAA,gBAAAA,OAAkB,IAAA,EAAA,KACnB,EAAA,EAAA,KAAA,GAGUD,KAAAA,iBAAmBA,EAEnBE,KAAAA,MAAQ,EAERJ,KAAAA,UAAYA,EAIZK,KAAAA,MAAQ,KAAKC,WAAW,CACzBX,YAAaA,EACbC,SAAUA,EACVC,SAAUA,EACVC,QAASA,EACTC,YAAaA,EACbC,UAAWA,IAEVK,KAAAA,MAAME,UAENC,KAAAA,YAAc,KAAKF,WAAW,CAC/BX,YAAaA,EACbC,SAAUA,EACVC,SAAUA,EACVC,QAASA,EACTC,YAAaA,EACbC,UAAWA,IAGVQ,KAAAA,YAAYC,WAAW,KAAKJ,MAAMK,cAIlCT,KAAAA,WAAaA,EACbU,KAAAA,OAAS,GAITR,KAAAA,gBAAkBA,EAClBS,KAAAA,UAAYnB,EAAGoB,MAAMC,KAAK,MAwP1C,OAAA,EAAA,EAAA,CAAA,CAAA,IAAA,aA5OK,MAAA,SAAA,GALMnB,IAAAA,EAAAA,EAAAA,YACAC,EAAAA,EAAAA,SACAE,EAAAA,EAAAA,QAAAA,OAAU,IAAA,EAAA,EAGhB,EAFME,EAAAA,EAAAA,UAAAA,OAAY,IAAA,EAAA,GAElB,EACMe,EAAQtB,EAAGsB,MAAM,CAAEC,MAAO,CAACrB,EAAaC,KAExCqB,EAAWxB,EAAGyB,OAAOC,OAAO,CAC5BrB,QAAmB,EAAVA,EACTsB,WAAY,CAAC,GACbC,WAAY,OACZC,QAAS,SACVC,MAAMR,GAYF,IAXPE,EAAWxB,EAAGyB,OAAOM,mBAAmB,IAAID,MAAMN,GAClDA,EAAWxB,EAAGyB,OAAOO,QAAQ,CAAEC,KAAM,MAAQH,MAAMN,GACnDA,EAAWxB,EAAGyB,OAAOC,OAAO,CACxBrB,QAAmB,EAAVA,EACTsB,WAAY,CAAC,GACbC,WAAY,OACZC,QAAS,SACVC,MAAMN,GACTA,EAAWxB,EAAGyB,OAAOM,mBAAmB,IAAID,MAAMN,GAClDA,EAAWxB,EAAGyB,OAAOO,QAAQ,CAAEC,KAAM,MAAQH,MAAMN,GAE5C,GAAKA,EAASD,MAAM,GAAK,GAC5BC,EAAWxB,EAAGyB,OAAOC,OAAO,CACxBrB,QAASA,EACTsB,WAAY,CAAC,GACbC,WAAY,OACZC,QAAS,SACVC,MAAMN,GACTA,EAAWxB,EAAGyB,OAAOM,mBAAmB,IAAID,MAAMN,GAClDA,EAAWxB,EAAGyB,OAAOO,QAAQ,CAAEC,KAAM,MAAQH,MAAMN,GACnDA,EAAWxB,EAAGyB,OAAOC,OAAO,CACxBrB,QAASA,EACTsB,WAAY,CAAC,GACbO,QAAS,CAAC,GACVN,WAAY,OACZC,QAAS,SACVC,MAAMN,GACTA,EAAWxB,EAAGyB,OAAOM,mBAAmB,IAAID,MAAMN,GAClDA,EAAWxB,EAAGyB,OAAOO,QAAQ,CAAEC,KAAM,MAAQH,MAAMN,GAGnDW,IAAAA,EAAQnC,EAAGyB,OAAOC,OAAO,CACzBrB,QAAmB,EAAVA,EACTsB,WAAY,CAAC,GACbC,WAAY,OACZC,QAAS,SACVC,MAAMN,GACTW,EAAQnC,EAAGyB,OAAOM,mBAAmB,IAAID,MAAMK,GAC/CA,EAAQnC,EAAGyB,OAAOC,OAAO,CACrBrB,QAAmB,EAAVA,EACTsB,WAAY,CAAC,GACbC,WAAY,OACZC,QAAS,SACVC,MAAMK,GACTA,EAAQnC,EAAGyB,OAAOM,mBAAmB,IAAID,MAAMK,GAC/CA,EAAQnC,EAAGyB,OAAOC,OAAO,CACrBrB,QAASE,EACToB,WAAY,CAAC,GACbC,WAAY,UACZC,QAAS,SACVC,MAAMK,GAELC,IAAAA,EAAIpC,EAAGyB,OAAOC,OAAO,CACrBrB,QAAmB,EAAVA,EACTsB,WAAY,CAAC,GACbC,WAAY,OACZC,QAAS,SACVC,MAAMN,GACTY,EAAIpC,EAAGyB,OAAOM,mBAAmB,IAAID,MAAMM,GAC3CA,EAAIpC,EAAGyB,OAAOC,OAAO,CACjBrB,QAAmB,EAAVA,EACTsB,WAAY,CAAC,GACbC,WAAY,OACZC,QAAS,SACVC,MAAMM,GACTA,EAAIpC,EAAGyB,OAAOM,mBAAmB,IAAID,MAAMM,GAC3CA,EAAIpC,EAAGyB,OAAOC,OAAO,CACjBrB,QAASE,EACToB,WAAY,CAAC,GACbC,WAAY,UACZC,QAAS,SACVC,MAAMM,GAELC,IAAAA,EAAOtC,EAAK0B,OAAOa,OAAO,CAC1BC,KAAM,SAACC,GACIxC,OAAAA,EAAGqC,KAAKG,EAAG,GAAG,IAEzBC,YAAa,CAAC,KACfX,MAAM,CAACM,IAENM,EAAY3C,EAAK0B,OAAOa,OAAO,CAC/BC,KAAM,SAACC,EAAGG,GACC3C,OAAAA,EAAG4C,IAAIJ,EAAGG,MAEtBb,MAAM,CAACM,EAAGC,IAETQ,EAAI7C,EAAGyB,OAAOqB,UAAUhB,MACxB9B,EAAGyB,OAAOsB,MAAMjB,MAAM,CAACK,EAAOO,KAI3B1C,OAFP6C,EAAI7C,EAAGyB,OAAOuB,UAAUlB,MAAMe,GAEvB7C,EAAGY,MAAM,CAAEqC,OAAQ,CAAC3B,GAAQ4B,QAASL,MAwInD,CAAA,IAAA,OArIQM,MAAAA,SAAAA,EAAYC,EAAQC,EAAQC,GAAY,IAAA,EAAA,KAWlCtD,OAAAA,EAAGuD,KAAK,WAEPC,IAAAA,EAAaxD,EAAGyD,SAASN,GACzBO,EAAS1D,EAAG2D,SAASP,EAAQ,SAC7BQ,EAAS5D,EAAG2D,SAASN,GACrBQ,EAAa7D,EAAGyD,SAASH,GAEvBQ,EAAc,EAAKlD,MAAMmD,QAAQP,GAEjCQ,EAAWhE,EAAGiE,OAAOP,EAAQ,EAAKnD,WAElC2D,EArBO,SAACN,EAAQC,GACf7D,OAAAA,EAAGuD,KAAK,WACLY,IAAAA,EAAOnE,EAAGoE,IACZpE,EAAGiE,OAAO,EAAKrD,MAAMmD,QAAQF,GAAYQ,OAAO,GAAI,EAAK9D,WACzD,EAAKQ,YAAYgD,QAAQF,IAC3BS,IAAI,GAECJ,OADSN,EAAOb,IAAIoB,EAAKC,IAAIpE,EAAGuE,OAAO,SAelCC,CAAWZ,EAAQC,GAC5B7D,OAAAA,EAAGyE,OAAOC,oBAAoBV,EAASW,OAAO,WAAYb,EAAYlB,IAAIsB,EAAQU,WAAW,IAAIC,cA8GnH,CAAA,IAAA,QAxG4E,MAAA,WAAA,IAAA,EAAA,KAAnEC,EAAY,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,IAAKC,EAAY,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,CAAC,MAAOC,EAAuB,UAAA,OAAA,QAAA,IAAA,UAAA,IAAA,UAAA,GAC9DhF,EAAGuD,KAAK,WACA0B,IAAAA,EAAS,SAACC,GACVlF,EAAGuD,KAAK,WAMC,IALDJ,IAAAA,EAAa,GACbC,EAAS,GACTC,EAAS,GACTC,EAAa,GAER6B,EAAI,EAAGA,EAAIL,EAAWK,IAAK,CAC5BC,IAAAA,EAAO,EAAKC,KAAKH,EAAYC,IAEjChC,EAAWmC,KAAKF,EAAK,IACrBhC,EAAOkC,KAAKF,EAAK,IACjB/B,EAAOiC,KAAKF,EAAK,IACjB9B,EAAWgC,KAAKF,EAAK,IAGrBG,IAAAA,EAAQ,EAAKpE,UAAUqE,iBACvB,WACQC,IAAAA,EAAO,EAAKA,KAAKtC,EAAYC,EAAQC,EAAQC,GAE1CmC,OADPA,EAAKC,QACED,GACR,EAAK7E,MAAMK,YAAW,IAAOsE,MAEhCI,EAAYC,OAAOC,KAAKN,GAC5BA,EAAQxF,EAAK+F,MAAMC,iBAAiBH,OAAOI,OAAOT,GAAQ,KAAM,GAEhE,EAAKpE,UAAU8E,eAAeN,EAAUO,OAAO,SAACC,EAAKC,EAAIC,GAK9CF,OAJPA,EAAIC,GAAMb,EAAMc,GAITF,GACR,KAEH,EAAKxF,QAEL,EAAKQ,UAAUmF,aAAgB,KAAO,KAAA,IAAA,EAAK3F,MAAS,IAAO,EAAKD,gBAE5D,EAAKC,MAAQ,EAAKF,kBAAoB,GACtC,EAAKM,YAAYC,WAAW,EAAKJ,MAAMK,iBAKzB,GAAtB,EAAKC,OAAOqF,QAURtB,EATAD,EAC8BhF,EAAGuD,KAAK,WAC9BiD,IAAAA,EAAIxG,EAAGyG,OAAO,EAAKvF,OAAOwF,IAAI,SAAAC,GAAOA,OAAAA,EAAI,MAItC3G,OAFPwG,GADAA,EAAIxG,EAAG4G,IAAIJ,EAAE5D,IAAI4D,EAAEnE,UACbwE,IAAIL,EAAElC,IAAI,GAAG,IAEZtE,EAAG8G,YAAYN,EAAG1B,EAAW,MAAM,GAAMiC,cAGrBL,IAAI,SAACM,EAAsBX,GAC/CtB,OAAkB,MAAlBA,EAAUsB,IAAkCY,MAAlBlC,EAAUsB,GAAoBW,EAAuBjC,EAAUsB,KAG7FtB,OA4C1B,CAAA,IAAA,QAtCSmC,MAAAA,SAAAA,EAAUC,EAAQC,EAAQC,GACxB,KAAKnG,OAAOqF,QAAU,KAAK/F,YACtBU,KAAAA,OAAOoG,MAEXpG,KAAAA,OAAOqG,QAAQ,CAACL,EAAUC,EAAQC,EAAQC,MAkCtD,CAAA,IAAA,OA/BQG,MAAAA,SAAAA,GAIM,OAHM,MAATA,GAAiBA,GAAS,KAAKtG,OAAOqF,UACtCiB,EAAQC,KAAKC,MAAMD,KAAKE,SAAW,KAAKzG,OAAOqF,SAE5C,KAAKrF,OAAOsG,OA2B1B,EAAA,GAtBM,SAASI,EAUb,GATC1H,IAAAA,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,GASf,EARCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,GAQZ,EAPCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,CAAC,GAAI,GAAI,IAOrB,EANCC,EAAAA,EAAAA,QAAAA,OAAU,IAAA,EAAA,CAAC,EAAG,EAAG,EAAG,GAMrB,EALCC,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,CAAC,GAAI,IAKpB,EAJCC,EAAAA,EAAAA,UAAAA,OAAY,IAAA,EAAA,EAIb,EAHCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,IAGd,EAFCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,GAEpB,EADCC,EAAAA,EAAAA,gBAEO,OAAA,IAAIT,EAAM,CACbC,YAAAA,EACAC,SAAAA,EACAC,SAAAA,EACAC,QAAAA,EACAC,YAAAA,EACAC,UAAAA,EACAC,WAAAA,EACAC,iBAAAA,EACAC,qBAXc,IAAA,EAAA,KACnB,IAYF,QAAA,MAAA;;AC/SD,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,IAAA,EAAA,QAAA,WAAA,OAAA,KAAA,GAAA,QAAA,SAAA,GAAA,YAAA,GAAA,eAAA,GAAA,OAAA,eAAA,QAAA,EAAA,CAAA,YAAA,EAAA,IAAA,WAAA,OAAA,EAAA;;ACgCA,aAhCA,IAAA,EAAA,EAAA,QAAA,qBACA,EAAA,QAAA,gCACA,EAAA,QAAA,qCA8BA,SAAA,IAAA,GAAA,mBAAA,QAAA,OAAA,KAAA,IAAA,EAAA,IAAA,QAAA,OAAA,EAAA,WAAA,OAAA,GAAA,EAAA,SAAA,EAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,IAAA,GAAA,GAAA,EAAA,IAAA,GAAA,OAAA,EAAA,IAAA,GAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,CAAA,IAAA,EAAA,OAAA,gBAAA,OAAA,yBAAA,IAAA,IAAA,KAAA,EAAA,GAAA,OAAA,UAAA,eAAA,KAAA,EAAA,GAAA,CAAA,IAAA,EAAA,EAAA,OAAA,yBAAA,EAAA,GAAA,KAAA,IAAA,EAAA,KAAA,EAAA,KAAA,OAAA,eAAA,EAAA,EAAA,GAAA,EAAA,GAAA,EAAA,IAAA,OAAA,EAAA,QAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EA7BA,IAAMX,GAAO,EAAaC,EAAAA,cAAAA,GAE1BA,EAAG6H,WAAW,SAEd,IAAItH,EAAY,EAEZuH,GAAa,EAAM,EAAA,OAAA,CACnB5H,YAAa,GACbC,SAAU,GACVE,QAAS,GACTE,UAAWA,EACXC,WAAY,KACZE,gBAAiB,KACjBD,iBAAkB,KAGlBsH,EAAa,CACF,QAAA,CACPC,MAAO,KACPb,OAAQ,KACRc,SAAS,GAEF,QAAA,CACPD,MAAO,KACPb,OAAQ,KACRc,SAAS,IAIjBjI,EAAGkI,QAAQC,KAAK,WACRC,IAAAA,EAAUC,KACdD,EAAQE,iBAAiB,UAAW,SAAC9B,GACjCxG,EAAGuD,KAAK,WACIiD,OAAAA,EAAEpB,KAAKmD,aACN,IAAA,OACDH,EAAQI,YAAY,CAAED,YAAa,SACnC,MAEC,IAAA,OACG3C,GAA2C,GAA3CA,OAAOC,KAAKW,EAAEpB,KAAKqD,KAAKC,SAASnC,OAAa,CAC1CoC,IAAAA,EAAgBb,EACflH,MACAmD,QACG/D,EAAGyG,OACCb,OAAOI,OAAOQ,EAAEpB,KAAKqD,KAAKC,SACrBhC,IAAI,SAAAgC,GACMA,OAAAA,EAAQV,UAO/BY,EAAU,GACVC,EAAiBF,EAActE,OAAO,GACrCyE,QAAQ,EAAE,IACV/B,YACDgC,EAAsB/I,EAAG8G,YAAY6B,EAAe,EAAG,MAAM,GAC5DG,QAAQ,EAAE,IACV/B,YACLP,EAAEpB,KAAKqD,KAAKO,aAAaC,QAAQ,SAACD,EAAc3C,GACxB,UAAhB2C,EACAJ,EAAQvC,GAAOwC,EAAexC,GACP,eAAhB2C,IACPJ,EAAQvC,GAAO0C,EAAoB1C,MAK3CT,OAAOC,KAAKkC,GAAYkB,QAAQ,SAACC,QAC8CjC,IAAvErB,OAAOC,KAAKW,EAAEpB,KAAKqD,KAAKC,SAASS,KAAK,SAAAC,GAAQA,OAAAA,IAASF,KACjB,GAAlCnB,EAAWmB,GAAYjB,SACvBH,EAAWuB,MACPtB,EAAWmB,GAAYlB,MACvBD,EAAWmB,GAAY/B,OACvBX,EAAEpB,KAAKqD,KAAKC,QAAQQ,GAAY9B,OAChCZ,EAAEpB,KAAKqD,KAAKC,QAAQQ,GAAYlB,OAGxCD,EAAWmB,GAAYjB,SAAU,GAEjCF,EAAWmB,GAAYjB,SAAU,IAIzCrC,OAAOC,KAAKW,EAAEpB,KAAKqD,KAAKC,SAASO,QAAQ,SAACC,EAAY7C,GAClD0B,EAAWmB,GAAYlB,MAAQxB,EAAEpB,KAAKqD,KAAKC,QAAQQ,GAAYlB,MAC/DD,EAAWmB,GAAY/B,OAASyB,EAAQvC,KAE5C+B,EAAQI,YAAY,CAChBD,YAAa,OACbE,KAAM,CACFC,QAAS9C,OAAOC,KAAKW,EAAEpB,KAAKqD,KAAKC,SAASxC,OAAO,SAACC,EAAKiD,EAAM/C,GAIlDF,OAHPA,EAAIiD,GAAQ,CACRjC,OAAQyB,EAAQvC,IAEbF,GACR,YAIXiC,EAAQI,YAAY,CAChBD,YAAa,OACbE,KAAM,CACFC,QAAS,MAKrB,MAEC,IAAA,QACDZ,EAAW1G,MAAMoF,EAAEpB,KAAKqD,KAAKa,IAAK9C,EAAEpB,KAAKqD,KAAKvD,YAAasB,EAAEpB,KAAKqD,KAAKzD,sBACvEoD,EAAQI,YAAY,CAAED,YAAa,UACnC,MAEC,IAAA,OACDvI,EAAGuD,KAAK,WACAgG,IACAC,EADK1B,EAAWlH,MAAMK,aACXiF,OAAO,SAACC,EAAKsD,GAEjBtD,OADPA,EAAIsD,EAAEL,MAAQK,EACPtD,GACR,IACHiC,EAAQI,YAAY,CAChBD,YAAa,OACbE,KAAM,CACFiB,cAAe3J,EAAK4J,GAAGC,KAAKJ,QAKxC,MAEC,IAAA,OACGK,IAAAA,EAAc9J,EAAK4J,GAAGtE,KAAKmB,EAAEpB,KAAKqD,KAAKiB,eAC3C5B,EAAWlH,MAAMK,aAAagI,QAAQ,SAACQ,GACnCA,EAAEK,OAAOD,EAAYJ,EAAEL,SAE3BtB,EAAW/G,YAAYC,WACnB8G,EAAWlH,MAAMK,cAErBmH,EAAQI,YAAY,CAAED,YAAa","file":"agent.347b5559.js","sourceRoot":"..\\..\\cnnNLP_dddqn_webworker","sourcesContent":["import * as tf from \"@tensorflow/tfjs\"\r\nimport { registerTfex } from \"../../../lib/tfjs-extensions/src\"\r\nconst tfex = registerTfex(tf)\r\n\r\nexport class DDDQN {\r\n    constructor({\r\n        sequenceLen = 60,\r\n        inputNum = 10,\r\n        embInner = [32, 32, 32],\r\n        filters = [8, 8, 8, 8],\r\n        outputInner = [32, 32],\r\n        actionNum = 8,\r\n        memorySize = 1000,\r\n        updateTargetStep = 20,\r\n        minLearningRate = 1e-5\r\n    }) {\r\n\r\n        {\r\n            this.updateTargetStep = updateTargetStep\r\n\r\n            this.count = 0\r\n\r\n            this.actionNum = actionNum\r\n        }\r\n\r\n        {\r\n            this.model = this.buildModel({\r\n                sequenceLen: sequenceLen,\r\n                inputNum: inputNum,\r\n                embInner: embInner,\r\n                filters: filters,\r\n                outputInner: outputInner,\r\n                actionNum: actionNum\r\n            })\r\n            this.model.summary()\r\n\r\n            this.targetModel = this.buildModel({\r\n                sequenceLen: sequenceLen,\r\n                inputNum: inputNum,\r\n                embInner: embInner,\r\n                filters: filters,\r\n                outputInner: outputInner,\r\n                actionNum: actionNum\r\n            })\r\n\r\n            this.targetModel.setWeights(this.model.getWeights())\r\n        }\r\n\r\n        {\r\n            this.memorySize = memorySize\r\n            this.memory = []\r\n        }\r\n\r\n        {\r\n            this.minLearningRate = minLearningRate\r\n            this.optimizer = tf.train.adam(1e-3)\r\n        }\r\n\r\n    }\r\n\r\n    buildModel(\r\n        {\r\n            sequenceLen,\r\n            inputNum,\r\n            filters = 8,\r\n            actionNum = 36\r\n        }\r\n    ) {\r\n        let input = tf.input({ shape: [sequenceLen, inputNum] })\r\n\r\n        let cnnLayer = tf.layers.conv1d({\r\n            filters: filters * 2,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(input)\r\n        cnnLayer = tf.layers.batchNormalization({}).apply(cnnLayer)\r\n        cnnLayer = tf.layers.dropout({ rate: 0.05 }).apply(cnnLayer)\r\n        cnnLayer = tf.layers.conv1d({\r\n            filters: filters * 2,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(cnnLayer)\r\n        cnnLayer = tf.layers.batchNormalization({}).apply(cnnLayer)\r\n        cnnLayer = tf.layers.dropout({ rate: 0.05 }).apply(cnnLayer)\r\n\r\n        while (1 <= cnnLayer.shape[1] / 2) {\r\n            cnnLayer = tf.layers.conv1d({\r\n                filters: filters,\r\n                kernelSize: [2],\r\n                activation: \"selu\",\r\n                padding: \"same\"\r\n            }).apply(cnnLayer)\r\n            cnnLayer = tf.layers.batchNormalization({}).apply(cnnLayer)\r\n            cnnLayer = tf.layers.dropout({ rate: 0.05 }).apply(cnnLayer)\r\n            cnnLayer = tf.layers.conv1d({\r\n                filters: filters,\r\n                kernelSize: [2],\r\n                strides: [2],\r\n                activation: \"selu\",\r\n                padding: \"same\"\r\n            }).apply(cnnLayer)\r\n            cnnLayer = tf.layers.batchNormalization({}).apply(cnnLayer)\r\n            cnnLayer = tf.layers.dropout({ rate: 0.05 }).apply(cnnLayer)\r\n        }\r\n\r\n        let value = tf.layers.conv1d({\r\n            filters: filters * 2,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(cnnLayer)\r\n        value = tf.layers.batchNormalization({}).apply(value)\r\n        value = tf.layers.conv1d({\r\n            filters: filters * 2,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(value)\r\n        value = tf.layers.batchNormalization({}).apply(value)\r\n        value = tf.layers.conv1d({\r\n            filters: actionNum,\r\n            kernelSize: [1],\r\n            activation: \"softmax\",\r\n            padding: \"same\"\r\n        }).apply(value)\r\n\r\n        let A = tf.layers.conv1d({\r\n            filters: filters * 2,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(cnnLayer)\r\n        A = tf.layers.batchNormalization({}).apply(A)\r\n        A = tf.layers.conv1d({\r\n            filters: filters * 2,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(A)\r\n        A = tf.layers.batchNormalization({}).apply(A)\r\n        A = tf.layers.conv1d({\r\n            filters: actionNum,\r\n            kernelSize: [1],\r\n            activation: \"softmax\",\r\n            padding: \"same\"\r\n        }).apply(A)\r\n\r\n        let mean = tfex.layers.lambda({\r\n            func: (x) => {\r\n                return tf.mean(x, 1, true)\r\n            },\r\n            outputShape: [1]\r\n        }).apply([A])\r\n\r\n        let advantage = tfex.layers.lambda({\r\n            func: (x, y) => {\r\n                return tf.sub(x, y)\r\n            }\r\n        }).apply([A, mean])\r\n\r\n        let Q = tf.layers.flatten().apply(\r\n            tf.layers.add().apply([value, advantage])\r\n        )\r\n        Q = tf.layers.softmax().apply(Q)\r\n\r\n        return tf.model({ inputs: [input], outputs: Q })\r\n    }\r\n\r\n    loss(arrayPrevS, arrayA, arrayR, arrayNextS) {\r\n        let calcTarget = (batchR, batchNextS) => {\r\n            return tf.tidy(() => {\r\n                const maxQ = tf.mul(\r\n                    tf.oneHot(this.model.predict(batchNextS).argMax(1), this.actionNum),\r\n                    this.targetModel.predict(batchNextS)\r\n                ).sum(1)\r\n                const targets = batchR.add(maxQ.mul(tf.scalar(0.99)));\r\n                return targets;\r\n            });\r\n        }\r\n        return tf.tidy(() => {\r\n            // console.log(arrayPrevS)\r\n            let batchPrevS = tf.tensor3d(arrayPrevS)\r\n            let batchA = tf.tensor1d(arrayA, 'int32')\r\n            let batchR = tf.tensor1d(arrayR)\r\n            let batchNextS = tf.tensor3d(arrayNextS)\r\n\r\n            const predictions = this.model.predict(batchPrevS);\r\n\r\n            const predMask = tf.oneHot(batchA, this.actionNum);\r\n\r\n            const targets = calcTarget(batchR, batchNextS)\r\n            return tf.losses.softmaxCrossEntropy(predMask.asType('float32'), predictions.sub(targets.expandDims(1)).square())\r\n            // return tf.mul(predictions[1].sub(targets.expandDims(1)).square(), predMask.asType('float32')).mean();\r\n        })\r\n\r\n    }\r\n\r\n    train(replayNum = 100, loadIdxes = [null], usePrioritizedReplay = false) {\r\n        tf.tidy(() => {\r\n            let train_ = (replayIdxes) => {\r\n                tf.tidy(() => {\r\n                    let arrayPrevS = []\r\n                    let arrayA = []\r\n                    let arrayR = []\r\n                    let arrayNextS = []\r\n\r\n                    for (let i = 0; i < replayNum; i++) {\r\n                        let data = this.load(replayIdxes[i])\r\n                        // console.log(data)\r\n                        arrayPrevS.push(data[0])\r\n                        arrayA.push(data[1])\r\n                        arrayR.push(data[2])\r\n                        arrayNextS.push(data[3])\r\n                    }\r\n\r\n                    let grads = this.optimizer.computeGradients(\r\n                        () => {\r\n                            let loss = this.loss(arrayPrevS, arrayA, arrayR, arrayNextS)\r\n                            loss.print()\r\n                            return loss\r\n                        }, this.model.getWeights(true)).grads\r\n\r\n                    let gradsName = Object.keys(grads)\r\n                    grads = tfex.funcs.clipByGlobalNorm(Object.values(grads), 0.05)[0]\r\n\r\n                    this.optimizer.applyGradients(gradsName.reduce((acc, gn, idx) => {\r\n                        acc[gn] = grads[idx]\r\n                        // if (gn == \"weighted_average_WeightedAverage1/w\") {\r\n                        //     acc[gn].print()\r\n                        // }\r\n                        return acc\r\n                    }, {}))\r\n\r\n                    this.count++\r\n\r\n                    this.optimizer.learningRate = (1e-4 / this.count ** 0.5) + this.minLearningRate\r\n\r\n                    if (this.count % this.updateTargetStep == 0) {\r\n                        this.targetModel.setWeights(this.model.getWeights())\r\n                        // this.count = 0\r\n                    }\r\n                })\r\n            }\r\n            if (this.memory.length != 0) {\r\n                if (usePrioritizedReplay) {\r\n                    let prioritizedReplayBuffer = tf.tidy(() => {\r\n                        let e = tf.tensor(this.memory.map(mem => mem[3]))\r\n                        e = tf.abs(e.sub(e.mean()))\r\n                        e = e.div(e.sum(0, true))\r\n                        // e.print()\r\n                        return tf.multinomial(e, replayNum, null, true).arraySync()\r\n                    })\r\n                    // console.log(prioritizedReplayBuffer)\r\n                    train_(prioritizedReplayBuffer.map((prioritizedReplayIdx, idx) => {\r\n                        return loadIdxes[idx] == null || loadIdxes[idx] == undefined ? prioritizedReplayIdx : loadIdxes[idx]\r\n                    }))\r\n                } else {\r\n                    train_(loadIdxes)\r\n                }\r\n            }\r\n        })\r\n    }\r\n\r\n    store(preState, action, reward, nextState) {\r\n        if (this.memory.length == this.memorySize) {\r\n            this.memory.pop()\r\n        }\r\n        this.memory.unshift([preState, action, reward, nextState])\r\n    }\r\n\r\n    load(index) {\r\n        if (index == null || index >= this.memory.length) {\r\n            index = Math.floor(Math.random() * this.memory.length);\r\n        }\r\n        return this.memory[index]\r\n    }\r\n\r\n}\r\n\r\nexport function dddqn({\r\n    sequenceLen = 60,\r\n    inputNum = 10,\r\n    embInner = [32, 32, 32],\r\n    filters = [8, 8, 8, 8],\r\n    outputInner = [32, 32],\r\n    actionNum = 8,\r\n    memorySize = 1000,\r\n    updateTargetStep = 20,\r\n    minLearningRate = 1e-3\r\n}) {\r\n    return new DDDQN({\r\n        sequenceLen,\r\n        inputNum,\r\n        embInner,\r\n        filters,\r\n        outputInner,\r\n        actionNum,\r\n        memorySize,\r\n        updateTargetStep,\r\n        minLearningRate\r\n    })\r\n}","export * from './model'","import * as tf from \"@tensorflow/tfjs\"\r\nimport { dddqn } from \"../../src/js/MirageNet/dddqn\"\r\nimport { registerTfex } from \"../../src/lib/tfjs-extensions/src\"\r\nconst tfex = registerTfex(tf)\r\n\r\ntf.setBackend(\"webgl\")\r\n\r\nlet actionNum = 9\r\n\r\nlet dddqnModel = dddqn({\r\n    sequenceLen: 64,\r\n    inputNum: 55,\r\n    filters: 32,\r\n    actionNum: actionNum,\r\n    memorySize: 3200,\r\n    minLearningRate: 1e-5,\r\n    updateTargetStep: 32\r\n})\r\n\r\nlet preArchive = {\r\n    \"player1\": {\r\n        state: null,\r\n        action: null,\r\n        expired: true\r\n    },\r\n    \"player2\": {\r\n        state: null,\r\n        action: null,\r\n        expired: true\r\n    }\r\n}\r\n\r\ntf.ready().then(() => {\r\n    let channel = self\r\n    channel.addEventListener(\"message\", (e) => {\r\n        tf.tidy(() => {\r\n            switch (e.data.instruction) {\r\n                case 'init': {\r\n                    channel.postMessage({ instruction: \"init\" })\r\n                    break\r\n                }\r\n                case 'ctrl': {\r\n                    if (Object.keys(e.data.args.archive).length != 0) {\r\n                        let outputActions = dddqnModel\r\n                            .model\r\n                            .predict(\r\n                                tf.tensor(\r\n                                    Object.values(e.data.args.archive)\r\n                                        .map(archive => {\r\n                                            return archive.state\r\n                                        })\r\n                                )\r\n                            )\r\n                        // outputActions.sum(1).print()\r\n                        // outputActions.print()\r\n\r\n                        let actions = []\r\n                        let chooseByArgMax = outputActions.argMax(1)\r\n                            .reshape([-1])\r\n                            .arraySync()\r\n                        let chooseByMultinomial = tf.multinomial(outputActions, 1, null, true)\r\n                            .reshape([-1])\r\n                            .arraySync()\r\n                        e.data.args.chooseAction.forEach((chooseAction, idx) => {\r\n                            if (chooseAction == \"argMax\") {\r\n                                actions[idx] = chooseByArgMax[idx]\r\n                            } else if (chooseAction == \"multinomial\") {\r\n                                actions[idx] = chooseByMultinomial[idx]\r\n                            }\r\n                        })\r\n\r\n\r\n                        Object.keys(preArchive).forEach((playerName) => {\r\n                            if (Object.keys(e.data.args.archive).find(name => name === playerName) !== undefined) {\r\n                                if (preArchive[playerName].expired == false) {\r\n                                    dddqnModel.store(\r\n                                        preArchive[playerName].state,\r\n                                        preArchive[playerName].action,\r\n                                        e.data.args.archive[playerName].reward,\r\n                                        e.data.args.archive[playerName].state,\r\n                                    )\r\n                                }\r\n                                preArchive[playerName].expired = false\r\n                            } else {\r\n                                preArchive[playerName].expired = true\r\n                            }\r\n                        })\r\n\r\n                        Object.keys(e.data.args.archive).forEach((playerName, idx) => {\r\n                            preArchive[playerName].state = e.data.args.archive[playerName].state\r\n                            preArchive[playerName].action = actions[idx]\r\n                        })\r\n                        channel.postMessage({\r\n                            instruction: \"ctrl\",\r\n                            args: {\r\n                                archive: Object.keys(e.data.args.archive).reduce((acc, name, idx) => {\r\n                                    acc[name] = {\r\n                                        action: actions[idx]\r\n                                    }\r\n                                    return acc\r\n                                }, {})\r\n                            }\r\n                        })\r\n                    } else {\r\n                        channel.postMessage({\r\n                            instruction: \"ctrl\",\r\n                            args: {\r\n                                archive: {}\r\n                            }\r\n                        })\r\n                    }\r\n                    // console.log(\"ctrl\")\r\n                    break\r\n                }\r\n                case 'train': {\r\n                    dddqnModel.train(e.data.args.bsz, e.data.args.replayIdxes, e.data.args.usePrioritizedReplay)\r\n                    channel.postMessage({ instruction: \"train\" })\r\n                    break\r\n                }\r\n                case 'save': {\r\n                    tf.tidy(() => {\r\n                        let Ws = dddqnModel.model.getWeights()\r\n                        let tList = Ws.reduce((acc, w) => {\r\n                            acc[w.name] = w\r\n                            return acc\r\n                        }, {})\r\n                        channel.postMessage({\r\n                            instruction: \"save\",\r\n                            args: {\r\n                                weightsBuffer: tfex.sl.save(tList)\r\n                            }\r\n                        })\r\n                    })\r\n\r\n                    break\r\n                }\r\n                case 'load': {\r\n                    let loadWeights = tfex.sl.load(e.data.args.weightsBuffer)\r\n                    dddqnModel.model.getWeights().forEach((w) => {\r\n                        w.assign(loadWeights[w.name])\r\n                    })\r\n                    dddqnModel.targetModel.setWeights(\r\n                        dddqnModel.model.getWeights()\r\n                    )\r\n                    channel.postMessage({ instruction: \"load\" })\r\n                    break\r\n                }\r\n            }\r\n        })\r\n    })\r\n})"]}