{"version":3,"sources":["../src/js/MirageNet/dddqn/model.js","../src/js/MirageNet/dddqn/index.js","js/agent.js"],"names":["tfex","tf","DDDQN","sequenceLen","inputNum","embInner","filters","outputInner","actionNum","memorySize","updateTargetStep","learningRate","count","model","buildModel2","summary","targetModel","setWeights","getWeights","memory","optimizer","train","adam","input","shape","preASV","embLayer","layers","dense","units","activation","apply","i","length","reshape","targetShape","dropout","rate","cnnLayer","conv2d","kernelSize","padding","Math","floor","strides","flattenLayer","flatten","outputLayer","value","A","mean","lambda","func","x","outputShape","advantage","y","sub","Q","add","ASV","softmax","AAV","div","max","stack","WeightedAverage","args","Layer","inputShape","w","addWeight","initializers","constant","built","inputs","kwargs","invokeCallHook","mul","read","serialization","registerClass","action","outputs","WeightedSequence","axis","script","write","sin","linspace","PI","funcs","einsum","WSLayer","conv1d","batchNormalization","tidy","aav","relu","sum","arrayPrevS","arrayPrevASV","arrayA","arrayR","arrayNextS","arrayNextASV","batchPrevS","tensor3d","batchPrevASV","tensor2d","batchA","tensor1d","batchR","batchNextS","predictions","predict","maxQ","predMask","oneHot","targets","scalar","expandDims","square","asType","replayNum","loadIdxes","usePrioritizedReplay","train_","replayIdxes","data","load","push","grads","computeGradients","loss","print","gradsName","Object","keys","clipByGlobalNorm","values","applyGradients","reduce","acc","gn","idx","e","tensor","map","mem","abs","multinomial","array","then","prioritizedReplayBuffer","prioritizedReplayIdx","undefined","preState","reward","nextState","nextASV","pop","unshift","index","random","dddqn","setBackend","dddqnModel","preArchive","state","fill","expired","ready","channel","self","addEventListener","instruction","postMessage","archive","ASVsAndActions","playerName","actions","chooseByArgMax","argMax","arraySync","chooseByMultinomial","chooseAction","forEach","find","name","store","dispose","keep","unstack","bsz","Ws","tList","weightsBuffer","sl","save","loadWeights","assign"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmfC,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,MAAA,EAAA,QAAA,WAAA,EAnfD,IAAA,EAAA,EAAA,QAAA,qBACA,EAAA,QAAA,oCAkfC,SAAA,IAAA,GAAA,mBAAA,QAAA,OAAA,KAAA,IAAA,EAAA,IAAA,QAAA,OAAA,EAAA,WAAA,OAAA,GAAA,EAAA,SAAA,EAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,IAAA,GAAA,GAAA,EAAA,IAAA,GAAA,OAAA,EAAA,IAAA,GAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,CAAA,IAAA,EAAA,OAAA,gBAAA,OAAA,yBAAA,IAAA,IAAA,KAAA,EAAA,GAAA,OAAA,UAAA,eAAA,KAAA,EAAA,GAAA,CAAA,IAAA,EAAA,EAAA,OAAA,yBAAA,EAAA,GAAA,KAAA,IAAA,EAAA,KAAA,EAAA,KAAA,OAAA,eAAA,EAAA,EAAA,GAAA,EAAA,GAAA,EAAA,IAAA,OAAA,EAAA,QAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EAAA,SAAA,EAAA,GAAA,OAAA,EAAA,mBAAA,QAAA,iBAAA,OAAA,SAAA,SAAA,GAAA,cAAA,GAAA,SAAA,GAAA,OAAA,GAAA,mBAAA,QAAA,EAAA,cAAA,QAAA,IAAA,OAAA,UAAA,gBAAA,IAAA,GAAA,SAAA,EAAA,EAAA,GAAA,OAAA,GAAA,WAAA,EAAA,IAAA,mBAAA,EAAA,EAAA,GAAA,EAAA,SAAA,EAAA,GAAA,QAAA,IAAA,EAAA,MAAA,IAAA,eAAA,6DAAA,OAAA,EAAA,SAAA,EAAA,GAAA,OAAA,EAAA,OAAA,eAAA,OAAA,eAAA,SAAA,GAAA,OAAA,EAAA,WAAA,OAAA,eAAA,KAAA,GAAA,SAAA,EAAA,EAAA,GAAA,GAAA,mBAAA,GAAA,OAAA,EAAA,MAAA,IAAA,UAAA,sDAAA,EAAA,UAAA,OAAA,OAAA,GAAA,EAAA,UAAA,CAAA,YAAA,CAAA,MAAA,EAAA,UAAA,EAAA,cAAA,KAAA,GAAA,EAAA,EAAA,GAAA,SAAA,EAAA,EAAA,GAAA,OAAA,EAAA,OAAA,gBAAA,SAAA,EAAA,GAAA,OAAA,EAAA,UAAA,EAAA,IAAA,EAAA,GAAA,SAAA,EAAA,EAAA,GAAA,KAAA,aAAA,GAAA,MAAA,IAAA,UAAA,qCAAA,SAAA,EAAA,EAAA,GAAA,IAAA,IAAA,EAAA,EAAA,EAAA,EAAA,OAAA,IAAA,CAAA,IAAA,EAAA,EAAA,GAAA,EAAA,WAAA,EAAA,aAAA,EAAA,EAAA,cAAA,EAAA,UAAA,IAAA,EAAA,UAAA,GAAA,OAAA,eAAA,EAAA,EAAA,IAAA,IAAA,SAAA,EAAA,EAAA,EAAA,GAAA,OAAA,GAAA,EAAA,EAAA,UAAA,GAAA,GAAA,EAAA,EAAA,GAAA,EAjfD,IAAMA,GAAO,EAAaC,EAAAA,cAAAA,GAEbC,EA+eZ,WApeM,SAAA,EAAA,GATCC,IAAAA,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,GASf,EARCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,GAQZ,EAPCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,CAAC,GAAI,GAAI,IAOrB,EANCC,EAAAA,EAAAA,QAAAA,OAAU,IAAA,EAAA,CAAC,EAAG,EAAG,EAAG,GAMrB,EALCC,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,CAAC,GAAI,IAKpB,EAJCC,EAAAA,EAAAA,UAAAA,OAAY,IAAA,EAAA,EAIb,EAHCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,IAGd,EAFCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,GAEpB,EADCC,EAAAA,EAAAA,aAAAA,OAAe,IAAA,EAAA,KAChB,EAAA,EAAA,KAAA,GAGUD,KAAAA,iBAAmBA,EAEnBE,KAAAA,MAAQ,EAERJ,KAAAA,UAAYA,EAIZK,KAAAA,MAAQ,KAAKC,YAAY,CAC1BX,YAAaA,EACbC,SAAUA,EACVC,SAAUA,EACVC,QAASA,EACTC,YAAaA,EACbC,UAAWA,IAEVK,KAAAA,MAAME,UAENC,KAAAA,YAAc,KAAKF,YAAY,CAChCX,YAAaA,EACbC,SAAUA,EACVC,SAAUA,EACVC,QAASA,EACTC,YAAaA,EACbC,UAAWA,IAGVQ,KAAAA,YAAYC,WAAW,KAAKJ,MAAMK,cAIlCT,KAAAA,WAAaA,EACbU,KAAAA,OAAS,GAITC,KAAAA,UAAYnB,EAAGoB,MAAMC,KAAKX,GA6b1C,OAAA,EAAA,EAAA,CAAA,CAAA,IAAA,aA/aK,MAAA,SAAA,GAKO,IAZDR,IAAAA,EAAAA,EAAAA,YACAC,EAAAA,EAAAA,SACAC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,CAAC,GAAI,GAAI,IAK1B,EAJMC,EAAAA,EAAAA,QAAAA,OAAU,IAAA,EAAA,CAAC,GAAI,GAAI,IAIzB,EAHMC,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,CAAC,GAAI,IAGzB,EAFMC,EAAAA,EAAAA,UAAAA,OAAY,IAAA,EAAA,GAElB,EACMe,EAAQtB,EAAGsB,MAAM,CAAEC,MAAO,CAACrB,EAAaC,KACxCqB,EAASxB,EAAGsB,MAAM,CAAEC,MAAO,CAAChB,KAE5BkB,EAAWzB,EAAG0B,OAAOC,MAAM,CAAEC,MAAOxB,EAAS,GAAIyB,WAAY,SAAUC,MAAMR,GACxES,EAAI,EAAGA,EAAI3B,EAAS4B,OAAQD,IACjCN,EAAWzB,EAAG0B,OAAOC,MAAM,CAAEC,MAAOxB,EAAS2B,GAAIF,WAAY,SAAUC,MAAML,GAEjFA,EAAWzB,EAAG0B,OAAOO,QAAQ,CAAEC,YAAa,CAAChC,EAAaE,EAASA,EAAS4B,OAAS,GAAI,KAAMF,MAAML,GACrGA,EAAWzB,EAAG0B,OAAOS,QAAQ,CAAEC,KAAM,KAAON,MAAML,GAQ7C,IANDY,IAAAA,EAAWrC,EAAG0B,OAAOY,OAAO,CAC5BjC,QAASA,EAAQ,GACjBkC,WAAY,CAAC,EAAGnC,EAASA,EAAS4B,OAAS,IAC3CH,WAAY,OACZW,QAAS,SACVV,MAAML,GACAM,EAAI,EAAGA,EAAI1B,EAAQ2B,OAAS,EAAGD,IACpCM,EAAWrC,EAAG0B,OAAOY,OAAO,CACxBjC,QAASA,EAAQ0B,GACjBQ,WAAY,CAACR,EAAIU,KAAKC,MAAMxC,EAAcG,EAAQ2B,QAAS5B,EAASA,EAAS4B,OAAS,IACtFH,WAAY,OACZW,QAAS,SACVV,MAAMO,GAEbA,EAAWrC,EAAG0B,OAAOY,OAAO,CACxBjC,QAASA,EAAQA,EAAQ2B,OAAS,GAClCO,WAAY,CAACrC,EAAaE,EAASA,EAAS4B,OAAS,IACrDW,QAAS,CAACzC,EAAaE,EAASA,EAAS4B,OAAS,IAClDH,WAAY,OACZW,QAAS,SACVV,MAAMO,GAELO,IAAAA,EAAe5C,EAAG0B,OAAOmB,UAAUf,MAAMO,GAC7CO,EAAe5C,EAAG0B,OAAOS,QAAQ,CAAEC,KAAM,KAAON,MAAMc,GAGjD,IADDE,IAAAA,EAAc9C,EAAG0B,OAAOC,MAAM,CAAEC,MAAOtB,EAAY,GAAIuB,WAAY,SAAUC,MAAMc,GAC9Eb,EAAI,EAAGA,EAAIzB,EAAY0B,OAAQD,IACpCe,EAAc9C,EAAG0B,OAAOC,MAAM,CAAEC,MAAOtB,EAAYyB,GAAIF,WAAY,SAAUC,MAAMgB,GAEvFA,EAAc9C,EAAG0B,OAAOC,MAAM,CAAEC,MAAOrB,EAAWsB,WAAY,SAAUC,MAAMgB,GAC9EA,EAAc9C,EAAG0B,OAAOS,QAAQ,CAAEC,KAAM,KAAON,MAAMgB,GAEjDC,IAAAA,EAAQ/C,EAAG0B,OAAOC,MAAM,CACxBC,MAAOrB,EACPsB,WAAY,SACbC,MAAMgB,GAELE,EAAIhD,EAAG0B,OAAOC,MAAM,CACpBC,MAAOrB,EACPsB,WAAY,SACbC,MAAMgB,GAELG,EAAOlD,EAAK2B,OAAOwB,OAAO,CAC1BC,KAAM,SAACC,GACIpD,OAAAA,EAAGiD,KAAKG,EAAG,GAAG,IAEzBC,YAAa,CAAC,KACfvB,MAAM,CAACkB,IAENM,EAAYvD,EAAK2B,OAAOwB,OAAO,CAC/BC,KAAM,SAACC,EAAGG,GACCvD,OAAAA,EAAGwD,IAAIJ,EAAGG,MAEtBzB,MAAM,CAACkB,EAAGC,IAETQ,EAAIzD,EAAG0B,OAAOgC,MAAM5B,MAAM,CAACiB,EAAOO,IAGlCK,EAAM3D,EAAG0B,OAAOkC,UAAU9B,MAAM2B,GAGhCI,EAAM9D,EAAK2B,OAAOwB,OAAO,CACzBC,KAAM,SAACQ,EAAKnC,GACDxB,OAAAA,EAAG8D,IAAI9D,EAAGwD,IAAIG,EAAKnC,GAASxB,EAAG+D,IAAI/D,EAAGgE,MAAM,CAACL,EAAKnC,IAAU,OAExEM,MAAM,CAAC6B,EAAKnC,IAITyC,EAhFR,SAAA,GAiFkBC,SAAAA,EAAAA,GACF,OADQ,EAAA,KAAA,GACR,EAAA,KAAA,EAAA,GAAA,KAAA,KAAA,KAlFhB,OAAA,EAAA,EAgFgClE,EAAG0B,OAAOyC,OAhF1C,EAAA,EAAA,CAAA,CAAA,IAAA,QAoFYC,MAAAA,SAAAA,GAEGC,KAAAA,EAAI,KAAKC,UAAU,IAAK,CAACF,EAAW,GAAGA,EAAWpC,OAAS,IAAK,UAAWhC,EAAGuE,aAAaC,SAAS,CAAEzB,MAAO,MAC7G0B,KAAAA,OAAQ,IAvFvB,CAAA,IAAA,qBAyFyBL,MAAAA,SAAAA,GAGRA,OAAAA,EAAW,KA5F5B,CAAA,IAAA,OA8FWM,MAAAA,SAAAA,EAAQC,GAGF3E,OADF4E,KAAAA,eAAeF,EAAQC,GACrB3E,EAAG0D,IACN1D,EAAG6E,IAAIH,EAAO,GAAI,KAAKL,EAAES,QACzB9E,EAAG6E,IAAIH,EAAO,GAAI1E,EAAGwD,IAAI,EAAG,KAAKa,EAAES,aAnGjD,CAAA,CAAA,IAAA,YA2G6B,IAAA,WACZ,MAAA,sBA5GjB,EAAA,GAgHE9E,EAAG+E,cAAcC,cAAcf,GAE3BgB,IAAAA,GAAS,IAAIhB,GAAkBnC,MAAM,CAAC6B,EAAKE,IAGxC7D,OAAAA,EAAGY,MAAM,CAAE8D,OAAQ,CAACpD,EAAOE,GAAS0D,QAAS,CAACvB,EAAKsB,OA0TjE,CAAA,IAAA,cAhTK,MAAA,SAAA,GALM/E,IAAAA,EAAAA,EAAAA,YACAC,EAAAA,EAAAA,SACAE,EAAAA,EAAAA,QAAAA,OAAU,IAAA,EAAA,EAGhB,EAFME,EAAAA,EAAAA,UAAAA,OAAY,IAAA,EAAA,GAElB,EACMe,EAAQtB,EAAGsB,MAAM,CAAEC,MAAO,CAACrB,EAAaC,KACxCqB,EAASxB,EAAGsB,MAAM,CAAEC,MAAO,CAAChB,KAE1B4E,EAJR,SAAA,GAK2C,SAAA,IAAA,IAAA,EAAzBjB,EAAO,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,CAAEkB,KAAAA,KAAMC,OAAAA,QAAU,OAAA,EAAA,KAAA,IAC3B,EAAA,EAAA,KAAA,EAAA,GAAA,KAAA,KAAA,MACDD,KAAOlB,EAAKkB,KACZC,EAAAA,OAASnB,EAAKmB,OAHc,EAL3C,OAAA,EAAA,EAIiCrF,EAAG0B,OAAOyC,OAJ3C,EAAA,EAAA,CAAA,CAAA,IAAA,QAUYC,MAAAA,SAAAA,GACGC,KAAAA,EAAI,KAAKC,UAAU,IAAK,CAACF,EAAW,KAAKgB,OAAQ,UAAWpF,EAAGuE,aAAaC,SAAS,CAAEzB,MAAO,MAC9FsB,KAAAA,EAAEiB,MAAMtF,EAAGuF,IAAIvF,EAAGwF,SAAS/C,KAAKgD,GAAK,EAAG,GAAKrB,EAAW,KAAKgB,SAC7DX,KAAAA,OAAQ,IAbvB,CAAA,IAAA,qBAeyBL,MAAAA,SAAAA,GACRA,OAAAA,IAhBjB,CAAA,IAAA,OAkBWM,MAAAA,SAAAA,EAAQC,GAGF5E,OADF6E,KAAAA,eAAeF,EAAQC,GACrB5E,EAAK2F,MAAMC,OAAO,KAAKN,OAAQX,EAAO,GAAI,KAAKL,EAAES,WArBlE,CAAA,CAAA,IAAA,YA4B6B,IAAA,WACZ,MAAA,uBA7BjB,EAAA,GAiCE9E,EAAG+E,cAAcC,cAAcG,GAE3BS,IAAAA,EAAU,IAAIT,EAAiB,CAAEC,KAAM,EAAGC,OAAQ,eAAgBvD,MAAMR,GAExEe,EAAWrC,EAAG0B,OAAOmE,OAAO,CAC5BxF,QAAmB,EAAVA,EACTkC,WAAY,CAAC,GACbV,WAAY,OACZW,QAAS,SACVV,MAAM8D,GAUF,IATPvD,EAAWrC,EAAG0B,OAAOmE,OAAO,CACxBxF,QAAmB,EAAVA,EACTkC,WAAY,CAAC,GACbV,WAAY,OACZW,QAAS,SACVV,MAAMO,GAETA,EAAWrC,EAAG0B,OAAOS,QAAQ,CAAEC,KAAM,KAAON,MAAMO,GAE3C,GAAKA,EAASd,MAAM,GAAK,GAC5Bc,EAAWrC,EAAG0B,OAAOmE,OAAO,CACxBxF,QAASA,EACTkC,WAAY,CAAC,GACbI,QAAS,CAAC,GACVd,WAAY,OACZW,QAAS,SACVV,MAAMO,GACTA,EAAWrC,EAAG0B,OAAOoE,mBAAmB,IAAIhE,MAAMO,GAGlDU,IAAAA,EAAQ/C,EAAG0B,OAAOmE,OAAO,CACzBxF,QAAmB,EAAVA,EACTkC,WAAY,CAAC,GACbV,WAAY,OACZW,QAAS,SACVV,MAAMO,GACTU,EAAQ/C,EAAG0B,OAAOmE,OAAO,CACrBxF,QAAmB,EAAVA,EACTkC,WAAY,CAAC,GACbV,WAAY,OACZW,QAAS,SACVV,MAAMiB,GAETA,EAAQ/C,EAAG0B,OAAOmE,OAAO,CACrBxF,QAASE,EACTgC,WAAY,CAAC,GACbV,WAAY,OACZW,QAAS,SACVV,MAAMiB,GAELC,IAAAA,EAAIhD,EAAG0B,OAAOmE,OAAO,CACrBxF,QAAmB,EAAVA,EACTkC,WAAY,CAAC,GACbV,WAAY,OACZW,QAAS,SACVV,MAAMO,GACTW,EAAIhD,EAAG0B,OAAOmE,OAAO,CACjBxF,QAAmB,EAAVA,EACTkC,WAAY,CAAC,GACbV,WAAY,OACZW,QAAS,SACVV,MAAMkB,GAETA,EAAIhD,EAAG0B,OAAOmE,OAAO,CACjBxF,QAASE,EACTgC,WAAY,CAAC,GACbV,WAAY,OACZW,QAAS,SACVV,MAAMkB,GAELC,IAAAA,EAAOlD,EAAK2B,OAAOwB,OAAO,CAC1BC,KAAM,SAACC,GACIpD,OAAAA,EAAGiD,KAAKG,EAAG,GAAG,IAEzBC,YAAa,CAAC,KACfvB,MAAM,CAACkB,IAENM,EAAYvD,EAAK2B,OAAOwB,OAAO,CAC/BC,KAAM,SAACC,EAAGG,GACCvD,OAAAA,EAAGwD,IAAIJ,EAAGG,MAEtBzB,MAAM,CAACkB,EAAGC,IAETQ,EAAIzD,EAAG0B,OAAOmB,UAAUf,MACxB9B,EAAG0B,OAAOgC,MAAM5B,MAAM,CAACiB,EAAOO,KAI9BK,EAAM3D,EAAG0B,OAAOkC,UAAU9B,MAAM2B,GAGhCI,EAAM9D,EAAK2B,OAAOwB,OAAO,CACzBC,KAAM,SAACQ,EAAKnC,GACDxB,OAAAA,EAAG+F,KAAK,WACPC,IAAAA,EAAMhG,EAAGwD,IAAIG,EAAKnC,GAGfwE,OAFPA,EAAMhG,EAAGiG,KAAKD,GACdA,EAAMhG,EAAG8D,IAAIkC,EAAKA,EAAIE,IAAI,GAAG,SAItCpE,MAAM,CAAC6B,EAAKnC,IAITyC,EAzIR,SAAA,GA0IkBC,SAAAA,EAAAA,GACF,OADQ,EAAA,KAAA,GACR,EAAA,KAAA,EAAA,GAAA,KAAA,KAAA,KA3IhB,OAAA,EAAA,EAyIgClE,EAAG0B,OAAOyC,OAzI1C,EAAA,EAAA,CAAA,CAAA,IAAA,QA6IYC,MAAAA,SAAAA,GAEGC,KAAAA,EAAI,KAAKC,UAAU,IAAK,CAACF,EAAW,GAAGA,EAAWpC,OAAS,IAAK,UAAWhC,EAAGuE,aAAaC,SAAS,CAAEzB,MAAO,MAC7G0B,KAAAA,OAAQ,IAhJvB,CAAA,IAAA,qBAkJyBL,MAAAA,SAAAA,GAGRA,OAAAA,EAAW,KArJ5B,CAAA,IAAA,OAuJWM,MAAAA,SAAAA,EAAQC,GAGF3E,OADF4E,KAAAA,eAAeF,EAAQC,GACrB3E,EAAG0D,IACN1D,EAAG6E,IAAIH,EAAO,GAAI,KAAKL,EAAES,QACzB9E,EAAG6E,IAAIH,EAAO,GAAI1E,EAAGwD,IAAI,EAAG,KAAKa,EAAES,aA5JjD,CAAA,CAAA,IAAA,YAoK6B,IAAA,WACZ,MAAA,sBArKjB,EAAA,GAyKE9E,EAAG+E,cAAcC,cAAcf,GAE3BgB,IAAAA,GAAS,IAAIhB,GAAkBnC,MAAM,CAAC6B,EAAKE,IAExC7D,OAAAA,EAAGY,MAAM,CAAE8D,OAAQ,CAACpD,EAAOE,GAAS0D,QAAS,CAACvB,EAAKsB,OAmIjE,CAAA,IAAA,OAhIQkB,MAAAA,SAAAA,EAAYC,EAAcC,EAAQC,EAAQC,EAAYC,GAAc,IAAA,EAAA,KAC9DxG,OAAAA,EAAG+F,KAAK,WAEPU,IAAAA,EAAazG,EAAG0G,SAASP,GACzBQ,EAAe3G,EAAG4G,SAASR,GAC3BS,EAAS7G,EAAG8G,SAAST,EAAQ,SAC7BU,EAAS/G,EAAG8G,SAASR,GACrBU,EAAahH,EAAG0G,SAASH,GAGvBU,GAFajH,EAAG4G,SAASJ,GAEX,EAAK5F,MAAMsG,QAAQ,CAACT,EAAYE,KAE9CQ,EAAO,EAAKpG,YAAYmG,QAAQ,CAACF,EAAYC,EAAY,KAAK,GAAGhF,QAAQ,CAACkE,EAAWnE,OAAQ,EAAKzB,YAAYwD,IAAI,GAElHqD,EAAWpH,EAAGqH,OAAOR,EAAQ,EAAKtG,WAElC+G,EAAUP,EAAOrD,IAAIyD,EAAKtC,IAAI7E,EAAGuH,OAAO,OAEvCvH,OAAAA,EAAG6E,IAAIoC,EAAY,GAAGzD,IAAI8D,EAAQE,WAAW,IAAIC,SAAUL,EAASM,OAAO,YAAYzE,WA8GzG,CAAA,IAAA,QAzG4E,MAAA,WAAA,IAAA,EAAA,KAAnE0E,EAAY,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,IAAKC,EAAY,UAAA,OAAA,QAAA,IAAA,UAAA,GAAA,UAAA,GAAA,CAAC,MAAOC,EAAuB,UAAA,OAAA,QAAA,IAAA,UAAA,IAAA,UAAA,GAC9D7H,EAAG+F,KAAK,WACA+B,IAAAA,EAAS,SAACC,GACV/H,EAAG+F,KAAK,WAQC,IAPDI,IAAAA,EAAa,GACbC,EAAe,GACfC,EAAS,GACTC,EAAS,GACTC,EAAa,GACbC,EAAe,GAEVzE,EAAI,EAAGA,EAAI4F,EAAW5F,IAAK,CAC5BiG,IAAAA,EAAO,EAAKC,KAAKF,EAAYhG,IAEjCoE,EAAW+B,KAAKF,EAAK,IACrB5B,EAAa8B,KAAKF,EAAK,IACvB3B,EAAO6B,KAAKF,EAAK,IACjB1B,EAAO4B,KAAKF,EAAK,IACjBzB,EAAW2B,KAAKF,EAAK,IACrBxB,EAAa0B,KAAKF,EAAK,IAGvBG,IAAAA,EAAQ,EAAKhH,UAAUiH,iBACvB,WACQC,IAAAA,EAAO,EAAKA,KAAKlC,EAAYC,EAAcC,EAAQC,EAAQC,EAAYC,GAEpE6B,OADPA,EAAKC,QACED,GACR,EAAKzH,MAAMK,YAAW,IAAOkH,MAEhCI,EAAYC,OAAOC,KAAKN,GAC5BA,EAAQpI,EAAK2F,MAAMgD,iBAAiBF,OAAOG,OAAOR,GAAQ,KAAM,GAEhE,EAAKhH,UAAUyH,eAAeL,EAAUM,OAAO,SAACC,EAAKC,EAAIC,GAE9CF,OADPA,EAAIC,GAAMZ,EAAMa,GACTF,GACR,KAEH,EAAKnI,QAED,EAAKA,OAAS,EAAKF,mBAEnB,EAAKM,YAAYC,WAAW,EAAKJ,MAAMK,cACvC,EAAKN,MAAQ,MAIC,GAAtB,EAAKO,OAAOc,SACR6F,EACA7H,EAAG+F,KAAK,WACAkD,IAAAA,EAAIjJ,EAAGkJ,OAAO,EAAKhI,OAAOiI,IAAI,SAAAC,GAAOA,OAAAA,EAAI,MAItCpJ,OAFPiJ,GADAA,EAAIjJ,EAAGqJ,IAAIJ,EAAEzF,IAAIyF,EAAEhG,UACba,IAAImF,EAAE/C,IAAI,GAAG,IAEZlG,EAAGsJ,YAAYL,EAAGtB,EAAW,MAAM,KAC3C4B,QAAQC,KAAK,SAAAC,GAEZ3B,EAAO2B,EAAwBN,IAAI,SAACO,EAAsBV,GAC/CpB,OAAkB,MAAlBA,EAAUoB,IAAkCW,MAAlB/B,EAAUoB,GAAoBU,EAAuB9B,EAAUoB,QAIxGlB,EAAOF,QA4C1B,CAAA,IAAA,QAtCSgC,MAAAA,SAAAA,EAAUpI,EAAQyD,EAAQ4E,EAAQC,EAAWC,GAC3C,KAAK7I,OAAOc,QAAU,KAAKxB,YACtBU,KAAAA,OAAO8I,MAEX9I,KAAAA,OAAO+I,QAAQ,CAACL,EAAUpI,EAAQyD,EAAQ4E,EAAQC,EAAWC,MAkCzE,CAAA,IAAA,OA/BQG,MAAAA,SAAAA,GAIM,OAHM,MAATA,GAAiBA,GAAS,KAAKhJ,OAAOc,UACtCkI,EAAQzH,KAAKC,MAAMD,KAAK0H,SAAW,KAAKjJ,OAAOc,SAE5C,KAAKd,OAAOgJ,OA2B1B,EAAA,GAtBM,SAASE,EAUb,GATClK,IAAAA,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,GASf,EARCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,GAQZ,EAPCC,EAAAA,EAAAA,SAAAA,OAAW,IAAA,EAAA,CAAC,GAAI,GAAI,IAOrB,EANCC,EAAAA,EAAAA,QAAAA,OAAU,IAAA,EAAA,CAAC,EAAG,EAAG,EAAG,GAMrB,EALCC,EAAAA,EAAAA,YAAAA,OAAc,IAAA,EAAA,CAAC,GAAI,IAKpB,EAJCC,EAAAA,EAAAA,UAAAA,OAAY,IAAA,EAAA,EAIb,EAHCC,EAAAA,EAAAA,WAAAA,OAAa,IAAA,EAAA,IAGd,EAFCC,EAAAA,EAAAA,iBAAAA,OAAmB,IAAA,EAAA,GAEpB,EADCC,EAAAA,EAAAA,aAEO,OAAA,IAAIT,EAAM,CACbC,YAAAA,EACAC,SAAAA,EACAC,SAAAA,EACAC,QAAAA,EACAC,YAAAA,EACAC,UAAAA,EACAC,WAAAA,EACAC,iBAAAA,EACAC,kBAXW,IAAA,EAAA,KAChB,IAYF,QAAA,MAAA;;ACnfD,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,IAAA,EAAA,QAAA,WAAA,OAAA,KAAA,GAAA,QAAA,SAAA,GAAA,YAAA,GAAA,eAAA,GAAA,OAAA,eAAA,QAAA,EAAA,CAAA,YAAA,EAAA,IAAA,WAAA,OAAA,EAAA;;ACoCA,aApCA,IAAA,EAAA,EAAA,QAAA,qBACA,EAAA,QAAA,gCACA,EAAA,QAAA,qCAkCA,SAAA,IAAA,GAAA,mBAAA,QAAA,OAAA,KAAA,IAAA,EAAA,IAAA,QAAA,OAAA,EAAA,WAAA,OAAA,GAAA,EAAA,SAAA,EAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,IAAA,GAAA,GAAA,EAAA,IAAA,GAAA,OAAA,EAAA,IAAA,GAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,CAAA,IAAA,EAAA,OAAA,gBAAA,OAAA,yBAAA,IAAA,IAAA,KAAA,EAAA,GAAA,OAAA,UAAA,eAAA,KAAA,EAAA,GAAA,CAAA,IAAA,EAAA,EAAA,OAAA,yBAAA,EAAA,GAAA,KAAA,IAAA,EAAA,KAAA,EAAA,KAAA,OAAA,eAAA,EAAA,EAAA,GAAA,EAAA,GAAA,EAAA,IAAA,OAAA,EAAA,QAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EAjCA,IAAMX,GAAO,EAAaC,EAAAA,cAAAA,GAE1BA,EAAGqK,WAAW,SAEd,IAAI9J,EAAY,EAEZ+J,GAAa,EAAM,EAAA,OAAA,CACnBpK,YAAa,KACbC,SAAU,GACVE,QAAS,GACTE,UAAWA,EACXC,WAAY,KACZE,aAAc,KACdD,iBAAkB,KAGlB8J,EAAa,CACF,QAAA,CACPC,MAAO,KACP7G,IAAK3D,EAAGyK,KAAK,CAAClK,GAAY,KAAM,WAChCiB,OAAQxB,EAAGyK,KAAK,CAAClK,GAAY,KAAM,WACnC0E,OAAQ,KACRyF,SAAS,GAEF,QAAA,CACPF,MAAO,KACP7G,IAAK3D,EAAGyK,KAAK,CAAClK,GAAY,KAAM,WAChCiB,OAAQxB,EAAGyK,KAAK,CAAClK,GAAY,KAAM,WACnC0E,OAAQ,KACRyF,SAAS,IAIjB1K,EAAG2K,QAAQnB,KAAK,WACRoB,IAAAA,EAAUC,KACdD,EAAQE,iBAAiB,UAAW,SAAC7B,GACjCjJ,EAAG+F,KAAK,WACIkD,OAAAA,EAAEjB,KAAK+C,aACN,IAAA,OACDH,EAAQI,YAAY,CAAED,YAAa,SACnC,MAEC,IAAA,OACGvC,GAA2C,GAA3CA,OAAOC,KAAKQ,EAAEjB,KAAK9D,KAAK+G,SAASjJ,OAAa,CAC1CkJ,IAAAA,EAAiBZ,EAChB1J,MACAsG,QAAQ,CACLlH,EAAGkJ,OACCV,OAAOG,OAAOM,EAAEjB,KAAK9D,KAAK+G,SACrB9B,IAAI,SAAA8B,GACMA,OAAAA,EAAQT,SAG3BxK,EAAGgE,MACCwE,OAAOC,KAAKQ,EAAEjB,KAAK9D,KAAK+G,SACnB9B,IAAI,SAAAgC,GACMZ,OAAAA,EAAWY,GAAYxH,SAM9CyH,EAAU,GACVC,EAAiBH,EAAe,GAAGI,OAAO,GAEzCrJ,QAAQ,EAAE,IACVsJ,YACDC,EAAsBxL,EAAGsJ,YAAY4B,EAAe,GAAI,EAAG,MAAM,GAEhEjJ,QAAQ,EAAE,IACVsJ,YACLtC,EAAEjB,KAAK9D,KAAKuH,aAAaC,QAAQ,SAACD,EAAczC,GACxB,UAAhByC,EACAL,EAAQpC,GAAOqC,EAAerC,GACP,eAAhByC,IACPL,EAAQpC,GAAOwC,EAAoBxC,MAK3CR,OAAOC,KAAK8B,GAAYmB,QAAQ,SAACP,QAC8CxB,IAAvEnB,OAAOC,KAAKQ,EAAEjB,KAAK9D,KAAK+G,SAASU,KAAK,SAAAC,GAAQA,OAAAA,IAAST,KACjB,GAAlCZ,EAAWY,GAAYT,SACvBJ,EAAWuB,MACPtB,EAAWY,GAAYX,MACvBD,EAAWY,GAAY3J,OAAO+J,YAC9BhB,EAAWY,GAAYlG,OACvBgE,EAAEjB,KAAK9D,KAAK+G,QAAQE,GAAYtB,OAChCZ,EAAEjB,KAAK9D,KAAK+G,QAAQE,GAAYX,MAChCD,EAAWY,GAAYxH,IAAI4H,aAGnChB,EAAWY,GAAYT,SAAU,GAEjCH,EAAWY,GAAYT,SAAU,IAIzClC,OAAOC,KAAKQ,EAAEjB,KAAK9D,KAAK+G,SAASS,QAAQ,SAACP,EAAYnC,GAClDuB,EAAWY,GAAYX,MAAQvB,EAAEjB,KAAK9D,KAAK+G,QAAQE,GAAYX,MAC/DxK,EAAG8L,QAAQvB,EAAWY,GAAY3J,QAClC+I,EAAWY,GAAY3J,OAASxB,EAAG+L,KAAKxB,EAAWY,GAAYxH,KAC/D4G,EAAWY,GAAYxH,IAAM3D,EAAG+L,KAAK/L,EAAGgM,QAAQd,EAAe,IAAIlC,IACnEuB,EAAWY,GAAYlG,OAASmG,EAAQpC,KAE5C4B,EAAQI,YAAY,CAChBD,YAAa,OACb7G,KAAM,CACF+G,QAASzC,OAAOC,KAAKQ,EAAEjB,KAAK9D,KAAK+G,SAASpC,OAAO,SAACC,EAAK8C,EAAM5C,GAIlDF,OAHPA,EAAI8C,GAAQ,CACR3G,OAAQmG,EAAQpC,IAEbF,GACR,YAIX8B,EAAQI,YAAY,CAChBD,YAAa,OACb7G,KAAM,CACF+G,QAAS,MAKrB,MAEC,IAAA,QACDX,EAAWlJ,MAAM6H,EAAEjB,KAAK9D,KAAK+H,IAAKhD,EAAEjB,KAAK9D,KAAK6D,YAAakB,EAAEjB,KAAK9D,KAAK2D,sBACvE+C,EAAQI,YAAY,CAAED,YAAa,UACnC,MAEC,IAAA,OACD/K,EAAG+F,KAAK,WACAmG,IACAC,EADK7B,EAAW1J,MAAMK,aACX4H,OAAO,SAACC,EAAKzE,GAEjByE,OADPA,EAAIzE,EAAEuH,MAAQvH,EACPyE,GACR,IACH8B,EAAQI,YAAY,CAChBD,YAAa,OACb7G,KAAM,CACFkI,cAAerM,EAAKsM,GAAGC,KAAKH,QAKxC,MAEC,IAAA,OACGI,IAAAA,EAAcxM,EAAKsM,GAAGpE,KAAKgB,EAAEjB,KAAK9D,KAAKkI,eAC3C9B,EAAW1J,MAAMK,aAAayK,QAAQ,SAACrH,GACnCA,EAAEmI,OAAOD,EAAYlI,EAAEuH,SAE3BtB,EAAWvJ,YAAYC,WACnBsJ,EAAW1J,MAAMK,cAErB2J,EAAQI,YAAY,CAAED,YAAa","file":"agent.347b5559.js","sourceRoot":"..\\..\\cnnNLP_dddqn_webworker","sourcesContent":["import * as tf from \"@tensorflow/tfjs\"\r\nimport { registerTfex } from \"../../../lib/tfjs-extensions/src\"\r\nconst tfex = registerTfex(tf)\r\n\r\nexport class DDDQN {\r\n    constructor({\r\n        sequenceLen = 60,\r\n        inputNum = 10,\r\n        embInner = [32, 32, 32],\r\n        filters = [8, 8, 8, 8],\r\n        outputInner = [32, 32],\r\n        actionNum = 8,\r\n        memorySize = 1000,\r\n        updateTargetStep = 20,\r\n        learningRate = 1e-3\r\n    }) {\r\n\r\n        {\r\n            this.updateTargetStep = updateTargetStep\r\n\r\n            this.count = 0\r\n\r\n            this.actionNum = actionNum\r\n        }\r\n\r\n        {\r\n            this.model = this.buildModel2({\r\n                sequenceLen: sequenceLen,\r\n                inputNum: inputNum,\r\n                embInner: embInner,\r\n                filters: filters,\r\n                outputInner: outputInner,\r\n                actionNum: actionNum\r\n            })\r\n            this.model.summary()\r\n\r\n            this.targetModel = this.buildModel2({\r\n                sequenceLen: sequenceLen,\r\n                inputNum: inputNum,\r\n                embInner: embInner,\r\n                filters: filters,\r\n                outputInner: outputInner,\r\n                actionNum: actionNum\r\n            })\r\n\r\n            this.targetModel.setWeights(this.model.getWeights())\r\n        }\r\n\r\n        {\r\n            this.memorySize = memorySize\r\n            this.memory = []\r\n        }\r\n\r\n        {\r\n            this.optimizer = tf.train.adam(learningRate)\r\n        }\r\n\r\n    }\r\n\r\n    buildModel(\r\n        {\r\n            sequenceLen,\r\n            inputNum,\r\n            embInner = [64, 64, 64],\r\n            filters = [64, 64, 64],\r\n            outputInner = [64, 64],\r\n            actionNum = 36\r\n        }\r\n    ) {\r\n        let input = tf.input({ shape: [sequenceLen, inputNum] })\r\n        let preASV = tf.input({ shape: [actionNum] })\r\n\r\n        let embLayer = tf.layers.dense({ units: embInner[0], activation: 'selu' }).apply(input)\r\n        for (let i = 1; i < embInner.length; i++) {\r\n            embLayer = tf.layers.dense({ units: embInner[i], activation: 'selu' }).apply(embLayer)\r\n        }\r\n        embLayer = tf.layers.reshape({ targetShape: [sequenceLen, embInner[embInner.length - 1], 1] }).apply(embLayer)\r\n        embLayer = tf.layers.dropout({ rate: 0.1 }).apply(embLayer)\r\n\r\n        let cnnLayer = tf.layers.conv2d({\r\n            filters: filters[0],\r\n            kernelSize: [2, embInner[embInner.length - 1]],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(embLayer)\r\n        for (let i = 1; i < filters.length - 1; i++) {\r\n            cnnLayer = tf.layers.conv2d({\r\n                filters: filters[i],\r\n                kernelSize: [i * Math.floor(sequenceLen / filters.length), embInner[embInner.length - 1]],\r\n                activation: \"selu\",\r\n                padding: \"same\"\r\n            }).apply(cnnLayer)\r\n        }\r\n        cnnLayer = tf.layers.conv2d({\r\n            filters: filters[filters.length - 1],\r\n            kernelSize: [sequenceLen, embInner[embInner.length - 1]],\r\n            strides: [sequenceLen, embInner[embInner.length - 1]],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(cnnLayer)\r\n\r\n        let flattenLayer = tf.layers.flatten().apply(cnnLayer)\r\n        flattenLayer = tf.layers.dropout({ rate: 0.1 }).apply(flattenLayer)\r\n\r\n        let outputLayer = tf.layers.dense({ units: outputInner[0], activation: 'selu' }).apply(flattenLayer)\r\n        for (let i = 1; i < outputInner.length; i++) {\r\n            outputLayer = tf.layers.dense({ units: outputInner[i], activation: 'selu' }).apply(outputLayer)\r\n        }\r\n        outputLayer = tf.layers.dense({ units: actionNum, activation: 'selu' }).apply(outputLayer)\r\n        outputLayer = tf.layers.dropout({ rate: 0.1 }).apply(outputLayer)\r\n\r\n        let value = tf.layers.dense({\r\n            units: actionNum,\r\n            activation: \"selu\"\r\n        }).apply(outputLayer)\r\n\r\n        let A = tf.layers.dense({\r\n            units: actionNum,\r\n            activation: \"selu\"\r\n        }).apply(outputLayer)\r\n\r\n        let mean = tfex.layers.lambda({\r\n            func: (x) => {\r\n                return tf.mean(x, 1, true)\r\n            },\r\n            outputShape: [1]\r\n        }).apply([A])\r\n\r\n        let advantage = tfex.layers.lambda({\r\n            func: (x, y) => {\r\n                return tf.sub(x, y)\r\n            }\r\n        }).apply([A, mean])\r\n\r\n        let Q = tf.layers.add().apply([value, advantage])\r\n\r\n        //Action Selection Value\r\n        let ASV = tf.layers.softmax().apply(Q)\r\n\r\n        //Action Activation Value\r\n        let AAV = tfex.layers.lambda({\r\n            func: (ASV, preASV) => {\r\n                return tf.div(tf.sub(ASV, preASV), tf.max(tf.stack([ASV, preASV]), 0))\r\n            }\r\n        }).apply([ASV, preASV])\r\n\r\n        // AAV = tf.layers.softmax().apply(AAV)\r\n\r\n        class WeightedAverage extends tf.layers.Layer {\r\n            constructor(args) {\r\n                super({})\r\n            }\r\n            build(inputShape) {\r\n                // console.log(\"LayerNorm build : \")\r\n                this.w = this.addWeight(\"w\", [inputShape[0][inputShape.length - 1]], \"float32\", tf.initializers.constant({ value: 0.5 }))\r\n                this.built = true\r\n            }\r\n            computeOutputShape(inputShape) {\r\n                //console.log(\"LayerNorm computeOutputShape\")\r\n                //console.log(inputShape)\r\n                return inputShape[0]\r\n            }\r\n            call(inputs, kwargs) {\r\n                //console.log(\"LayerNorm call\")\r\n                this.invokeCallHook(inputs, kwargs)\r\n                return tf.add(\r\n                    tf.mul(inputs[0], this.w.read()),\r\n                    tf.mul(inputs[1], tf.sub(1, this.w.read()))\r\n                )\r\n            }\r\n\r\n            /*\r\n            * If a custom layer class is to support serialization, it must implement\r\n            * the `className` static getter.\r\n            */\r\n            static get className() {\r\n                return \"WeightedAverage\"\r\n            }\r\n        }\r\n        // registerClass\r\n        tf.serialization.registerClass(WeightedAverage)\r\n\r\n        let action = new WeightedAverage().apply([ASV, AAV])\r\n        // action = tf.layers.softmax().apply(action)\r\n\r\n        return tf.model({ inputs: [input, preASV], outputs: [ASV, action] })\r\n    }\r\n\r\n    buildModel2(\r\n        {\r\n            sequenceLen,\r\n            inputNum,\r\n            filters = 8,\r\n            actionNum = 36\r\n        }\r\n    ) {\r\n        let input = tf.input({ shape: [sequenceLen, inputNum] })\r\n        let preASV = tf.input({ shape: [actionNum] })\r\n\r\n        class WeightedSequence extends tf.layers.Layer {\r\n            constructor(args = { axis, script }) {\r\n                super({})\r\n                this.axis = args.axis\r\n                this.script = args.script\r\n            }\r\n            build(inputShape) {\r\n                this.w = this.addWeight(\"w\", [inputShape[this.axis]], \"float32\", tf.initializers.constant({ value: 0.5 }))\r\n                this.w.write(tf.sin(tf.linspace(Math.PI / 2, 0.1, inputShape[this.axis])))\r\n                this.built = true\r\n            }\r\n            computeOutputShape(inputShape) {\r\n                return inputShape\r\n            }\r\n            call(inputs, kwargs) {\r\n                //console.log(\"LayerNorm call\")\r\n                this.invokeCallHook(inputs, kwargs)\r\n                return tfex.funcs.einsum(this.script, inputs[0], this.w.read())\r\n            }\r\n\r\n            /*\r\n            * If a custom layer class is to support serialization, it must implement\r\n            * the `className` static getter.\r\n            */\r\n            static get className() {\r\n                return \"WeightedSequence\"\r\n            }\r\n        }\r\n        // registerClass\r\n        tf.serialization.registerClass(WeightedSequence)\r\n\r\n        let WSLayer = new WeightedSequence({ axis: 1, script: \"ijk,j->ijk\" }).apply(input)\r\n\r\n        let cnnLayer = tf.layers.conv1d({\r\n            filters: filters * 4,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(WSLayer)\r\n        cnnLayer = tf.layers.conv1d({\r\n            filters: filters * 4,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(cnnLayer)\r\n\r\n        cnnLayer = tf.layers.dropout({ rate: 0.1 }).apply(cnnLayer)\r\n\r\n        while (1 <= cnnLayer.shape[1] / 2) {\r\n            cnnLayer = tf.layers.conv1d({\r\n                filters: filters,\r\n                kernelSize: [4],\r\n                strides: [2],\r\n                activation: \"selu\",\r\n                padding: \"same\"\r\n            }).apply(cnnLayer)\r\n            cnnLayer = tf.layers.batchNormalization({}).apply(cnnLayer)\r\n        }\r\n\r\n        let value = tf.layers.conv1d({\r\n            filters: filters * 4,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(cnnLayer)\r\n        value = tf.layers.conv1d({\r\n            filters: filters * 4,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(value)\r\n\r\n        value = tf.layers.conv1d({\r\n            filters: actionNum,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(value)\r\n\r\n        let A = tf.layers.conv1d({\r\n            filters: filters * 4,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(cnnLayer)\r\n        A = tf.layers.conv1d({\r\n            filters: filters * 4,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(A)\r\n\r\n        A = tf.layers.conv1d({\r\n            filters: actionNum,\r\n            kernelSize: [1],\r\n            activation: \"selu\",\r\n            padding: \"same\"\r\n        }).apply(A)\r\n\r\n        let mean = tfex.layers.lambda({\r\n            func: (x) => {\r\n                return tf.mean(x, 1, true)\r\n            },\r\n            outputShape: [1]\r\n        }).apply([A])\r\n\r\n        let advantage = tfex.layers.lambda({\r\n            func: (x, y) => {\r\n                return tf.sub(x, y)\r\n            }\r\n        }).apply([A, mean])\r\n\r\n        let Q = tf.layers.flatten().apply(\r\n            tf.layers.add().apply([value, advantage])\r\n        )\r\n\r\n        //Action Selection Value\r\n        let ASV = tf.layers.softmax().apply(Q)\r\n\r\n        //Action Activation Value\r\n        let AAV = tfex.layers.lambda({\r\n            func: (ASV, preASV) => {\r\n                return tf.tidy(() => {\r\n                    let aav = tf.sub(ASV, preASV)\r\n                    aav = tf.relu(aav)\r\n                    aav = tf.div(aav, aav.sum(1, true))\r\n                    return aav\r\n                })\r\n            }\r\n        }).apply([ASV, preASV])\r\n\r\n        // AAV = tf.layers.softmax().apply(AAV)\r\n\r\n        class WeightedAverage extends tf.layers.Layer {\r\n            constructor(args) {\r\n                super({})\r\n            }\r\n            build(inputShape) {\r\n                // console.log(\"LayerNorm build : \")\r\n                this.w = this.addWeight(\"w\", [inputShape[0][inputShape.length - 1]], \"float32\", tf.initializers.constant({ value: 0.8 }))\r\n                this.built = true\r\n            }\r\n            computeOutputShape(inputShape) {\r\n                //console.log(\"LayerNorm computeOutputShape\")\r\n                //console.log(inputShape)\r\n                return inputShape[0]\r\n            }\r\n            call(inputs, kwargs) {\r\n                //console.log(\"LayerNorm call\")\r\n                this.invokeCallHook(inputs, kwargs)\r\n                return tf.add(\r\n                    tf.mul(inputs[0], this.w.read()),\r\n                    tf.mul(inputs[1], tf.sub(1, this.w.read()))\r\n                )\r\n            }\r\n\r\n            /*\r\n            * If a custom layer class is to support serialization, it must implement\r\n            * the `className` static getter.\r\n            */\r\n            static get className() {\r\n                return \"WeightedAverage\"\r\n            }\r\n        }\r\n        // registerClass\r\n        tf.serialization.registerClass(WeightedAverage)\r\n\r\n        let action = new WeightedAverage().apply([ASV, AAV])\r\n\r\n        return tf.model({ inputs: [input, preASV], outputs: [ASV, action] })\r\n    }\r\n\r\n    loss(arrayPrevS, arrayPrevASV, arrayA, arrayR, arrayNextS, arrayNextASV) {\r\n        return tf.tidy(() => {\r\n            // console.log(arrayPrevS)\r\n            let batchPrevS = tf.tensor3d(arrayPrevS)\r\n            let batchPrevASV = tf.tensor2d(arrayPrevASV)\r\n            let batchA = tf.tensor1d(arrayA, 'int32')\r\n            let batchR = tf.tensor1d(arrayR)\r\n            let batchNextS = tf.tensor3d(arrayNextS)\r\n            let batchNextASV = tf.tensor2d(arrayNextASV)\r\n\r\n            const predictions = this.model.predict([batchPrevS, batchPrevASV]);\r\n\r\n            const maxQ = this.targetModel.predict([batchNextS, predictions[0]])[1].reshape([arrayPrevS.length, this.actionNum]).max(1)\r\n\r\n            const predMask = tf.oneHot(batchA, this.actionNum);\r\n\r\n            const targets = batchR.add(maxQ.mul(tf.scalar(0.99)));\r\n\r\n            return tf.mul(predictions[1].sub(targets.expandDims(1)).square(), predMask.asType('float32')).mean();\r\n        })\r\n\r\n    }\r\n\r\n    train(replayNum = 100, loadIdxes = [null], usePrioritizedReplay = false) {\r\n        tf.tidy(() => {\r\n            let train_ = (replayIdxes) => {\r\n                tf.tidy(() => {\r\n                    let arrayPrevS = []\r\n                    let arrayPrevASV = []\r\n                    let arrayA = []\r\n                    let arrayR = []\r\n                    let arrayNextS = []\r\n                    let arrayNextASV = []\r\n\r\n                    for (let i = 0; i < replayNum; i++) {\r\n                        let data = this.load(replayIdxes[i])\r\n                        // console.log(data)\r\n                        arrayPrevS.push(data[0])\r\n                        arrayPrevASV.push(data[1])\r\n                        arrayA.push(data[2])\r\n                        arrayR.push(data[3])\r\n                        arrayNextS.push(data[4])\r\n                        arrayNextASV.push(data[5])\r\n                    }\r\n\r\n                    let grads = this.optimizer.computeGradients(\r\n                        () => {\r\n                            let loss = this.loss(arrayPrevS, arrayPrevASV, arrayA, arrayR, arrayNextS, arrayNextASV)\r\n                            loss.print()\r\n                            return loss\r\n                        }, this.model.getWeights(true)).grads\r\n\r\n                    let gradsName = Object.keys(grads)\r\n                    grads = tfex.funcs.clipByGlobalNorm(Object.values(grads), 0.05)[0]\r\n\r\n                    this.optimizer.applyGradients(gradsName.reduce((acc, gn, idx) => {\r\n                        acc[gn] = grads[idx]\r\n                        return acc\r\n                    }, {}))\r\n\r\n                    this.count++\r\n\r\n                    if (this.count >= this.updateTargetStep) {\r\n\r\n                        this.targetModel.setWeights(this.model.getWeights())\r\n                        this.count = 0\r\n                    }\r\n                })\r\n            }\r\n            if (this.memory.length != 0) {\r\n                if (usePrioritizedReplay) {\r\n                    tf.tidy(() => {\r\n                        let e = tf.tensor(this.memory.map(mem => mem[3]))\r\n                        e = tf.abs(e.sub(e.mean()))\r\n                        e = e.div(e.sum(0, true))\r\n                        // e.print()\r\n                        return tf.multinomial(e, replayNum, null, true)\r\n                    }).array().then(prioritizedReplayBuffer => {\r\n                        // console.log(prioritizedReplayBuffer)\r\n                        train_(prioritizedReplayBuffer.map((prioritizedReplayIdx, idx) => {\r\n                            return loadIdxes[idx] == null || loadIdxes[idx] == undefined ? prioritizedReplayIdx : loadIdxes[idx]\r\n                        }))\r\n                    })\r\n                } else {\r\n                    train_(loadIdxes)\r\n                }\r\n            }\r\n        })\r\n    }\r\n\r\n    store(preState, preASV, action, reward, nextState, nextASV) {\r\n        if (this.memory.length == this.memorySize) {\r\n            this.memory.pop()\r\n        }\r\n        this.memory.unshift([preState, preASV, action, reward, nextState, nextASV])\r\n    }\r\n\r\n    load(index) {\r\n        if (index == null || index >= this.memory.length) {\r\n            index = Math.floor(Math.random() * this.memory.length);\r\n        }\r\n        return this.memory[index]\r\n    }\r\n\r\n}\r\n\r\nexport function dddqn({\r\n    sequenceLen = 60,\r\n    inputNum = 10,\r\n    embInner = [32, 32, 32],\r\n    filters = [8, 8, 8, 8],\r\n    outputInner = [32, 32],\r\n    actionNum = 8,\r\n    memorySize = 1000,\r\n    updateTargetStep = 20,\r\n    learningRate = 1e-3\r\n}) {\r\n    return new DDDQN({\r\n        sequenceLen,\r\n        inputNum,\r\n        embInner,\r\n        filters,\r\n        outputInner,\r\n        actionNum,\r\n        memorySize,\r\n        updateTargetStep,\r\n        learningRate\r\n    })\r\n}","export * from './model'","import * as tf from \"@tensorflow/tfjs\"\r\nimport { dddqn } from \"../../src/js/MirageNet/dddqn\"\r\nimport { registerTfex } from \"../../src/lib/tfjs-extensions/src\"\r\nconst tfex = registerTfex(tf)\r\n\r\ntf.setBackend(\"webgl\")\r\n\r\nlet actionNum = 9\r\n\r\nlet dddqnModel = dddqn({\r\n    sequenceLen: 1024,\r\n    inputNum: 20,\r\n    filters: 32,\r\n    actionNum: actionNum,\r\n    memorySize: 3200,\r\n    learningRate: 1e-4,\r\n    updateTargetStep: 32\r\n})\r\n\r\nlet preArchive = {\r\n    \"player1\": {\r\n        state: null,\r\n        ASV: tf.fill([actionNum], 1e-5, \"float32\"),\r\n        preASV: tf.fill([actionNum], 1e-5, \"float32\"),\r\n        action: null,\r\n        expired: true\r\n    },\r\n    \"player2\": {\r\n        state: null,\r\n        ASV: tf.fill([actionNum], 1e-5, \"float32\"),\r\n        preASV: tf.fill([actionNum], 1e-5, \"float32\"),\r\n        action: null,\r\n        expired: true\r\n    }\r\n}\r\n\r\ntf.ready().then(() => {\r\n    let channel = self\r\n    channel.addEventListener(\"message\", (e) => {\r\n        tf.tidy(() => {\r\n            switch (e.data.instruction) {\r\n                case 'init': {\r\n                    channel.postMessage({ instruction: \"init\" })\r\n                    break\r\n                }\r\n                case 'ctrl': {\r\n                    if (Object.keys(e.data.args.archive).length != 0) {\r\n                        let ASVsAndActions = dddqnModel\r\n                            .model\r\n                            .predict([\r\n                                tf.tensor(\r\n                                    Object.values(e.data.args.archive)\r\n                                        .map(archive => {\r\n                                            return archive.state\r\n                                        })\r\n                                ),\r\n                                tf.stack(\r\n                                    Object.keys(e.data.args.archive)\r\n                                        .map(playerName => {\r\n                                            return preArchive[playerName].ASV\r\n                                        })\r\n                                )\r\n                            ])\r\n                        // ASVsAndActions[1].print()\r\n\r\n                        let actions = []\r\n                        let chooseByArgMax = ASVsAndActions[1].argMax(1)\r\n                            // selectAction(outputs)\r\n                            .reshape([-1])\r\n                            .arraySync()\r\n                        let chooseByMultinomial = tf.multinomial(ASVsAndActions[1], 1, null, true)\r\n                            // selectAction(outputs)\r\n                            .reshape([-1])\r\n                            .arraySync()\r\n                        e.data.args.chooseAction.forEach((chooseAction, idx) => {\r\n                            if (chooseAction == \"argMax\") {\r\n                                actions[idx] = chooseByArgMax[idx]\r\n                            } else if (chooseAction == \"multinomial\") {\r\n                                actions[idx] = chooseByMultinomial[idx]\r\n                            }\r\n                        })\r\n\r\n\r\n                        Object.keys(preArchive).forEach((playerName) => {\r\n                            if (Object.keys(e.data.args.archive).find(name => name === playerName) !== undefined) {\r\n                                if (preArchive[playerName].expired == false) {\r\n                                    dddqnModel.store(\r\n                                        preArchive[playerName].state,\r\n                                        preArchive[playerName].preASV.arraySync(),\r\n                                        preArchive[playerName].action,\r\n                                        e.data.args.archive[playerName].reward,\r\n                                        e.data.args.archive[playerName].state,\r\n                                        preArchive[playerName].ASV.arraySync()\r\n                                    )\r\n                                }\r\n                                preArchive[playerName].expired = false\r\n                            } else {\r\n                                preArchive[playerName].expired = true\r\n                            }\r\n                        })\r\n\r\n                        Object.keys(e.data.args.archive).forEach((playerName, idx) => {\r\n                            preArchive[playerName].state = e.data.args.archive[playerName].state\r\n                            tf.dispose(preArchive[playerName].preASV)\r\n                            preArchive[playerName].preASV = tf.keep(preArchive[playerName].ASV)\r\n                            preArchive[playerName].ASV = tf.keep(tf.unstack(ASVsAndActions[0])[idx])\r\n                            preArchive[playerName].action = actions[idx]\r\n                        })\r\n                        channel.postMessage({\r\n                            instruction: \"ctrl\",\r\n                            args: {\r\n                                archive: Object.keys(e.data.args.archive).reduce((acc, name, idx) => {\r\n                                    acc[name] = {\r\n                                        action: actions[idx]\r\n                                    }\r\n                                    return acc\r\n                                }, {})\r\n                            }\r\n                        })\r\n                    } else {\r\n                        channel.postMessage({\r\n                            instruction: \"ctrl\",\r\n                            args: {\r\n                                archive: {}\r\n                            }\r\n                        })\r\n                    }\r\n                    // console.log(\"ctrl\")\r\n                    break\r\n                }\r\n                case 'train': {\r\n                    dddqnModel.train(e.data.args.bsz, e.data.args.replayIdxes, e.data.args.usePrioritizedReplay)\r\n                    channel.postMessage({ instruction: \"train\" })\r\n                    break\r\n                }\r\n                case 'save': {\r\n                    tf.tidy(() => {\r\n                        let Ws = dddqnModel.model.getWeights()\r\n                        let tList = Ws.reduce((acc, w) => {\r\n                            acc[w.name] = w\r\n                            return acc\r\n                        }, {})\r\n                        channel.postMessage({\r\n                            instruction: \"save\",\r\n                            args: {\r\n                                weightsBuffer: tfex.sl.save(tList)\r\n                            }\r\n                        })\r\n                    })\r\n\r\n                    break\r\n                }\r\n                case 'load': {\r\n                    let loadWeights = tfex.sl.load(e.data.args.weightsBuffer)\r\n                    dddqnModel.model.getWeights().forEach((w) => {\r\n                        w.assign(loadWeights[w.name])\r\n                    })\r\n                    dddqnModel.targetModel.setWeights(\r\n                        dddqnModel.model.getWeights()\r\n                    )\r\n                    channel.postMessage({ instruction: \"load\" })\r\n                    break\r\n                }\r\n            }\r\n        })\r\n    })\r\n})"]}